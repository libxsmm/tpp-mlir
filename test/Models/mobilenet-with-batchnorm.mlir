// RUN: tpp-opt %s -decompose-conv-to-matmul-or-brgemm -map-linalg-to-tpp -empty-tensor-to-alloc-tensor \
// RUN: -one-shot-bufferize="bufferize-function-boundaries allow-return-allocs function-boundary-type-conversion=identity-layout-map" \
// RUN: -drop-equivalent-buffer-results -finalizing-bufferize -canonicalize \
// RUN: -map-linalg-to-tpp -convert-linalg-to-tpp="use-parallel-loops=false" \
// RUN: -convert-tpp-to-xsmm -convert-xsmm-to-func \
// RUN: -expand-strided-metadata -lower-affine | \
// RUN: FileCheck %s
//

// ----------------------
// MobileNet Architecture
// ----------------------
// NOTE: TensorFlow model uses a slightly different version than in the paper.
// Specifically, first bottleneck block does not have 1x1 Conv2D.
//
// Layer 1 - Conv2D, 3x3 filter, stride 2
// Layer 2 - Bottleneck block 1, depthwise Conv2D, 3x3, stride 1
// Layer 3 - Bottleneck block 1, second Conv2D, 1x1 filter, stride 1
// Layer 4 - Bottleneck block 2, first Conv2D, 1x1 filter, stride 1
// Layer 5 - Bottleneck block 2, depthwise Conv2D, 3x3, stride 2
// Layer 6 - Bottleneck block 2, second Conv2D, 1x1 filter, stride 1
// Layer 7 - Bottleneck block 3, first Conv2D, 1x1 filter, stride 1
// Layer 8 - Bottleneck block 3, depthwise Conv2D, 3x3, stride 1
// Layer 9 - Bottleneck block 3, second Conv2D, 1x1 filter, stride 1
// Layer 10 - Bottleneck block 4, first Conv2D, 1x1 filter, stride 1
// Layer 11 - Bottleneck block 4, depthwise Conv2D, 3x3, stride 2
// Layer 12 - Bottleneck block 4, second Conv2D, 1x1 filter, stride 1
// Layer 13 - Bottleneck block 5, first Conv2D, 1x1 filter, stride 1
// Layer 14 - Bottleneck block 5, depthwise Conv2D, 3x3, stride 1
// Layer 15 - Bottleneck block 5, second Conv2D, 1x1 filter, stride 1
// Layer 16 - Bottleneck block 6, first Conv2D, 1x1 filter, stride 1
// Layer 17 - Bottleneck block 6, depthwise Conv2D, 3x3, stride 1
// Layer 18 - Bottleneck block 6, second Conv2D, 1x1 filter, stride 1
// Layer 19 - Bottleneck block 7, first Conv2D, 1x1 filter, stride 1
// Layer 20 - Bottleneck block 7, depthwise Conv2D, 3x3, stride 2
// Layer 21 - Bottleneck block 7, second Conv2D, 1x1 filter, stride 1
// Layer 22 - Bottleneck block 8, first Conv2D, 1x1 filter, stride 1
// Layer 23 - Bottleneck block 8, depthwise Conv2D, 3x3, stride 1
// Layer 24 - Bottleneck block 8, second Conv2D, 1x1 filter, stride 1
// Layer 25 - Bottleneck block 9, first Conv2D, 1x1 filter, stride 1
// Layer 26 - Bottleneck block 9, depthwise Conv2D, 3x3, stride 1
// Layer 27 - Bottleneck block 9, second Conv2D, 1x1 filter, stride 1
// Layer 28 - Bottleneck block 10, first Conv2D, 1x1 filter, stride 1
// Layer 29 - Bottleneck block 10, depthwise Conv2D, 3x3, stride 1
// Layer 30 - Bottleneck block 10, second Conv2D, 1x1 filter, stride 1
// Layer 31 - Bottleneck block 11, first Conv2D, 1x1 filter, stride 1
// Layer 32 - Bottleneck block 11, depthwise Conv2D, 3x3, stride 1
// Layer 33 - Bottleneck block 11, second Conv2D, 1x1 filter, stride 1
// Layer 34 - Bottleneck block 12, first Conv2D, 1x1 filter, stride 1
// Layer 35 - Bottleneck block 12, depthwise Conv2D, 3x3, stride 1
// Layer 36 - Bottleneck block 12, second Conv2D, 1x1 filter, stride 1
// Layer 37 - Bottleneck block 13, first Conv2D, 1x1 filter, stride 1
// Layer 38 - Bottleneck block 13, depthwise Conv2D, 3x3, stride 1
// Layer 39 - Bottleneck block 13, second Conv2D, 1x1 filter, stride 1
// Layer 40 - Bottleneck block 14, first Conv2D, 1x1 filter, stride 1
// Layer 41 - Bottleneck block 14, depthwise Conv2D, 3x3, stride 2
// Layer 42 - Bottleneck block 14, second Conv2D, 1x1 filter, stride 1
// Layer 43 - Bottleneck block 15, first Conv2D, 1x1 filter, stride 1
// Layer 44 - Bottleneck block 15, depthwise Conv2D, 3x3, stride 1
// Layer 45 - Bottleneck block 15, second Conv2D, 1x1 filter, stride 1
// Layer 46 - Bottleneck block 16, first Conv2D, 1x1 filter, stride 1
// Layer 47 - Bottleneck block 16, depthwise Conv2D, 3x3, stride 1
// Layer 48 - Bottleneck block 16, second Conv2D, 1x1 filter, stride 1
// Layer 49 - Bottleneck block 17, first Conv2D, 1x1 filter, stride 1
// Layer 50 - Bottleneck block 17, depthwise Conv2D, 3x3, stride 1
// Layer 51 - Bottleneck block 17, second Conv2D, 1x1 filter, stride 1
// Layer 52 - Conv2D, 1x1 filter, stride 1
// Layer 53 - Average pooling
// Layer 54 - Conv2D, 1x1 filter, stride 1

#map0 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> ()>
#map2 = affine_map<(d0) -> (d0)>
#map3 = affine_map<(d0, d1, d2, d3) -> (d3)>

//
// CHECK-LABEL: @mobilenet(
// CHECK-SAME: %[[arg:.*]]: memref<1x224x224x3xf32>) -> memref<1x1001xf32> {
//
func.func @mobilenet(%arg0: tensor<1x224x224x3xf32>) -> tensor<1x1001xf32> {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant dense<1.000000e-03> : tensor<32xf32>
  %cst_1 = arith.constant dense<1.000000e-03> : tensor<16xf32>
  %cst_2 = arith.constant dense<1.000000e-03> : tensor<96xf32>
  %cst_3 = arith.constant dense<1.000000e-03> : tensor<24xf32>
  %cst_4 = arith.constant dense<1.000000e-03> : tensor<144xf32>
  %cst_5 = arith.constant dense<1.000000e-03> : tensor<192xf32>
  %cst_6 = arith.constant dense<1.000000e-03> : tensor<64xf32>
  %cst_7 = arith.constant dense<1.000000e-03> : tensor<384xf32>
  %cst_8 = arith.constant dense<1.000000e-03> : tensor<576xf32>
  %cst_9 = arith.constant dense<1.000000e-03> : tensor<160xf32>
  %cst_10 = arith.constant dense<1.000000e-03> : tensor<960xf32>
  %cst_11 = arith.constant dense<1.000000e-03> : tensor<320xf32>
  %cst_12 = arith.constant dense<1.000000e-03> : tensor<1280xf32>
  %cst_13 = arith.constant dense<4.900000e+01> : tensor<f32>
  %cst_14 = arith.constant dense<6.000000e+00> : tensor<f32>
  %cst_15 = arith.constant dense<0.000000e+00> : tensor<f32>
  %cst_16 = arith.constant dense<1.000000e+00> : tensor<f32>
  %cst_17 = arith.constant dense<2.000000e+00> : tensor<f32>

  %layer_1_conv_BatchNorm_beta  = arith.constant dense<[2.25554872, 2.92245936, -1.66315615, -1.21565294, 3.33179927, 3.69170165, -6.159710e+00, -2.54278374, 2.7811873, 2.24960351, -2.13791609, -0.298735231, -1.953850e-01, -1.34365737, 2.71462131, 2.94299102, 0.00682453858, 2.60169625, -3.65165472, -1.30849361, 2.43524456, 3.37377167, 2.16475296, -0.408423364, 3.41844273, 3.2883625, 0.213621914, 2.78795624, 0.0876075401, 2.40671778, -3.21157765, 4.7613039]> : tensor<32xf32>
  %layer_1_conv_BatchNorm_gamma  = arith.constant dense<[0.61217618, 1.52599823, 1.67057538, 0.690793931, 0.550860763, 1.21739149, 4.29392242, 0.497940689, 1.46930325, 0.647338152, 2.57277203, 0.975993037, 0.948703169, 0.229183063, 1.42201865, 0.88473469, 1.04328179, 0.633869767, 2.81038237, 0.158598527, 0.651199758, 0.593193114, 0.347987592, 0.969841837, 1.35439336, 1.36573553, 0.970487177, 1.6944195, 1.03797102, 0.573929548, 2.79525781, 0.176083818]> : tensor<32xf32>
  %layer_1_conv_BatchNorm_moving_mean  = arith.constant dense<[-0.0367616639, 0.00373166706, -0.0363905206, 7.18992659E-21, -0.186189786, 0.165299132, 0.0970188975, 7.03429566E-22, 0.0110954735, -0.0201514605, 0.0624767467, -1.11152779E-21, -1.33736627E-21, -5.3064848E-22, -0.154078633, -0.0700953826, -1.09995359E-4, -1.40111642E-5, 0.330333322, -5.43228936E-21, -0.0314484611, -0.18477723, 0.00198132126, -0.0245106649, 0.214064285, 7.917760e-02, 0.00152423256, -0.00403895183, 6.32722032E-22, -0.238866553, -0.0691612735, 0.0108955735]> : tensor<32xf32>
  %layer_1_conv_BatchNorm_moving_variance  = arith.constant dense<[0.120516591, 0.115784936, 0.0200384893, 3.91475062E-36, 0.574720144, 0.93622148, 0.297442347, 3.91224236E-36, 0.074043192, 0.0692586452, 0.148472115, 3.91183556E-36, 3.90965088E-36, 3.91161207E-36, 0.812721491, 0.173544407, 3.15677738E-7, 0.0463415869, 0.988436281, 3.91509859E-36, 0.0216893554, 0.698844492, 0.0103410184, 0.0332942382, 1.42868555, 0.241909772, 3.48448448E-5, 0.11898233, 3.9072897E-36, 0.583033144, 0.140964225, 0.0195200425]> : tensor<32xf32>
  %layer_1_conv_weights  = arith.constant dense<1.0> : tensor<3x3x3x32xf32>
  
  %layer_52_conv_BatchNorm_beta  = arith.constant dense<1.0> : tensor<1280xf32>
  %layer_52_conv_BatchNorm_gamma  = arith.constant dense<1.0> : tensor<1280xf32>
  %layer_52_conv_BatchNorm_moving_mean  = arith.constant dense<1.0> : tensor<1280xf32>
  %layer_52_conv_BatchNorm_moving_variance  = arith.constant dense<1.0> : tensor<1280xf32>
  %layer_52_conv_weights  = arith.constant dense<1.0> : tensor<1x1x320x1280xf32>

  %layer_54_logits_conv_biases  = arith.constant dense<0.5> : tensor<1001xf32>
  %layer_54_logits_conv_weights = arith.constant dense<1.0> : tensor<1x1x1280x1001xf32> 

  // Expand block in a bottleneck block refers to 1st 1x1 Conv2D in the bottleneck block.
  // Project block in a bottleneck block refers to 2nd 1x1 Conv2D in the bottleneck block.
  %bottleneck_block_1_depthwise_BatchNorm_beta  = arith.constant dense<[1.74432492, 3.22856832, -0.164343342, -0.151181191, 3.41901779, 2.9530704, 5.097770e-01, -0.22501117, 3.29713655, 1.05740237, 0.15488711, -0.36347121, -0.436501116, -1.04766357, 2.89067554, 2.63541865, -0.519024551, 1.43494928, 2.56361675, -1.3595705, -0.166126043, 2.404210e+00, -0.0780990198, -1.22872186, 3.07737827, 2.9610846, -0.147120178, 2.70570183, -0.359455556, 2.39848304, -0.579904437, -0.323385626]> : tensor<32xf32>
  %bottleneck_block_1_depthwise_BatchNorm_gamma  = arith.constant dense<[0.79812473, 1.02470672, 0.234702155, 5.847020e-01, 1.47273922, 1.65369105, 0.207335263, 0.253795445, 1.74145031, 0.851999104, 0.285381347, 0.0487552546, 0.619520783, 0.658530533, 0.462138057, 0.997453808, 0.514498651, 0.881484925, 0.226436034, 7.940340e-01, 0.176940665, 1.25603747, 1.08425307, 0.481042415, 1.55542338, 1.30222631, -0.0969873368, 0.840993523, 0.0373481698, 1.28414547, 0.509954929, 0.82484883]> : tensor<32xf32>
  %bottleneck_block_1_depthwise_BatchNorm_moving_mean  = arith.constant dense<[2.83318233, -6.53696203, 0.0420894213, -3.90999813E-36, 1.27528048, -7.626320e-01, 0.0138975857, 3.91655755E-36, -1.63337111, 2.17463207, 0.0931125953, 3.91609192E-36, -3.91780558E-36, 3.90671214E-36, 3.92310977, 0.766388356, -0.10357853, 0.174043208, 0.00519207632, 3.91023956E-36, -13.6242762, -1.58756614, -0.244740307, 3.34658194, -0.238025799, -0.150351256, 0.699682236, -6.87351561, 0.149567708, 0.404550731, 0.278983235, 11.8062963]> : tensor<32xf32>
  %bottleneck_block_1_depthwise_BatchNorm_moving_variance  = arith.constant dense<[52.9916306, 98.6942443, 1.07424688, 3.90845594E-36, 57.062622, 296.507599, 0.411148727, 3.91267929E-36, 110.319336, 26.4148273, 5.2001071, 3.91252109E-36, 3.91761222E-36, 3.91278261E-36, 21.3122597, 70.8626938, 0.0140138669, 35.9642715, 0.0347588137, 3.91159879E-36, 13.3438597, 1.412400e+02, 10.2351866, 26.5206547, 415.62619, 24.5138931, 0.232058972, 87.2247086, 1.3200994E-4, 3.68522573, 3.7254498, 4.24222136]> : tensor<32xf32>
  %bottleneck_block_1_depthwise_depthwise_weights = arith.constant dense<1.0> : tensor<3x3x32x1xf32>
  %bottleneck_block_1_project_BatchNorm_beta  = arith.constant dense<[-8.19714798E-4, -0.0309335329, -0.0145276617, -0.0272252783, 0.00549815083, 0.0209561121, -0.0147552742, 0.00554378517, 0.0135861654, -0.0330353081, -0.023117546, 7.524020e-02, 0.00900177471, 0.027946597, -0.0386469066, 0.0130989701]> : tensor<16xf32>
  %bottleneck_block_1_project_BatchNorm_gamma  = arith.constant dense<[3.40056849, 3.28421092, 5.15095568, 4.87235546, 2.63781261, 4.399660e+00, 3.9031713, 4.10531473, 4.17432976, 4.4959836, 3.82573795, 4.41370964, 4.32342243, 3.78632116, 4.25729561, 3.81137443]> : tensor<16xf32>
  %bottleneck_block_1_project_BatchNorm_moving_mean  = arith.constant dense<[0.370955408, -0.457018822, -2.472435, -3.22375035, -3.62205291, -0.512393236, 4.14230191E-4, -1.57693684, 3.10221648, -0.567590356, 0.37900725, -4.35477877, 2.78368974, 1.71124804, -1.3105365, 0.598687291]> : tensor<16xf32>
  %bottleneck_block_1_project_BatchNorm_moving_variance  = arith.constant dense<[0.492682636, 0.218184263, 0.608508169, 0.425083429, 0.47516489, 0.418958843, 0.571839213, 0.783529698, 0.873603045, 0.438180149, 0.272738069, 1.0370059, 0.40277645, 0.331211984, 0.51713872, 0.625526368]> : tensor<16xf32>
  %bottleneck_block_1_project_weights  = arith.constant dense<1.0> : tensor<1x1x32x16xf32>
  
  %bottleneck_block_2_depthwise_BatchNorm_beta  = arith.constant dense<[0.075763084, 0.556233525, 0.60598743, -0.0194897912, 0.842676639, 7.29253283E-4, 0.296607643, 0.0085013276, -0.383848131, 0.718912422, 0.0931074991, 2.42484164, 0.505089104, -0.00672543747, -0.0535928272, 2.87292123, 0.771947562, -0.00569115113, 0.311199158, -0.854263484, 0.813602089, 0.52456665, 0.0394771472, -0.251009613, -0.00753197353, -0.00669688917, -4.14281416, -0.0192595329, -0.281938165, 0.92985022, -0.0131408181, 0.0112754144, -1.28576577, -0.0191722084, -0.0990585535, 0.0687611178, 0.210619345, -0.0368103087, 0.460901648, -0.454100907, -1.0837549, 0.00178176514, 1.05362773, 0.540647388, 0.00376042398, 2.51668477, 0.681804656, 0.111346446, 4.56463432, 0.349312663, -0.0156647228, 0.720750451, 0.181947798, 0.00100856903, 0.57716465, -0.00775138522, 0.0268215891, 0.254376858, 3.06475687, -0.983887135, 1.39018989, -1.11407483, 0.0207444429, -0.102040209, 0.0081587648, 0.836840033, 0.0336996019, 0.338566422, -0.0567593724, 1.28401804, -2.76571918, 0.045484975, -8.24082992E-4, -3.55457742E-4, -0.980479359, -0.0245683286, 0.532637715, -0.026479492, -0.0130770952, 0.960767507, -0.0366650894, 0.0181219392, 0.608906388, 0.55669409, 3.8238039, 0.412681371, -1.20101893, -1.44559777, 0.0609581582, -5.238230e-02, -2.8009665, 0.25020051, 2.00201941, 0.00250861631, 0.546782374, -0.00142083399]> : tensor<96xf32>
  %bottleneck_block_2_depthwise_BatchNorm_gamma  = arith.constant dense<[0.890267312, 0.596128643, 0.817270636, 0.744000732, 0.731782615, 1.03296041, 0.500598729, 0.924991548, 1.33119798, 0.822722852, 1.08684301, 0.483177334, 0.649478971, 1.00084603, 0.658253848, 0.453266323, 0.830686688, 1.00440526, 0.977883875, 1.71405602, 0.747993231, 0.680301964, 1.33033478, 1.197440e+00, 0.88829875, 0.982442319, 1.43396533, 0.911843955, 1.42144191, 0.790293097, 0.886332452, 1.05867946, 2.52831173, 9.873510e-01, 1.35442388, 0.707504212, 1.03027761, 1.18410861, 0.587145448, 1.37719083, 1.91317868, 1.37733114, 0.753638744, 0.648172498, 0.940217971, 0.700704038, 0.777976512, 0.869827687, 0.81795156, 0.545369148, 0.849215149, 0.855934977, 1.03926933, 0.991148054, 0.666229606, 9.179590e-01, 0.928147494, 1.29936242, 0.612392306, 2.44894624, 0.648945093, 2.11283088, 0.759577095, 0.958055675, 0.898208857, 0.734331965, 1.03250206, 1.22035158, 1.19430685, 0.735356748, 3.41700602, 1.03210902, 0.875568807, 1.01257622, 1.9026401, 0.627402306, 0.679248034, 0.840537905, 0.909008265, 0.696251392, 0.597221732, 1.36274028, 0.935684561, 0.587884784, 0.756439626, 0.926523506, 2.08558822, 2.97733688, 0.675049782, 0.892708241, 1.16603971, 1.28459418, 0.7803694, 1.03744328, 0.776447772, 1.08817816]> : tensor<96xf32>
  %bottleneck_block_2_depthwise_BatchNorm_moving_mean  = arith.constant dense<[0.0416700691, 1.92287076, 4.57740879, 5.53305054, 4.98347235, 0.00883556809, 1.3732326, 0.481353462, 28.6326618, 2.40713477, 18.9752426, -12.0163755, 2.74067402, 1.75730288, 6.05060863, -1.52116203, 2.88509583, 0.00517815677, -4.8391571, -9.18975925, 3.65348697, 2.40108943, -17.2298775, -7.93841124, 0.140097514, -0.184655845, 0.0639636889, 0.146247804, 32.502758, -14.4677744, 0.134101942, -2.0256772, -7.1124525, -5.36600494, 0.247182757, 4.51493263, -0.199170381, 27.1986427, -10.8441982, -7.9941597, -6.92659378, -4.9867816, 39.0245476, 1.95448494, 0.0261880234, -6.28950786, 3.2861445, -28.6945648, -3.79356217, 1.9812057, 0.114015967, 4.64576054, -1.25658226, 0.0189403184, 2.10093737, -0.127945662, 1.89052665, -3.97486401, -4.31072712, -6.06908274, -3.08855534, -7.63081073, -0.223834455, -7.0499053, -0.0530991741, 3.55838108, 18.821352, -5.51690578, -0.344994873, 3.85224962, -7.50418186, -1.7648735, 0.0912790745, -0.213905692, -8.08001899, 0.726449191, 2.59946036, 1.59937906, 0.0124042984, -15.8675499, 0.260116667, -1.07084453, -12.4783897, -11.9488945, -20.4352703, -1.07939541, -8.33849525, -10.5388613, -0.352636278, -0.155235365, 0.0553191639, -3.23795843, -5.70739698, -1.15071583, -10.1446457, 0.226829305]> : tensor<96xf32>
  %bottleneck_block_2_depthwise_BatchNorm_moving_variance  = arith.constant dense<[24.2594433, 6.84813213, 38.2375488, 25.6215572, 26.9548244, 2.9359374, 5.03880119, 6.97662115, 6.65080404, 8.97752857, 13.0803738, 2.2176218, 13.3688641, 8.15823841, 0.846018671, 7.27513313, 11.0407963, 3.32503319, 23.3536339, 63.5768433, 16.8672028, 11.5441208, 189.448318, 16.0902653, 2.88693428, 2.70087481, 0.239523903, 0.463206828, 8.93383884, 169.075668, 6.60774374, 21.4965591, 50.1164665, 13.9232664, 9.88177776, 9.00228309, 89.9697876, 27.9575653, 83.9798431, 51.6152153, 45.9922562, 21.5007668, 3.89156604, 6.57490683, 1.2199266, 40.2284317, 16.5793972, 124.354332, 19.1620426, 9.87185955, 3.7372365, 37.0463371, 10.0187635, 2.6869843, 7.75519847, 11.8283119, 9.19869709, 26.9907112, 21.2434235, 52.1491318, 12.3058214, 47.4957924, 41.0126648, 26.3935413, 9.20099925, 12.6591978, 1.738810e+01, 43.2171898, 16.9349632, 16.3747616, 56.7835312, 10.1376038, 1.43224704, 5.48142481, 50.8617592, 0.809611082, 13.5723553, 20.7559376, 3.12434483, 216.937943, 5.84756708, 5.56508875, 138.429352, 92.1282653, 8.62939643, 103.088951, 52.5264816, 121.691513, 2.10189867, 4.85313034, 0.16565752, 17.8572502, 40.8276596, 3.66794467, 88.097229, 3.07709932]> : tensor<96xf32>
  %bottleneck_block_2_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x96x1xf32>
  %bottleneck_block_2_expand_BatchNorm_beta  = arith.constant dense<[0.791253745, -0.00625628326, 0.0164244398, 2.53171802, -0.129518598, 1.93132687, -0.0136202015, 1.64649844, 2.53116035, 0.206663132, 2.31441975, 1.89547729, 0.138999864, 2.41638589, 1.51033115, -0.0371032842, 0.0554995686, 2.26342463, 0.508027315, -0.27538228, -0.0392090715, -0.0416388474, 0.875448465, 1.11595118, 1.33425021, 2.23228455, -2.24294591, 1.68439817, 3.18936062, 0.423338473, 0.635678887, 2.30395365, -0.368289351, 4.90230942, 2.42004514, 1.49982595, 2.32918835, 2.53781891, 0.198789194, -0.764684975, -0.281551689, 0.380105704, 4.11209249, -0.0474878885, 1.82528508, -0.20341821, 0.0144800246, 3.15299797, 0.0596953221, 0.028049903, 2.28372765, -0.00953424443, 0.142196819, 2.05306363, 0.0330575481, 1.09865737, 1.49927032, 0.141164884, 2.57387352, 0.192767054, 0.267090648, -0.319839597, 3.81175208, 2.17115593, 1.0511328, 0.0268308818, 1.91761577, 0.328406692, 2.96591139, -0.0410891138, 0.107148767, 1.25212419, 2.01175404, 2.4990406, -0.220617428, 1.43415606, -0.0184701029, 1.48559499, 1.51876426, 0.227677256, 1.78802478, 0.0939446091, 0.061333321, 0.59024024, 1.98332095, 1.88633192, 0.063022472, 0.250983506, 1.23973048, 1.84975994, -1.92136407, 0.0810356736, -0.123802908, 2.52600718, 1.19839847, 2.12222648]> : tensor<96xf32>
  %bottleneck_block_2_expand_BatchNorm_gamma  = arith.constant dense<[1.22767234, 0.59426856, 1.59510052, 1.9263382, 1.65168178, 0.407234162, 0.763577938, 0.650442421, 0.61202532, 0.609301269, 0.453565776, 0.366932511, 1.27483618, 0.631105542, 0.252343833, 0.878948211, 0.757994592, 0.399029404, 1.78342307, 5.88366938, 1.09283042, 1.0080502, 8.11980533, 1.60857689, 0.513570964, 0.407376528, 0.745314121, 0.205889806, 0.789244234, 9.77658271, 0.834677875, 0.998944044, 5.47919559, 0.773754179, 0.502682507, 0.825049221, 3.81119728, 0.800765454, 6.98591375, 6.14424896, 4.96997786, 2.27323389, 0.33272928, 0.740801334, 0.315720141, 2.17472601, 0.917621851, 4.81370354, 1.05332947, 1.07336712, 4.455980e-01, 1.54496932, 1.13703609, 0.38687548, 0.779322087, 0.657845675, 0.722159505, 2.46076775, 1.95760596, 2.29669476, 1.07253706, 4.76074219, 1.73521018, 1.95580268, 0.960702896, 0.958575248, 0.690533697, 2.72268295, 0.617593288, 1.1630342, 5.48943758, 0.703634262, 0.33023411, 0.474977762, 5.10354042, 0.320191473, 0.883943676, 1.2490629, 0.66700679, 9.20526123, 0.724862158, 0.853929638, 9.42533779, 6.7522254, 0.502082109, 5.22622347, 5.32728291, 5.12173891, 0.25761354, 7.685920e-01, 0.678396165, 1.71673083, 2.6490047, 0.475152671, 3.63279128, 0.420024693]> : tensor<96xf32>
  %bottleneck_block_2_expand_BatchNorm_moving_mean  = arith.constant dense<[-0.0168888289, -0.00316146505, 0.0282705277, -0.0278135221, 0.00493787462, 0.0238661468, 0.00861460716, 0.0250727739, 0.0398940295, 0.00527513539, -0.00216202391, 0.0138845444, -0.0246928297, -0.0232806113, -0.01133331, -0.00801348313, 0.0401567742, -0.00329448981, 0.0205698721, 0.0247913729, -0.0536587238, -0.00438696751, -0.0286551379, -0.0227385908, 0.00368787162, -0.00465336349, -0.0101342844, 0.00458787708, -3.085200e-03, -0.0298466347, 0.00657342421, 0.0230471119, -0.00742753595, 0.0286068488, 0.0100677358, -0.00172263035, 0.0136269219, 0.0231221728, 0.00104182842, -0.00774289714, 0.0276790056, 0.0279000141, -8.587920e-03, -0.00101263367, -0.0166132506, 0.00138127897, 0.00299589452, 0.0283225495, -0.0169240087, 0.0288520288, 4.70893923E-4, -0.0331461616, -0.00934269931, 0.00262755714, 0.00804559886, -0.00214422261, -0.00225821137, -0.0307881124, -0.0236392282, -0.0232816394, -0.00315627153, 0.00863971096, -0.00762622198, -0.00105694437, 0.005172743, -0.032203842, -0.0269558262, -0.00749304052, -0.00136714429, 0.0252296347, -0.0255127512, 0.00516000437, -0.0180989858, 0.0104155112, -0.0257571489, 8.64615198E-4, 0.0220881868, -0.0243092161, -0.00116866978, 0.0274884216, 0.00566426758, 0.00658158771, 0.0365771875, 0.0120647578, 1.67575257E-4, 0.0193712879, -0.0129224714, 0.0325272493, -6.14345423E-4, -0.00293266983, -0.00944238714, 0.00315348804, -0.00746045541, -0.0263783894, 0.0168799367, -0.00260351528]> : tensor<96xf32>
  %bottleneck_block_2_expand_BatchNorm_moving_variance  = arith.constant dense<[2.59159327, 2.53570127, 10.4927835, 3.51469135, 13.4151592, 3.48554087, 3.50743532, 4.485240e+00, 9.5318489, 6.1766119, 3.07388949, 3.39420271, 5.46677065, 4.25872087, 2.33511853, 3.55466843, 14.6076279, 2.71356821, 3.75317502, 8.605160e+00, 13.8079481, 10.9676752, 11.3685884, 3.82780838, 3.31585145, 3.53890228, 3.94280314, 2.02294397, 10.1588745, 12.1289043, 3.29788399, 3.91295671, 12.1542006, 3.76842856, 2.7002387, 2.57250381, 3.19908905, 6.63535929, 8.56240081, 12.4127283, 10.2295771, 5.2781744, 4.82045841, 9.0474205, 3.32078862, 13.228878, 15.4229612, 9.35667896, 16.5581474, 5.74614048, 2.58621931, 11.7694807, 3.28367448, 2.52471113, 6.89618396, 2.54046655, 3.84810972, 5.08615398, 3.51519942, 4.69362974, 2.20209336, 10.0410442, 2.25373292, 3.72028208, 4.01845598, 14.1793242, 6.90473651, 4.4216671, 3.03634572, 13.3703651, 3.80505443, 3.44741797, 2.66724563, 3.86514592, 9.10229111, 2.01489758, 9.87242698, 2.84478521, 4.03935814, 8.832201, 1.84623253, 3.69929957, 15.2974033, 9.90408325, 7.61182165, 4.41899633, 9.01449203, 11.4462948, 1.75843298, 2.9125886, 1.64914906, 4.33877611, 12.1088514, 5.35515404, 6.02762842, 4.16573715]> : tensor<96xf32>
  %bottleneck_block_2_expand_weights  = arith.constant dense<1.0> : tensor<1x1x16x96xf32>
  %bottleneck_block_2_project_BatchNorm_beta  = arith.constant dense<[-0.00557816448, -0.00263959868, 0.00401740242, 0.00432028482, -0.0101700919, -7.47990503E-4, 0.00499755098, -0.0022082075, 5.35378698E-4, -0.00522752525, 0.00281768385, 0.00171113911, 0.00346040237, -0.00633987505, 0.00250144233, 0.0104376879, 0.00355520076, 0.00292971521, 0.00690554408, 3.35121556E-4, 0.00497298688, -8.76762439E-4, -0.00106618355, -1.0939718E-4]> : tensor<24xf32>
  %bottleneck_block_2_project_BatchNorm_gamma  = arith.constant dense<[2.57771158, 3.69063854, 2.83831406, 3.87169361, 2.61303663, 2.8247838, 3.7412827, 2.15734911, 3.06861234, 2.4392035, 5.31477785, 4.53066301, 2.809980e+00, 4.31477642, 3.44714618, 1.98722923, 4.26552725, 2.54838514, 4.85397291, 3.63126874, 3.88489032, 5.30345678, 2.86938405, 3.75189519]> : tensor<24xf32>
  %bottleneck_block_2_project_BatchNorm_moving_mean  = arith.constant dense<[-1.99822152, 2.29876685, -2.98063183, 2.53998566, -5.225890e-01, 0.547777772, 1.12811923, -0.955577969, 1.24982333, -0.0591878369, -0.983643472, 1.14647317, -1.39277732, 1.08950388, -5.11862516, 1.31960511, -2.36047721, 1.293580e+00, 0.131009921, -0.677315712, 3.02787566, 1.59654009, 0.48207137, -3.23425269]> : tensor<24xf32>
  %bottleneck_block_2_project_BatchNorm_moving_variance  = arith.constant dense<[0.40463984, 1.30977511, 0.357889831, 1.22326589, 0.647126734, 0.66305226, 1.44740856, 0.216079295, 0.901478886, 0.438607544, 2.97381711, 1.84096253, 0.382242173, 1.20802915, 1.39219677, 0.304214984, 1.1096034, 4.131600e-01, 2.0443902, 0.525245726, 0.676085353, 2.78503466, 0.651482344, 1.37233531]> : tensor<24xf32>
  %bottleneck_block_2_project_weights  = arith.constant dense<1.0> : tensor<1x1x96x24xf32>
  %bottleneck_block_11_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_11_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_11_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_11_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_11_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x384x1xf32>
  %bottleneck_block_11_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_11_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_11_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_11_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_11_expand_weights  = arith.constant dense<1.0> : tensor<1x1x64x384xf32>
  %bottleneck_block_11_project_BatchNorm_beta  = arith.constant dense<[-0.00137918803, 0.00232685427, 2.02661453E-4, 1.26824571E-5, -0.00120684691, 0.00113291456, 0.00122009648, -0.00166119286, -0.00168813032, -0.00104906166, -2.69461161E-4, 0.00271106395, -2.99948413E-4, -0.00127025053, -0.00110016088, 2.15643595E-4, -7.62648939E-4, 0.00136871217, -9.88266547E-4, -0.00145929051, 2.7358532E-4, 0.00290935859, -0.00318993255, 6.28198963E-4, -2.29209065E-4, 0.0012352186, 0.00187398435, 0.00242577563, -4.001380e-04, 5.99409628E-4, 0.00248733186, -0.00125654193, -0.0032282602, 0.00101434463, 1.70147119E-4, -0.00143975834, -0.00299824635, -0.00189851888, -0.00187299517, -0.00149797974, -0.00237648166, -0.00415344397, -0.00150687131, 3.72927869E-4, 0.00144312216, 0.00185100303, 6.51392401E-5, -0.00511776283, -0.00205189642, -7.7631278E-4, 3.15112702E-4, -0.0026104732, 0.00193718448, -0.00295866164, -0.00189856673, -0.00155507703, 0.00138318387, -0.00210811314, 0.00218440522, -0.00140783528, -0.00266304659, -0.00123410497, -0.00259372848, 0.00179059489, 0.00114162103, -6.58302102E-4, 0.00306518422, -0.00207902677, 0.00347131677, -0.00201979885, -0.00129993446, -1.10264373E-5, -0.00297355605, -0.00389793236, 1.85543409E-4, -0.00285018864, -0.00213649101, 0.00146558811, 0.00151711365, -0.0019227697, 0.0012727431, 3.21380212E-5, -0.0044287364, 0.00125187554, 1.75624344E-4, 0.00628813914, -0.00116188265, -7.29536929E-4, -0.00180051476, -0.00418251194, 4.21601289E-4, 0.00214284728, -5.72595745E-4, -0.00732150162, -0.00226626196, 0.00394018879]> : tensor<96xf32>
  %bottleneck_block_11_project_BatchNorm_gamma  = arith.constant dense<[1.99929357, 2.29257798, 3.06219077, 3.41785097, 2.24546742, 2.21359253, 2.0891664, 2.05895352, 2.34318137, 2.0890255, 2.21391416, 2.708400e+00, 2.43945622, 3.2084012, 2.56334686, 2.16595149, 2.38740277, 2.22562742, 4.2095809, 2.89505172, 3.7465868, 2.17351818, 3.95636868, 2.14238429, 3.24902773, 2.06369925, 2.62472486, 3.88336229, 2.64506841, 2.1402905, 2.14790916, 2.34767771, 2.40297675, 1.93260419, 2.19320035, 2.31809282, 2.004070e+00, 2.04782152, 2.29135394, 2.73409915, 2.34819961, 3.28277421, 2.18373704, 2.23675179, 2.69756293, 2.21542549, 2.13960123, 2.13323593, 3.29308915, 3.31167245, 3.16841221, 2.09413362, 2.197640e+00, 2.16421318, 2.78338933, 3.38245583, 2.14238501, 3.10082102, 2.56931543, 2.92209601, 2.822930e+00, 3.66426754, 2.1860733, 3.50220299, 2.01095438, 3.59902048, 2.58512115, 2.06240439, 2.26428366, 2.12105656, 3.85183573, 2.11970735, 2.70922279, 3.25828743, 3.15174842, 2.53221846, 1.98110259, 2.46699452, 2.70713568, 2.94393015, 2.34516788, 2.16346216, 4.06309366, 2.82496166, 3.19598126, 4.37761211, 2.34727287, 2.57199049, 1.82375717, 2.90415668, 3.30654693, 3.13561869, 2.42570066, 2.29822683, 2.015470e+00, 1.9186883]> : tensor<96xf32>
  %bottleneck_block_11_project_BatchNorm_moving_mean  = arith.constant dense<[-0.696096837, 0.103633314, -0.592202902, -2.08943558, -0.409571975, 0.188394144, -1.58808613, 2.43821311, -0.258466303, 0.362926632, 2.34552026, 0.783510982, -2.10632277, -1.4964807, -1.74501216, -0.690057516, -1.35529327, -1.11293864, 0.474933177, -0.286293745, 0.785476624, 0.565707207, -0.64007616, 1.29370689, -0.376152962, 0.615011573, 0.975451827, 0.656703948, -1.02739751, -1.47984266, -0.683403909, 0.148491383, 1.83246398, -1.01419866, -2.89966321, -0.512563765, 1.09055805, -1.02495086, 0.44139269, -0.087328732, 0.807940483, -0.606162369, 0.221164793, -0.764140188, 0.617159247, 1.73751307, -0.991132736, 1.52626181, 1.36680603, 0.381213665, 1.23739171, -0.677370727, -2.26676273, -0.706099272, 1.79423118, 0.420650214, 1.25175059, 0.980172634, 0.718025684, -0.370255649, -1.13295245, -1.07492387, 1.46596766, -3.08391666, 1.00192153, 3.33439374, 2.02496219, 0.925584316, 0.432539135, 1.11847234, -4.06817627, 1.98176074, 1.57874906, -2.55168056, -4.49103642, -2.58502173, -0.227786124, 0.575894833, 0.169988453, -1.04773533, -0.268364638, 2.47536206, -0.73134154, -0.887676239, -1.6933285, 0.864161253, -2.723230e-01, 3.02155519, -1.07705212, 1.17304862, 0.509576201, 1.79797053, -0.00520747434, -0.0873416587, 0.869105994, 1.29717231]> : tensor<96xf32>
  %bottleneck_block_11_project_BatchNorm_moving_variance  = arith.constant dense<[0.546545744, 0.686481297, 1.50096917, 2.08308768, 0.550752044, 0.554183364, 0.516450524, 0.516444564, 0.715580284, 0.571705401, 0.570343435, 0.943575441, 0.690594912, 1.81425202, 0.86608231, 0.518204629, 0.744644343, 0.583968878, 5.05016661, 1.22113776, 3.0504725, 0.606735646, 4.18767309, 0.559874773, 1.95125747, 0.489547938, 0.921764492, 3.95730543, 0.962697446, 5.333470e-01, 0.561033845, 0.656434298, 0.747837603, 0.445894748, 0.614447891, 0.643187582, 0.553866148, 0.561616361, 0.607680737, 1.09042513, 0.644380092, 1.76927042, 0.632828832, 0.61505407, 0.956487357, 0.591555655, 0.619051396, 0.608062446, 1.95929813, 1.98969615, 1.92301047, 0.53276217, 0.605584204, 0.525525928, 1.1988827, 2.13814092, 0.592370749, 1.61734569, 0.890471637, 1.28280163, 1.14276206, 2.63909173, 0.68373394, 2.86822581, 0.454088181, 2.67747068, 0.883796513, 0.476436734, 0.653018594, 0.503269315, 3.4726615, 0.544629514, 1.01875329, 1.81880677, 1.84354091, 0.847302079, 0.533751726, 0.777003943, 1.02780974, 1.2336446, 0.654808342, 0.572023273, 4.27663946, 1.0308007, 1.92214346, 5.51232529, 0.786587417, 0.871815145, 0.467649579, 1.37139118, 1.84989405, 1.63199151, 0.711324453, 0.729230523, 0.525800526, 0.527295828]> : tensor<96xf32>
  %bottleneck_block_11_project_weights  = arith.constant dense<1.0> : tensor<1x1x384x96xf32>
  %bottleneck_block_12_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_12_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_12_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_12_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_12_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x576x1xf32>
  %bottleneck_block_12_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_12_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_12_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_12_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_12_expand_weights  = arith.constant dense<1.0> : tensor<1x1x96x576xf32>
  %bottleneck_block_12_project_BatchNorm_beta  = arith.constant dense<[-0.00110509305, 0.00318432646, 0.00137408951, 2.60960573E-4, -5.1066064E-4, 0.00190932828, 6.55086187E-4, 4.87833822E-5, -6.34343246E-4, -0.00105381175, 6.77535863E-5, 0.00241911295, -0.00133574894, -7.25285558E-4, -6.67248329E-4, 3.41505976E-4, -2.92567624E-4, -3.13474913E-4, -5.22818627E-5, -9.5693604E-4, -4.7660264E-4, 0.00228427211, -0.00334612164, 6.92141824E-4, 8.48076597E-4, 7.26756523E-4, -3.66564782E-4, 0.00200567115, -8.16146203E-4, 1.64059929E-5, 5.14805142E-4, -0.00115083379, -0.00315096951, 3.24601977E-4, 0.00122222374, -0.00118464523, -0.00165296462, -0.00130562985, 4.52934444E-4, -9.38057666E-4, -0.00139887165, -0.00292073539, -9.00948246E-4, 4.57057758E-4, 8.91874311E-4, 0.00156790076, -4.78438189E-4, -0.00462378096, -4.42943623E-4, -1.29689637E-4, -0.0013687663, -0.0011471092, -2.49255128E-4, -0.00151503843, -0.00184448645, -0.00206342083, 2.99595213E-5, -0.00195056375, 0.00175111648, -8.915970e-04, -0.00137435901, -8.06410273E-4, -0.00234582974, 6.9230079E-4, -0.00131286215, -0.00128475868, 0.00124748109, -0.00149307842, 0.00237920671, -0.00144689763, -8.91715608E-5, -0.00102780305, -0.00211486174, -0.00196464336, 0.00132013788, -0.00158023601, -0.00184268516, 0.0021874425, -4.09895147E-4, -0.00174732832, 6.56639517E-4, -6.57374097E-4, -0.00361918448, 4.70086379E-4, 5.61889377E-4, 0.00423468556, 1.50966196E-4, -8.03458446E-4, -1.740790e-03, -0.0043122326, -0.0010865978, 0.00118971663, -0.00167468702, -0.00654628035, -0.00147088955, 8.97456601E-4]> : tensor<96xf32>
  %bottleneck_block_12_project_BatchNorm_gamma  = arith.constant dense<[2.07404613, 1.69344974, 0.919801771, 1.15948367, 2.39659405, 2.373230e+00, 1.8545121, 2.54417014, 2.05270505, 1.97427046, 2.39363241, 1.58096552, 2.58404613, 0.90192914, 1.616630e+00, 1.94424987, 1.8877176, 1.87843168, 0.781716585, 1.36067593, 0.7518996, 2.50671196, 0.667791187, 2.21117783, 1.07523119, 2.72824025, 1.71363938, 0.762381434, 1.0436573, 2.31621456, 2.11264157, 2.25504184, 2.5231564, 2.34497952, 2.65070748, 2.3018384, 2.13331985, 2.4959352, 2.55562139, 1.76987576, 1.92569685, 1.10902286, 2.56979418, 1.92629945, 1.48840547, 2.2596364, 2.46996236, 2.30821276, 1.25431287, 1.07680559, 0.817877054, 2.21652603, 2.43310118, 2.50688577, 1.524562, 0.808447301, 2.43721676, 1.25531292, 2.032410e+00, 0.774332165, 1.5984422, 0.752915621, 2.11925554, 0.868061184, 2.30795097, 0.700376212, 1.79565871, 2.12975836, 1.88950884, 2.13427234, 0.659382045, 2.26558566, 1.7818768, 1.03008533, 1.10346913, 1.64183056, 2.32775736, 1.74163151, 1.66720831, 1.59895623, 2.03236699, 2.46258545, 0.727916657, 1.46363091, 1.08447874, 0.641324937, 2.30252218, 1.77518463, 2.40165043, 0.923349142, 0.985091745, 0.984502434, 1.94136822, 2.12048769, 2.40192485, 2.53940892]> : tensor<96xf32>
  %bottleneck_block_12_project_BatchNorm_moving_mean  = arith.constant dense<[-0.160395473, -0.184203982, -0.150086045, -0.529564083, 1.0274483, 0.551825345, 0.927039921, -0.990446567, 0.218077302, 0.105461814, -0.903956175, 1.73793459, 0.420907915, 0.203208655, -0.532062471, 0.644741178, -1.02792537, -0.115823545, 0.91687268, -1.3924216, 0.555822849, -1.32974911, 2.03569603, -1.03781176, 0.0367189273, -2.05969024, 0.193310499, -0.464592516, -0.378951669, -0.524736464, -0.186341971, 7.601640e-01, 2.21895099, -0.891204655, -0.335304916, -0.369666964, 0.705542981, -1.39056087, 0.327093422, -0.377784163, 0.00931331701, 0.409581482, -0.329343736, 0.9294734, 0.87585479, 0.0098399613, 0.0469597206, -1.0471549, -0.0408768915, -0.0616654679, -0.140879765, -1.43229449, -0.226090237, -0.700067698, -0.528794229, 0.40845722, -0.49433735, 0.146966606, -1.15457928, -0.521970689, -0.614522576, -0.165837765, 1.35237908, -0.137210935, 0.210499391, -0.00747748232, -0.252388746, -0.0116865281, 0.0823973789, 0.159036934, -1.02299929, -0.159822702, -1.19879627, 0.219429553, -1.02396822, 0.610587298, -0.647192537, -0.745598912, 0.257633567, 0.159522966, 0.7779271, 0.524478614, 0.616605341, -0.399228364, -0.494428545, 1.7442193, -1.24356031, -0.0878095328, 0.151649475, -0.298553258, 0.220584244, -0.381827742, -0.585862279, -0.453098267, -0.522650957, 0.28549239]> : tensor<96xf32>
  %bottleneck_block_12_project_BatchNorm_moving_variance  = arith.constant dense<[0.219779909, 0.186755523, 0.126334623, 0.165422246, 0.279974818, 0.231963664, 0.167483523, 0.25410074, 0.223657295, 0.202373371, 0.238709211, 0.205686063, 0.272919029, 0.129256636, 0.178025767, 0.176432684, 0.208793372, 0.180907041, 0.159206554, 1.790960e-01, 0.131632477, 0.278602928, 0.12576662, 0.222449079, 0.15922536, 0.309649259, 0.197087318, 0.159999713, 0.123845071, 0.236104935, 0.212990016, 0.218469024, 0.28127709, 0.230788216, 0.274620384, 0.230335519, 0.217982069, 0.27376762, 0.323914498, 0.235445708, 0.196463287, 0.156978562, 0.328405231, 0.197785079, 0.156670481, 0.211767927, 0.263925135, 0.269202173, 0.201333061, 0.149103165, 0.119953416, 0.257711083, 0.255884916, 0.263846189, 0.201351777, 0.11405585, 0.279740363, 0.170154378, 0.227605045, 0.0954229385, 0.227790132, 0.107249103, 0.25393483, 0.167991668, 0.234159485, 0.117990687, 0.174404219, 0.191139713, 0.187474176, 0.191028908, 0.118187562, 0.233359963, 0.211851031, 0.133348897, 0.159035966, 0.169580147, 0.266600907, 0.212255612, 0.203238517, 0.189311981, 0.190374538, 0.251684695, 0.146233946, 0.165516451, 0.164231554, 0.143435732, 0.25447306, 0.210977092, 0.245103374, 0.121809512, 0.125270501, 0.134822115, 0.196661517, 0.258565485, 0.222074881, 0.277043283]> : tensor<96xf32>
  %bottleneck_block_12_project_weights  = arith.constant dense<1.0> : tensor<1x1x576x96xf32>
  %bottleneck_block_13_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_13_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_13_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_13_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_13_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x576x1xf32>
  %bottleneck_block_13_expand_BatchNorm_beta  = arith.constant dense<1.0> : tensor<576xf32>
  %bottleneck_block_13_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_13_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_13_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_13_expand_weights  = arith.constant dense<1.0> : tensor<1x1x96x576xf32>
  %bottleneck_block_13_project_BatchNorm_beta  = arith.constant dense<[-0.00143726449, 0.00135308097, 0.00137350603, -2.28230856E-4, -5.25867217E-4, 0.00170540332, 6.79499586E-4, 0.00148805487, -3.257895E-4, -8.41335349E-5, -7.45196943E-4, 0.0017134035, -8.37872619E-4, 6.02378859E-4, -1.62949073E-4, 0.00115985225, 3.34064709E-4, 0.001021081, -1.56746362E-4, -5.00390364E-4, -2.67150172E-4, 0.00277465885, -0.00228366442, 1.40462158E-4, -2.17477806E-4, 6.37253629E-4, 2.30452555E-4, 0.00206898013, -5.48234559E-4, -5.45460149E-4, 6.44361833E-4, 7.65905366E-4, -0.0038834929, 6.527210e-04, 7.46474077E-4, -0.00125304947, -0.00142518827, -0.00160949735, -7.16762152E-4, 9.19475395E-4, -0.001009222, -0.00355092483, -8.73079916E-5, 6.22154097E-4, 7.21708813E-4, 0.00178659253, -6.19921717E-4, -0.00327280909, -7.60794733E-4, -1.74892106E-4, -0.00162157917, 1.91903426E-4, -2.4870038E-4, -0.00145883404, -8.42963578E-4, 2.34278064E-4, 0.00114469475, -0.00137551047, 0.00179826748, 3.61063867E-4, -0.0014805533, -4.3923434E-4, -0.00217810553, -4.87579848E-4, -1.07838488E-4, -0.00166536635, 0.00129893085, 1.445260e-04, 7.60357187E-4, -7.460520e-04, -8.66618123E-4, -6.60914287E-4, -0.00190136582, 3.11096024E-4, 0.00149776833, -0.0010973108, -8.76485428E-4, 0.00191665359, 5.74223872E-4, -7.32821761E-4, 0.00118837308, 7.06325518E-4, -0.00215071347, 9.26773122E-4, -3.30115523E-4, 0.0045473068, 7.03498837E-4, -7.32063199E-4, -0.00192969502, -0.00316465856, 4.08829364E-4, 8.37879604E-4, -0.00106759067, -0.00554904249, 1.08573498E-4, -0.00130822032]> : tensor<96xf32>
  %bottleneck_block_13_project_BatchNorm_gamma  = arith.constant dense<[2.31163383, 2.12935901, 1.03898263, 1.28451717, 2.38642097, 2.27777457, 2.86574507, 2.42383337, 1.97618234, 2.34608102, 2.30618787, 1.57765198, 2.61020064, 0.994287788, 1.78044879, 2.47284937, 2.13457799, 2.49240422, 9.169380e-01, 1.45355189, 0.828644454, 2.81593633, 1.00573778, 3.2493937, 1.41240978, 2.60399437, 1.92747378, 0.875699818, 1.24377441, 2.8046937, 2.56608033, 2.4564271, 2.36197972, 2.90046668, 2.44853139, 2.73481822, 3.52470732, 2.69061518, 3.64173985, 1.79391813, 2.56995106, 1.20145524, 2.79372978, 2.23291421, 1.63063407, 2.64385128, 2.94608879, 3.05537796, 1.34049702, 1.23739827, 0.839056134, 2.89554882, 2.51309299, 2.5808053, 1.5466994, 0.913335919, 3.46975541, 1.4311223, 2.22633958, 0.867625475, 1.42411435, 0.969473302, 3.00471306, 1.00068307, 2.47431827, 0.780714213, 2.09962821, 2.4330616, 2.6412704, 2.75298548, 1.00338793, 2.59661269, 1.87948644, 1.26113379, 1.23167646, 2.0726366, 2.39675307, 2.12601233, 1.91669166, 1.6595422, 2.6616807, 2.54429841, 0.765616893, 1.68298721, 1.11041117, 1.06404185, 2.63899517, 2.04230094, 2.70525265, 1.15914428, 1.28621733, 1.20128965, 2.25760865, 2.07328653, 4.17447758, 2.82799315]> : tensor<96xf32>
  %bottleneck_block_13_project_BatchNorm_moving_mean  = arith.constant dense<[1.00109982, 0.639266908, -0.45019415, -0.188665107, 0.626417815, -0.314570874, -1.59644473, -0.153338566, 0.304532915, -0.644072533, 0.938882052, -0.418645769, 0.534505129, -0.544042468, 0.919247686, -1.06507814, 0.993837594, 0.41622287, 0.331483334, -0.18144682, 0.401779622, 0.00576624554, -0.181555495, -0.194370016, 0.134333014, -1.54011571, -1.34695768, -0.160348803, 0.513450861, 1.396650e+00, -0.728828907, -0.850042641, -0.190185145, -0.819826602, -1.13187206, 0.725804805, -0.0521289594, -0.168617874, 1.19222033, -0.701949239, 0.547474265, -0.515167594, -0.978964567, 0.47450307, 1.03299153, 0.0936731919, -0.0112812724, 0.582599163, -0.278748959, 1.52833486, -0.814209878, -1.98540759, -0.909707188, 0.565543413, -0.298692554, 0.206677347, 1.03434157, 0.0920667275, 0.369455636, -0.249580413, 0.394036025, 0.276590079, -1.28205752, 0.90979892, -0.206494212, -0.470487446, -0.623034775, 0.0635239631, 0.267757446, 0.277118713, -1.50590026, 0.831250369, 1.33088279, -1.09755802, 0.281722575, 0.454027563, -0.925882518, 1.04766715, -0.132491872, 0.283803612, 0.538782656, 0.234974861, -1.59540462, -1.07705271, 1.32434785, 0.360326856, -0.56740284, 0.23440969, 0.958619713, -0.268364519, -1.03438306, -0.00768793095, 0.394932926, -0.890087425, 0.948619425, -0.255844206]> : tensor<96xf32>
  %bottleneck_block_13_project_BatchNorm_moving_variance  = arith.constant dense<[0.10986495, 0.118442595, 0.076691635, 0.0935210735, 0.158178329, 0.101972111, 0.160915732, 0.117110647, 0.102086239, 0.131107524, 0.111337885, 0.0905585512, 0.141171038, 0.0708624795, 0.106005408, 1.271630e-01, 0.115958869, 0.128214747, 0.113552287, 0.104009472, 0.0808085203, 0.1480252, 0.130306348, 0.2089338, 0.119090647, 0.128263682, 0.134486273, 0.102836564, 0.0734332278, 0.135990307, 0.122058526, 0.114876054, 0.111835763, 0.165309176, 0.103736937, 0.140286669, 0.196322292, 0.131668508, 3.024700e-01, 0.110138133, 0.144410074, 0.103585385, 0.183144912, 0.117682822, 0.0975165143, 0.123203985, 0.174697012, 0.170596987, 0.111547783, 0.0958024635, 0.0704459101, 0.166908011, 0.121578477, 0.120068237, 0.101724781, 0.07581871, 0.216354907, 0.0996310561, 0.133621484, 0.0657711625, 0.0911353528, 0.085945487, 0.224059194, 0.104970664, 0.122560769, 0.0794243514, 0.118886285, 0.111050084, 0.150166333, 0.125091568, 0.11465358, 0.123907879, 0.125405878, 0.106115311, 0.0994838401, 0.129130974, 0.12250191, 0.128801256, 0.131878704, 0.102694832, 0.136303753, 0.125008598, 0.0910251662, 0.0921516865, 0.0924805924, 0.147532672, 0.134596974, 0.13250798, 0.130897745, 0.0961341038, 0.0955859124, 0.0963374972, 0.112811573, 0.114089042, 0.262813807, 0.158883676]> : tensor<96xf32>
  %bottleneck_block_13_project_weights  = arith.constant dense<1.0> : tensor<1x1x576x96xf32>
  %bottleneck_block_14_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_14_depthwise_BatchNorm_gamma  = arith.constant dense<1.0> : tensor<576xf32>
  %bottleneck_block_14_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_14_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_14_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x576x1xf32>
  %bottleneck_block_14_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_14_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_14_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_14_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<576xf32>
  %bottleneck_block_14_expand_weights  = arith.constant dense<1.0> : tensor<1x1x96x576xf32>
  %bottleneck_block_14_project_BatchNorm_beta  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_14_project_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_14_project_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_14_project_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_14_project_weights  = arith.constant dense<1.0> : tensor<1x1x576x160xf32>
  %bottleneck_block_15_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_15_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_15_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_15_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_15_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x960x1xf32>
  %bottleneck_block_15_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_15_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_15_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_15_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_15_expand_weights  = arith.constant dense<1.0> : tensor<1x1x160x960xf32>
  %bottleneck_block_15_project_BatchNorm_beta  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_15_project_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_15_project_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_15_project_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_15_project_weights  = arith.constant dense<1.0> : tensor<1x1x960x160xf32>
  %bottleneck_block_16_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_16_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_16_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_16_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_16_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x960x1xf32>
  %bottleneck_block_16_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_16_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_16_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_16_expand_BatchNorm_moving_variance  = arith.constant dense<1.0> : tensor<960xf32>
  %bottleneck_block_16_expand_weights  = arith.constant dense<1.0> : tensor<1x1x160x960xf32>
  %bottleneck_block_16_project_BatchNorm_beta  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_16_project_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_16_project_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_16_project_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<160xf32>
  %bottleneck_block_16_project_weights  = arith.constant dense<1.0> : tensor<1x1x960x160xf32>
  %bottleneck_block_17_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_17_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_17_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_17_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_17_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x960x1xf32>
  %bottleneck_block_17_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_17_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_17_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_17_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<960xf32>
  %bottleneck_block_17_expand_weights  = arith.constant dense<1.0> : tensor<1x1x160x960xf32>
  %bottleneck_block_17_project_BatchNorm_beta  = arith.constant dense<0.5> : tensor<320xf32>
  %bottleneck_block_17_project_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<320xf32>
  %bottleneck_block_17_project_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<320xf32>
  %bottleneck_block_17_project_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<320xf32>
  %bottleneck_block_17_project_weights  = arith.constant dense<1.0> : tensor<1x1x960x320xf32>
  %bottleneck_block_3_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_3_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_3_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_3_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_3_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x144x1xf32>
  %bottleneck_block_3_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_3_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_3_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_3_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_3_expand_weights  = arith.constant dense<1.0> : tensor<1x1x24x144xf32>
  %bottleneck_block_3_project_BatchNorm_beta  = arith.constant dense<[-1.10840097E-4, -0.00141254219, 0.00438215258, 0.00207087304, -0.00663679605, 0.00191197847, 0.00737526454, 1.73164037E-4, -6.35992037E-4, 0.00275248336, 7.60916504E-4, 0.00117976579, 6.76645141E-4, -0.00297800801, -4.90088947E-4, 0.00780288968, 0.00557349343, -0.00130244915, 0.00651422376, -0.00171459781, 0.00278353738, 0.00453276467, -1.31873239E-4, 0.00305115874]> : tensor<24xf32>
  %bottleneck_block_3_project_BatchNorm_gamma  = arith.constant dense<[5.76229954, 2.51489067, 4.26193428, 2.2371366, 5.91965103, 6.79239035, 3.59160161, 5.83146763, 4.58673382, 7.7472167, 1.44550216, 2.26339221, 5.42607594, 3.82572293, 3.18042898, 5.45825291, 3.48263955, 5.18568563, 2.97673035, 2.33244109, 3.07076764, 3.20989347, 6.87093448, 3.83162475]> : tensor<24xf32>
  %bottleneck_block_3_project_BatchNorm_moving_mean  = arith.constant dense<[-3.96336293, 2.09737301, -1.61835837, 1.52041399, -0.18146193, -0.057119254, -3.72119474, -3.58824778, 3.75655317, 4.35369873, -0.0731221884, -1.44981682, 1.41397214, 0.758293271, 3.97817302, -4.30173969, -2.21524858, -2.333020e+00, -3.54700232, -0.519831479, 1.54426193, 5.201015, 0.663312197, 2.41179705]> : tensor<24xf32>
  %bottleneck_block_3_project_BatchNorm_moving_variance  = arith.constant dense<[0.95581156, 0.606004715, 0.570896626, 0.625032663, 0.511951149, 0.557450473, 0.923527717, 0.921319246, 1.16179538, 1.58613586, 0.527518809, 0.630187154, 0.707579374, 1.05843091, 1.47940123, 0.551914275, 0.887054502, 0.578834116, 0.699196338, 0.438332766, 0.653797209, 1.07163823, 1.11183405, 0.921585977]> : tensor<24xf32>
  %bottleneck_block_3_project_weights  = arith.constant dense<1.0> : tensor<1x1x144x24xf32>
  %bottleneck_block_4_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_4_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_4_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_4_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_4_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x144x1xf32>
  %bottleneck_block_4_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_4_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_4_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_4_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<144xf32>
  %bottleneck_block_4_expand_weights  = arith.constant dense<1.0> : tensor<1x1x24x144xf32>
  %bottleneck_block_4_project_BatchNorm_beta  = arith.constant dense<[0.00370177161, 0.00140112988, -0.00258006691, -4.90564853E-4, -0.00194338919, -0.00100821897, -0.00258628698, -0.00350645371, 0.00907640717, -0.0020959985, 1.39014708E-4, -0.00111268973, -9.80948912E-4, 0.00695825461, -0.00497078476, 0.00176591193, -0.00278408849, 0.00182228943, 0.0029404934, 0.00307895313, 0.00124321983, -0.0019954734, 0.00266197207, -0.00263781031, 4.69803985E-4, -0.00317021576, -4.54732188E-4, 0.00199294137, -4.23086225E-4, -0.00592600182, -0.00172725448, -0.00458199251]> : tensor<32xf32>
  %bottleneck_block_4_project_BatchNorm_gamma  = arith.constant dense<[3.44014955, 4.70023918, 3.38617873, 3.1993928, 3.24505186, 4.02824259, 5.38114738, 4.56098557, 4.19177675, 2.86185169, 3.62831879, 3.62053823, 4.52435112, 6.72874069, 6.03186226, 3.26883149, 5.89848042, 2.48408413, 6.19413805, 2.76427889, 3.6751647, 5.63652945, 3.50008368, 5.05563927, 3.68668413, 3.85327148, 4.21535778, 3.72879195, 2.61883593, 4.05221796, 5.18505287, 3.53483343]> : tensor<32xf32>
  %bottleneck_block_4_project_BatchNorm_moving_mean  = arith.constant dense<[0.795696735, -1.93054271, -1.14781833, 1.21154499, -3.23717427, -0.0323888808, -1.29945791, 5.31799221, 4.023480e+00, 1.72272277, -0.934754371, 3.51991153, -1.53776038, 3.22588277, 1.06243479, -6.381750e-01, -0.560844779, 1.93213546, 2.55428743, 2.48952413, 1.11578977, 6.37846279, 3.54499769, -0.577093065, 0.179600447, 1.204230e+00, -2.4275074, 1.63844395, 0.709120929, 3.21487045, 1.90140057, 0.141144857]> : tensor<32xf32>
  %bottleneck_block_4_project_BatchNorm_moving_variance  = arith.constant dense<[0.567695677, 2.91223741, 0.672225773, 0.746465265, 0.84565252, 1.49146974, 3.76341486, 2.34898543, 1.48775458, 0.680753589, 0.758826851, 0.772321105, 1.79111481, 7.98738909, 5.47672796, 0.688363791, 5.22510099, 0.499254525, 5.72801876, 0.779977977, 0.926311194, 4.67590237, 0.840478182, 2.52708459, 0.840468168, 0.950435876, 1.45593941, 0.941489636, 0.49671644, 1.25347602, 3.6368475, 0.818802893]> : tensor<32xf32>
  %bottleneck_block_4_project_weights  = arith.constant dense<1.0> : tensor<1x1x144x32xf32>
  %bottleneck_block_5_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_5_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_5_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_5_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_5_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x192x1xf32>
  %bottleneck_block_5_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_5_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_5_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_5_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_5_expand_weights  = arith.constant dense<1.0> : tensor<1x1x32x192xf32>
  %bottleneck_block_5_project_BatchNorm_beta  = arith.constant dense<[0.00467124349, 0.00282153324, -0.00329607888, -0.00122506358, -0.00263784826, -0.00125799992, 0.00162221538, -0.00267972448, 0.0059132278, -0.00221901154, 3.23877524E-4, -1.13248665E-4, -0.0030574156, 0.0062084794, -0.00619219942, 2.5475254E-5, -0.00150896027, 8.29112891E-4, 0.00313016097, 0.00317869964, 9.33243718E-4, -0.00380914495, 0.0044361013, -0.0019827811, -0.00208673161, -0.00311034103, -0.00321591087, 3.16501479E-4, -0.00166306202, -0.00523890741, -1.99239323E-4, -0.00203576311]> : tensor<32xf32>
  %bottleneck_block_5_project_BatchNorm_gamma  = arith.constant dense<[2.21830726, 1.40422559, 1.80432284, 2.84071016, 4.25283861, 1.61321509, 1.8786447, 1.38188708, 1.69132471, 4.98737478, 1.65015268, 2.82802439, 1.59364593, 1.31450319, 1.54468906, 2.47650647, 1.53259623, 5.09514284, 1.19291008, 6.04661703, 1.56056058, 0.980811715, 2.18454075, 1.89124358, 1.80151296, 2.14044237, 1.2064898, 1.62399101, 4.68834543, 2.23199701, 1.2231909, 1.81795335]> : tensor<32xf32>
  %bottleneck_block_5_project_BatchNorm_moving_mean  = arith.constant dense<[-1.21328342, 0.136539102, -0.27421692, -1.67442536, -2.48573613, 0.803876757, -0.3611435, -0.576489091, -0.538041353, 1.17765093, -1.02831745, -1.83119619, -0.677886605, -0.283308953, -0.744996905, -1.28359962, 1.31708062, -2.77516961, -0.581726491, -0.210306048, 0.734397531, 0.684777856, -1.26875246, 1.41649175, -0.638263464, 0.507054567, -0.878227651, -0.63459444, 2.35203767, 0.573163509, 0.183927447, -0.891707479]> : tensor<32xf32>
  %bottleneck_block_5_project_BatchNorm_moving_variance  = arith.constant dense<[0.172181711, 0.226225376, 0.19817251, 0.347204804, 0.588174224, 0.227300778, 0.342914462, 0.251505405, 0.228975937, 0.608312904, 0.162419215, 0.354495347, 0.203028485, 0.295351207, 0.32876128, 0.309873492, 0.317863137, 0.841221511, 0.246222451, 1.00600207, 0.160762414, 0.165656641, 0.286288589, 0.304324746, 0.194241613, 0.248520181, 0.134569764, 0.157892913, 0.539770186, 0.319414288, 0.212281138, 0.189721987]> : tensor<32xf32>
  %bottleneck_block_5_project_weights  = arith.constant dense<1.0> : tensor<1x1x192x32xf32>
  %bottleneck_block_6_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_6_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_6_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_6_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_6_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x192x1xf32>
  %bottleneck_block_6_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_6_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_6_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_6_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_6_expand_weights  = arith.constant dense<1.0> : tensor<1x1x32x192xf32>
  %bottleneck_block_6_project_BatchNorm_beta  = arith.constant dense<[0.00331549835, 0.00271418295, -4.722370e-03, 1.21148136E-4, -0.00238861633, -0.00103763572, 0.00268932828, -0.0024911589, 0.00468819914, -8.61733569E-4, 1.88171893E-4, 0.00129603245, -0.00287071941, 0.00562018808, -5.512050e-03, 0.00130743755, -0.00205839355, 3.74711264E-4, 1.26477025E-4, -5.64672693E-4, -0.00115059153, -0.00240466953, 5.108800e-03, -0.00167679496, -7.5665809E-4, -0.00302729965, -0.00396680366, 6.08819362E-4, 9.11367897E-5, -0.00436137617, -0.00194745499, -0.00110441912]> : tensor<32xf32>
  %bottleneck_block_6_project_BatchNorm_gamma  = arith.constant dense<[1.77894831, 1.18283665, 2.95728254, 3.4536674, 2.69082975, 1.39005804, 1.4471823, 1.10844982, 1.30538666, 2.10301876, 1.73040295, 2.05216241, 1.1185354, 1.48521149, 1.21179867, 2.44878626, 1.32536864, 4.31447268, 1.36504471, 4.66759062, 1.96329963, 1.15665042, 2.14059734, 1.31270742, 2.36013246, 2.13760591, 1.38066745, 1.92120492, 5.728080e+00, 1.7702527, 0.919074892, 1.3574003]> : tensor<32xf32>
  %bottleneck_block_6_project_BatchNorm_moving_mean  = arith.constant dense<[-0.512240827, -0.151630074, -0.813071548, 0.330567181, -0.705060363, -0.104040444, 0.603873729, 0.386960953, 0.403344631, -0.498957038, 0.620678424, 0.0669822097, 0.308991611, 1.14828241, 0.39075458, 0.183489174, -1.92254579, -0.237477705, -1.22793019, 1.05685341, 0.115652762, 0.977336227, 1.74439573, -0.220874324, 0.753632485, 1.22318029, -0.789815962, 0.966464936, 2.48157954, -0.693826437, -0.0436951295, -0.0828595608]> : tensor<32xf32>
  %bottleneck_block_6_project_BatchNorm_moving_variance  = arith.constant dense<[0.134180784, 0.232987255, 0.346680313, 0.384693861, 0.358039558, 0.19275032, 0.262854099, 0.185167626, 0.186031818, 0.226655781, 0.186286375, 0.242159024, 0.138012692, 0.360847563, 0.262507498, 0.253161848, 0.298754394, 0.454458684, 0.33485049, 0.641799688, 0.235203028, 0.266524255, 0.291594416, 0.200588018, 0.296196163, 0.244976282, 0.173745349, 0.236852407, 0.728980422, 0.23946929, 0.176791772, 0.13602221]> : tensor<32xf32>
  %bottleneck_block_6_project_weights  = arith.constant dense<1.0> : tensor<1x1x192x32xf32>
  %bottleneck_block_7_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_7_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_7_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_7_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_7_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x192x1xf32>
  %bottleneck_block_7_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_7_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_7_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_7_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<192xf32>
  %bottleneck_block_7_expand_weights  = arith.constant dense<1.0> : tensor<1x1x32x192xf32>
  %bottleneck_block_7_project_BatchNorm_beta  = arith.constant dense<[6.92248228E-4, 0.00293073687, -0.00165135285, -1.95478045E-4, -0.00578329572, -0.00174898084, 0.00182868727, -4.48152015E-4, -0.00145365635, 0.00534256501, -0.0010513321, -0.00311013614, 3.50921327E-4, -0.00102315261, -0.0021040733, 7.07725849E-5, 0.00173121027, -0.00271164067, -1.202870e-03, 0.00375042832, 0.00499196677, 0.00112114497, 6.65688829E-4, -7.52479536E-5, -0.00357684633, 0.00368152582, 7.86582066E-4, 0.00316452445, 0.00198084977, 0.00205935235, 3.55589029E-4, -3.19437851E-4, -0.00209050043, 0.00468337256, 9.73574293E-4, 8.936080e-04, -0.00136271305, 3.1568663E-4, -0.00275958725, 4.14844952E-4, 8.57991326E-5, 0.00338769495, 0.00309932325, 7.36908347E-4, 4.34676185E-4, -8.01220536E-4, -0.00226487149, 9.00740444E-4, -2.16697415E-4, 4.409560e-03, -0.00157875416, 0.00124602567, 1.89704413E-4, 3.0786969E-4, -8.91055678E-5, -0.00317609776, -0.00153485255, 4.64336918E-4, -0.00252952613, -0.00188674359, -1.186070e-03, -8.10004305E-4, -0.00375156198, 9.75697942E-4]> : tensor<64xf32>
  %bottleneck_block_7_project_BatchNorm_gamma  = arith.constant dense<[4.09824753, 2.62230563, 3.94015431, 5.17866039, 3.36066365, 4.41226673, 2.34137535, 3.37077641, 2.36627722, 3.72152328, 2.6107657, 2.61275339, 4.38849735, 3.23991776, 1.94228828, 2.33268309, 6.07447052, 3.57753301, 2.35518265, 0.968925595, 3.52971363, 3.38143206, 3.0169909, 4.77587891, 3.94203043, 2.84581518, 1.65182674, 2.93426943, 2.74472141, 3.75923395, 1.84388518, 2.15077925, 3.5534482, 4.97301865, 2.34668326, 1.32701325, 4.17357683, 3.14039278, 4.57391119, 2.42452717, 2.43982434, 0.870895624, 4.13350153, 3.65940046, 3.73878264, 3.18394423, 3.51472282, 5.74171782, 2.02586675, 3.70908427, 1.46581161, 3.75219607, 3.87408328, 2.06245327, 5.20281649, 2.72664404, 1.82808304, 3.10110307, 2.56593347, 6.30745601, 3.92183733, 1.75574195, 5.765250e+00, 2.3406148]> : tensor<64xf32>
  %bottleneck_block_7_project_BatchNorm_moving_mean  = arith.constant dense<[4.92161703, -0.275739223, 0.754918694, -2.90305614, 0.00510624563, 3.64466596, -2.67862248, -1.94121015, -1.18049049, -3.206429, -1.51297069, -1.27631652, 0.569393039, 1.33628893, -0.239363417, 1.11434436, -0.251384437, -1.052320e+00, 0.947364032, -2.11099029, -6.11454964, -3.190860e+00, -0.995934665, -3.69956398, -1.98339975, 1.87921834, 1.67825818, 1.88850915, -0.142194748, -2.51514149, 1.27163804, 0.712305069, -3.05064368, -3.35466099, 2.14026308, 0.17314826, -1.36166286, -4.38712645, 2.02890682, -1.11897624, 0.0861594974, -0.40216276, -4.39339638, 0.293855786, 3.87285972, 2.33581948, -1.87716675, 3.18734813, -1.40052593, -0.428869128, 0.847130119, 1.26131225, -1.66069365, 0.468192637, -5.98988056, 0.441894054, 0.854168295, -0.227544516, -1.66157484, -5.49376392, -1.48557067, 0.677581489, -3.51338625, -1.08894229]> : tensor<64xf32>
  %bottleneck_block_7_project_BatchNorm_moving_variance  = arith.constant dense<[2.11041069, 0.599385321, 1.5626018, 4.53780222, 0.947822988, 2.46109509, 4.061630e-01, 0.911251604, 0.380416185, 1.28222024, 0.424102813, 5.120360e-01, 2.37755632, 0.874721884, 0.355885595, 0.33432579, 7.73017168, 1.13860071, 0.404718667, 0.175476685, 1.06717873, 0.852097213, 0.801472723, 3.09456301, 1.62029827, 0.644109904, 0.251345307, 0.505682528, 0.445923448, 1.30594468, 1.08391953, 0.333862841, 0.990256249, 4.23767042, 0.415303618, 0.187365562, 2.31051636, 0.729007422, 2.82389307, 0.408362865, 0.424417973, 0.318983436, 1.94143009, 1.18498313, 1.3161962, 0.63117516, 1.01762664, 6.51422501, 0.322261781, 1.28933394, 0.243390739, 1.36941767, 1.44313025, 0.366722584, 5.16192913, 0.572289646, 0.297204643, 0.789320349, 0.426051229, 10.7825956, 1.88068056, 0.309319675, 6.55933142, 0.419682503]> : tensor<64xf32>
  %bottleneck_block_7_project_weights  = arith.constant dense<1.0> : tensor<1x1x192x64xf32>
  %bottleneck_block_8_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_8_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_8_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_8_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_8_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x384x1xf32>
  %bottleneck_block_8_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_8_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_8_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_8_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_8_expand_weights  = arith.constant dense<1.0> : tensor<1x1x64x384xf32>
  %bottleneck_block_8_project_BatchNorm_beta  = arith.constant dense<[7.88287259E-4, 0.00153485814, 1.96401947E-4, -5.80901455E-4, -0.00408440363, -7.35991576E-4, 9.36789438E-4, -0.00188061956, -8.95112811E-4, 0.00356560037, -0.00213697692, -0.0020329461, -7.41349213E-5, -2.221350e-03, -0.00259904447, 4.02996753E-4, 3.38556245E-4, -0.00149816356, -0.0019974669, 0.00320882211, 0.00447141146, 2.17337481E-4, 2.12028517E-5, 0.00103784422, -0.00154945895, 0.0034333393, 0.00145661191, 0.00312017952, -2.96340528E-4, 0.00183497905, 7.74265325E-4, 6.69160741E-4, 7.50286417E-5, 0.00147678389, 6.91654626E-4, 0.00211672066, -0.00211168244, 3.7946066E-4, -0.00333778723, 0.00155049143, -4.75324283E-4, 0.00339181395, 0.00193425838, 3.88583634E-4, -2.53126229E-4, -0.00142692542, -0.00308711175, -3.75296164E-4, -2.23654337E-4, 0.00477918657, -0.00160683272, 9.12597752E-4, 0.00153446558, 5.272570e-04, -5.22802875E-4, -0.0025429409, -3.0813695E-4, 5.236090e-04, -9.37289966E-4, -0.00162703171, -4.81321244E-4, -8.47276475E-4, -0.004171276, 0.00120723434]> : tensor<64xf32>
  %bottleneck_block_8_project_BatchNorm_gamma  = arith.constant dense<[0.903783619, 1.12861264, 0.812810361, 0.687063813, 1.11833608, 0.695590078, 2.07691908, 1.02231312, 1.82621288, 0.934233486, 1.98974025, 1.7719481, 0.74889034, 1.20877135, 3.14546204, 2.3580358, 0.691895067, 0.997094631, 2.15631437, 5.12513304, 1.26306438, 1.08760631, 1.23444951, 0.693695903, 0.875986933, 2.16770768, 2.18894792, 1.41029596, 1.58128786, 9.803550e-01, 5.72090054, 2.55058861, 1.13700354, 0.665378809, 2.03316402, 3.09243774, 0.810298383, 1.84730828, 0.697325945, 2.67202353, 1.80694664, 5.28951788, 0.813038825, 0.913242518, 0.901372313, 1.52080214, 1.22075939, 0.617798328, 3.05554247, 0.990416407, 3.46506357, 0.949207842, 0.963535428, 3.49006653, 0.63292563, 2.01524448, 2.93463421, 1.50413418, 1.39740479, 6.829640e-01, 0.888263941, 3.38321352, 0.650289952, 2.30506539]> : tensor<64xf32>
  %bottleneck_block_8_project_BatchNorm_moving_mean  = arith.constant dense<[-0.381498158, 0.319742411, 0.120319843, -0.265123963, 0.0152540272, -0.140066415, 0.323179722, -0.176531062, -0.0823650285, 0.263178736, 0.476200312, -0.251358449, -0.0834666342, 0.354844332, 0.134441733, -0.705471635, -0.171222374, 0.399798453, -0.871947705, 0.180239379, -0.0967596396, 1.07268584, -0.501696348, 0.179437786, -0.2233776, 0.146031305, -0.0584448799, 0.191297829, -0.864466249, -0.461527854, 2.51370716, 0.885920286, -0.455879599, -0.0596643351, 0.535204589, -0.453963399, 0.56415534, 0.00588075211, -0.659347116, 0.615750909, 0.160614148, 1.36310506, -0.0568897687, -0.464205384, -0.328027189, -0.0440972932, 0.595461249, 0.0500435308, 0.570048153, 0.165251434, 0.0873261243, 0.656359612, 0.333421826, 0.210379347, -0.47091493, 0.19101359, -0.418135583, -0.0409084819, 0.679029881, -0.878257751, -5.590910e-01, -0.524053276, 0.0785976797, -0.131620035]> : tensor<64xf32>
  %bottleneck_block_8_project_BatchNorm_moving_variance  = arith.constant dense<[0.161627322, 0.131586209, 0.118589409, 0.140935495, 0.14959237, 0.121153586, 0.262805462, 0.137253582, 0.19457601, 0.138016671, 0.244044662, 0.21046412, 0.117927954, 0.171025828, 0.438970923, 0.221783444, 0.210242331, 0.133222863, 0.231221035, 1.43764269, 0.188949332, 0.149851039, 0.172813594, 0.133926988, 0.131872028, 0.261083513, 0.291001558, 0.150299445, 0.159508616, 0.156243667, 1.78576016, 0.364579618, 0.154997736, 0.152040273, 0.244196206, 0.329838812, 0.172417134, 0.269202709, 0.118551739, 0.286631614, 0.213982239, 1.23543191, 0.129203588, 0.120409831, 0.127616271, 0.178608209, 0.160047486, 0.154938757, 0.347175181, 0.135034278, 0.495823294, 0.148306578, 0.14453952, 0.481049299, 0.161263078, 0.236528575, 0.376507401, 0.184423566, 0.149643123, 0.257384926, 0.146675512, 0.466157913, 0.183106989, 0.339083731]> : tensor<64xf32>
  %bottleneck_block_8_project_weights  = arith.constant dense<1.0> : tensor<1x1x384x64xf32>
  %bottleneck_block_9_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_9_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_9_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_9_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_9_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x384x1xf32>
  %bottleneck_block_9_expand_BatchNorm_beta  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_9_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_9_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_9_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_9_expand_weights  = arith.constant dense<1.0> : tensor<1x1x64x384xf32>
  %bottleneck_block_9_project_BatchNorm_beta  = arith.constant dense<[9.40561876E-5, 0.00149285269, 0.00148805929, -3.89138353E-4, -0.00489914278, 3.21409054E-4, 7.39812268E-4, -0.00139508233, -0.00105923368, 0.0027884664, -0.00165233377, -0.00294918334, 0.00124332844, -0.00164524256, -0.00188454776, -6.27259142E-5, 0.00157436461, -0.00149503816, -0.0017636104, 0.00376999076, 0.00436559273, -6.55751864E-6, 4.86606441E-4, -3.58765479E-4, -0.00128436193, 0.00271697203, 0.00113442354, 0.0023829327, -6.74177645E-5, 0.00231783744, 6.16902253E-5, 2.76414678E-4, -4.38361458E-5, -2.31399958E-4, 6.513660e-04, 0.00137255993, -0.00107167289, 3.41189792E-4, -0.00268527819, 0.00259293895, -0.00144913222, 0.00289012142, 0.00268242368, 7.39048164E-6, -5.38115739E-4, -9.90374945E-4, -0.00403075526, 0.00158395385, -7.75725697E-4, 0.0033244323, -0.00130727096, 5.53068181E-4, 0.00217990484, 4.17438889E-4, 4.62874486E-5, -0.00169808464, -7.2690309E-4, 4.11560206E-4, -0.00121505221, -0.00116072397, -7.1085681E-4, -1.54601963E-4, -0.00252806023, 0.00206077425]> : tensor<64xf32>
  %bottleneck_block_9_project_BatchNorm_gamma  = arith.constant dense<[0.942582905, 2.65216708, 0.759456098, 0.861808657, 1.66040826, 0.953296482, 2.3614893, 1.09733593, 2.22773647, 1.26657391, 2.10873151, 2.04145813, 1.00628006, 1.17854476, 2.81732035, 2.326570e+00, 0.787487149, 1.28707433, 3.30671525, 3.56134248, 1.26581323, 1.12077034, 2.11882639, 0.904941797, 0.990650713, 2.33607388, 2.57165217, 1.23850453, 1.92586446, 1.29062557, 2.37102127, 2.11626554, 1.10044146, 0.718658745, 2.87190127, 3.32831049, 0.861841797, 1.52565074, 1.04902089, 2.53168178, 2.61981797, 2.5232234, 0.936123251, 1.27601755, 0.869254171, 1.46259224, 1.27947652, 0.917648554, 2.41259074, 1.01193273, 3.38403773, 0.971811413, 1.32293332, 2.75825357, 0.663071632, 2.05725145, 3.35664487, 1.59115565, 2.02319479, 0.78181523, 1.42645371, 3.88132405, 0.860671818, 2.45956779]> : tensor<64xf32>
  %bottleneck_block_9_project_BatchNorm_moving_mean  = arith.constant dense<[-0.440362811, -1.10109353, -0.373315632, 6.642350e-02, 0.385279536, -8.584380e-02, 0.13143757, -0.260275334, -0.349107504, 0.0213437565, -0.813891947, 0.301329374, 0.671902954, -0.283000112, 0.562124074, 0.966803848, 0.068089895, -0.0889555216, -0.519399405, -0.0484010354, 0.636344314, -0.588465452, 0.184605122, 0.0161526389, -0.674601197, 0.323734194, -0.86439395, -5.375710e-01, 0.253443778, -0.680881619, 0.863248944, 0.631370425, 0.140274271, 0.095040977, 0.401015818, -0.470354259, 0.452767283, 0.374023676, 0.249018103, 0.58620584, -0.746792912, -0.607475817, 0.633092046, -0.214467436, 0.0112061966, -0.415628642, -0.117741689, 0.094698146, 8.898380e-01, -0.126294509, -0.156630278, -0.0630371868, 0.151345238, 0.275589198, -0.178348735, 0.347400278, 0.358845025, -0.392247796, -0.40516758, -0.50088346, 0.840881347, -0.283749253, 0.207025662, 0.403472751]> : tensor<64xf32>
  %bottleneck_block_9_project_BatchNorm_moving_variance  = arith.constant dense<[0.14219445, 0.360149294, 0.0848607495, 0.138035238, 0.189302787, 0.14349398, 0.21262525, 0.110452004, 0.18442826, 0.146859437, 0.18775934, 0.17656225, 0.155189797, 0.123123586, 0.243447348, 0.168268234, 0.180892274, 0.145765528, 0.274982452, 0.489373744, 0.129505441, 0.108713515, 0.280194461, 0.14880541, 0.123293944, 0.207382441, 0.205465615, 0.100074202, 0.146896884, 0.164432883, 0.263276875, 0.195558637, 0.110284045, 0.121482082, 0.262405902, 0.272181183, 0.136200815, 0.137869745, 0.164208874, 0.186358064, 0.251157701, 0.299650759, 0.119559616, 0.146425277, 0.0984979867, 0.13639307, 0.127437562, 0.200403318, 0.168455407, 0.11136651, 0.292989105, 0.124229454, 0.152055815, 0.204870448, 0.13396138, 0.195587724, 0.272032499, 0.149255514, 0.197180152, 0.180370912, 0.226091564, 0.386197865, 0.182494894, 0.235217229]> : tensor<64xf32>
  %bottleneck_block_9_project_weights  = arith.constant dense<1.0> : tensor<1x1x384x64xf32>
  %bottleneck_block_10_depthwise_BatchNorm_beta  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_10_depthwise_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_10_depthwise_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_10_depthwise_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_10_depthwise_depthwise_weights  = arith.constant dense<1.0> : tensor<3x3x384x1xf32>
  %bottleneck_block_10_expand_BatchNorm_beta  = arith.constant dense<1.0> : tensor<384xf32>
  %bottleneck_block_10_expand_BatchNorm_gamma  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_10_expand_BatchNorm_moving_mean  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_10_expand_BatchNorm_moving_variance  = arith.constant dense<0.5> : tensor<384xf32>
  %bottleneck_block_10_expand_weights  = arith.constant dense<1.0> : tensor<1x1x64x384xf32>
  %bottleneck_block_10_project_BatchNorm_beta  = arith.constant dense<[0.0012460344, 0.00216071354, 7.64668337E-4, 7.33129506E-4, -0.00274707354, 3.37286474E-5, 3.74571158E-4, -5.17571752E-4, 3.24305496E-4, 0.00326926308, -0.00200215168, -0.00227618613, 0.00187921035, -0.00158316491, -0.00242142729, -5.59794833E-4, 0.00127907644, -0.00205093878, -0.0012049725, 0.00320026092, 0.00337433699, -0.00119141047, 7.57938891E-4, 4.35967086E-4, -0.00142430165, 0.00106051122, 4.56051202E-4, 0.00149333675, 0.00132515747, 0.00226504193, 2.03052259E-4, 9.44629078E-4, -4.98370791E-4, -8.92440904E-4, 4.41343756E-4, 5.79451036E-4, -6.85262959E-4, -6.88447792E-4, -0.00330180768, 0.00233211229, -0.00150087196, 0.00185121945, 0.00232016016, 8.33082187E-4, -2.78971187E-4, -0.00103451521, -0.00400561932, 0.00110856281, -1.61329197E-4, 0.00298276055, -0.00167266815, 9.26444249E-4, 0.00174618897, 7.23056204E-4, -5.74977952E-4, -0.0018740379, -0.00169817696, 2.55647203E-4, -0.0010612926, -0.00160679489, -0.00100565189, 1.93448373E-4, -0.00326280156, 8.20050714E-4]> : tensor<64xf32>
  %bottleneck_block_10_project_BatchNorm_gamma  = arith.constant dense<[0.824798524, 1.83405983, 0.771157801, 0.903619528, 1.3810935, 1.10527158, 1.96365845, 1.09310472, 2.31062555, 1.27998161, 1.69889379, 2.19726658, 1.10781121, 1.28051949, 2.83265591, 2.38957047, 0.980695307, 1.21326625, 3.14561558, 3.07468247, 1.02380049, 0.917705476, 1.59912956, 0.935236394, 0.82105273, 1.97261846, 3.78063369, 1.11594009, 1.858390e+00, 1.17259634, 2.47891665, 2.04268646, 1.07294714, 0.837881505, 2.59935832, 3.23960948, 0.917557835, 1.48168623, 1.02481186, 2.62003517, 2.37699699, 2.137520e+00, 1.03275311, 1.13030243, 1.01774192, 1.24086678, 0.994022607, 0.942208647, 2.86304951, 0.981932103, 3.272789, 1.13359344, 1.14384818, 2.61883569, 0.696251809, 1.83744848, 3.71029139, 1.50534022, 1.76339984, 0.959164738, 0.826022744, 3.4960711, 0.947622954, 2.26416016]> : tensor<64xf32>
  %bottleneck_block_10_project_BatchNorm_moving_mean  = arith.constant dense<[0.115088947, 0.185070708, 0.343737781, -0.424566954, -0.0960654392, -0.0109307775, 0.410115182, 0.0767833888, 0.684615493, 0.454419553, 0.771862745, -1.71504784, -1.06522417, 0.433285475, 0.473022252, 0.807321667, 0.609904348, 0.55491519, -0.185495391, -0.787615895, 0.251363128, 0.533298969, 0.212058187, -0.156211853, 0.204408571, -0.366432577, 0.587550104, -0.350687593, 0.100598402, 0.266816556, -0.951297104, 0.980450093, -0.083085224, -0.00563991815, -0.324171603, 0.604831338, -0.0604231209, 0.82368189, -0.526620746, 0.596073329, 0.0726610422, 0.108430684, -0.483571678, -0.27738145, 0.150955349, -0.0506194308, 0.0715780184, -1.2415117, 0.0902082324, 0.323953778, 0.806786179, -0.301751554, -0.414297402, -0.571648657, 0.0487779565, -0.331932962, 0.446591288, 0.596796036, 0.0473702811, -0.505222559, -0.345819592, 0.445110381, -0.0402634516, -1.14839041]> : tensor<64xf32>
  %bottleneck_block_10_project_BatchNorm_moving_variance  = arith.constant dense<[0.0969781801, 0.162956938, 0.0820329338, 0.148975372, 0.130608022, 0.15548262, 0.14069739, 0.102584533, 0.156498387, 0.132546768, 0.119584575, 0.17010881, 0.161594421, 0.12562643, 0.243083924, 0.146172181, 0.214886203, 0.115657091, 0.228507608, 0.363624573, 0.0985570996, 0.0762393102, 0.144886672, 0.145792812, 0.0961846932, 0.140986294, 0.279985338, 0.0771736279, 0.133273184, 0.121663556, 0.272020042, 0.174332529, 0.0987680852, 0.143089175, 0.185165435, 0.238022372, 0.13765426, 0.131401807, 0.147537231, 0.172201857, 0.168803737, 0.213481024, 0.129076958, 0.111269139, 0.127274364, 0.103862882, 0.0977269038, 0.199586406, 0.202797577, 0.101538293, 0.339413255, 0.147204652, 0.124885261, 0.2280761, 0.12715441, 0.144602776, 0.297043651, 0.125754327, 0.123597518, 0.248592913, 0.103439756, 0.325702369, 0.191316694, 0.176188529]> : tensor<64xf32>
  %bottleneck_block_10_project_weights  = arith.constant dense<1.0> : tensor<1x1x384x64xf32>
  
  %0 = tensor.empty() : tensor<1x224x224x3xf32>
  %1 = linalg.generic {indexing_maps = [#map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_17 : tensor<f32>) outs(%0 : tensor<1x224x224x3xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x224x224x3xf32>
  %2 = tensor.empty() : tensor<1x224x224x3xf32>
  %3 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%arg0, %1 : tensor<1x224x224x3xf32>, tensor<1x224x224x3xf32>) outs(%2 : tensor<1x224x224x3xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x224x224x3xf32>
  %4 = tensor.empty() : tensor<1x224x224x3xf32>
  %5 = linalg.generic {indexing_maps = [#map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_16 : tensor<f32>) outs(%4 : tensor<1x224x224x3xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x224x224x3xf32>
  %6 = tensor.empty() : tensor<1x224x224x3xf32>
  %7 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%3, %5 : tensor<1x224x224x3xf32>, tensor<1x224x224x3xf32>) outs(%6 : tensor<1x224x224x3xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x224x224x3xf32>
  
  // Layer 1 - Conv2D, 3x3, stride 2
  %8 = tensor.empty() : tensor<1x112x112x32xf32>
  %9 = linalg.fill ins(%cst : f32) outs(%8 : tensor<1x112x112x32xf32>) -> tensor<1x112x112x32xf32>
  %padded = tensor.pad %7 low[0, 0, 0, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x224x224x3xf32> to tensor<1x225x225x3xf32>
  %10 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%padded, %layer_1_conv_weights : tensor<1x225x225x3xf32>, tensor<3x3x3x32xf32>) outs(%9 : tensor<1x112x112x32xf32>) -> tensor<1x112x112x32xf32>
  %11 = tensor.empty() : tensor<32xf32>
  %12 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%layer_1_conv_BatchNorm_moving_variance, %cst_0 : tensor<32xf32>, tensor<32xf32>) outs(%11 : tensor<32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<32xf32>
  %13 = tensor.empty() : tensor<32xf32>
  %14 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%12 : tensor<32xf32>) outs(%13 : tensor<32xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<32xf32>
  %15 = tensor.empty() : tensor<1x112x112x32xf32>
  %16 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%layer_1_conv_BatchNorm_gamma : tensor<32xf32>) outs(%15 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x32xf32>
  %17 = tensor.empty() : tensor<1x112x112x32xf32>
  %18 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%layer_1_conv_BatchNorm_beta : tensor<32xf32>) outs(%17 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x32xf32>
  %19 = tensor.empty() : tensor<1x112x112x32xf32>
  %20 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%layer_1_conv_BatchNorm_moving_mean : tensor<32xf32>) outs(%19 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x32xf32>
  %21 = tensor.empty() : tensor<1x112x112x32xf32>
  %22 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%14 : tensor<32xf32>) outs(%21 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x32xf32>
  %23 = tensor.empty() : tensor<1x112x112x32xf32>
  %24 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%10, %20 : tensor<1x112x112x32xf32>, tensor<1x112x112x32xf32>) outs(%23 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x32xf32>
  %25 = tensor.empty() : tensor<1x112x112x32xf32>
  %26 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%24, %16 : tensor<1x112x112x32xf32>, tensor<1x112x112x32xf32>) outs(%25 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x32xf32>
  %27 = tensor.empty() : tensor<1x112x112x32xf32>
  %28 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%26, %22 : tensor<1x112x112x32xf32>, tensor<1x112x112x32xf32>) outs(%27 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x32xf32>
  %29 = tensor.empty() : tensor<1x112x112x32xf32>
  %30 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%28, %18 : tensor<1x112x112x32xf32>, tensor<1x112x112x32xf32>) outs(%29 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x32xf32>

  // ReLU6
  %31 = tensor.empty() : tensor<1x112x112x32xf32>
  %32 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %30, %cst_14 : tensor<f32>, tensor<1x112x112x32xf32>, tensor<f32>) outs(%31 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x112x112x32xf32>
  
  // Layer 2 - Bottleneck block 1 - depthwise Conv2D, 3x3, stride 1
  %padded_18 = tensor.pad %32 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x112x112x32xf32> to tensor<1x114x114x32xf32>
  %33 = tensor.empty() : tensor<1x112x112x32xf32>
  %34 = linalg.fill ins(%cst : f32) outs(%33 : tensor<1x112x112x32xf32>) -> tensor<1x112x112x32xf32>
  %collapsed = tensor.collapse_shape %bottleneck_block_1_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x32x1xf32> into tensor<3x3x32xf32>
  %35 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_18, %collapsed : tensor<1x114x114x32xf32>, tensor<3x3x32xf32>) outs(%34 : tensor<1x112x112x32xf32>) -> tensor<1x112x112x32xf32>
  %36 = tensor.empty() : tensor<32xf32>
  %37 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_1_depthwise_BatchNorm_moving_variance, %cst_0 : tensor<32xf32>, tensor<32xf32>) outs(%36 : tensor<32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<32xf32>
  %38 = tensor.empty() : tensor<32xf32>
  %39 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%37 : tensor<32xf32>) outs(%38 : tensor<32xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<32xf32>
  %40 = tensor.empty() : tensor<1x112x112x32xf32>
  %41 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_1_depthwise_BatchNorm_gamma : tensor<32xf32>) outs(%40 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x32xf32>
  %42 = tensor.empty() : tensor<1x112x112x32xf32>
  %43 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_1_depthwise_BatchNorm_beta : tensor<32xf32>) outs(%42 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x32xf32>
  %44 = tensor.empty() : tensor<1x112x112x32xf32>
  %45 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_1_depthwise_BatchNorm_moving_mean : tensor<32xf32>) outs(%44 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x32xf32>
  %46 = tensor.empty() : tensor<1x112x112x32xf32>
  %47 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%39 : tensor<32xf32>) outs(%46 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x32xf32>
  %48 = tensor.empty() : tensor<1x112x112x32xf32>
  %49 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%35, %45 : tensor<1x112x112x32xf32>, tensor<1x112x112x32xf32>) outs(%48 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x32xf32>
  %50 = tensor.empty() : tensor<1x112x112x32xf32>
  %51 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%49, %41 : tensor<1x112x112x32xf32>, tensor<1x112x112x32xf32>) outs(%50 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x32xf32>
  %52 = tensor.empty() : tensor<1x112x112x32xf32>
  %53 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%51, %47 : tensor<1x112x112x32xf32>, tensor<1x112x112x32xf32>) outs(%52 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x32xf32>
  %54 = tensor.empty() : tensor<1x112x112x32xf32>
  %55 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%53, %43 : tensor<1x112x112x32xf32>, tensor<1x112x112x32xf32>) outs(%54 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x32xf32>

  // ReLU6
  %56 = tensor.empty() : tensor<1x112x112x32xf32>
  %57 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %55, %cst_14 : tensor<f32>, tensor<1x112x112x32xf32>, tensor<f32>) outs(%56 : tensor<1x112x112x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x112x112x32xf32>
  
  // Layer 3 - Bottleneck block 1, second Conv2D, 1x1 filter, stride 1
  %58 = tensor.empty() : tensor<1x112x112x16xf32>
  %59 = linalg.fill ins(%cst : f32) outs(%58 : tensor<1x112x112x16xf32>) -> tensor<1x112x112x16xf32>
  %60 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%57, %bottleneck_block_1_project_weights : tensor<1x112x112x32xf32>, tensor<1x1x32x16xf32>) outs(%59 : tensor<1x112x112x16xf32>) -> tensor<1x112x112x16xf32>
  %61 = tensor.empty() : tensor<16xf32>
  %62 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_1_project_BatchNorm_moving_variance, %cst_1 : tensor<16xf32>, tensor<16xf32>) outs(%61 : tensor<16xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<16xf32>
  %63 = tensor.empty() : tensor<16xf32>
  %64 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%62 : tensor<16xf32>) outs(%63 : tensor<16xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<16xf32>
  %65 = tensor.empty() : tensor<1x112x112x16xf32>
  %66 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_1_project_BatchNorm_gamma : tensor<16xf32>) outs(%65 : tensor<1x112x112x16xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x16xf32>
  %67 = tensor.empty() : tensor<1x112x112x16xf32>
  %68 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_1_project_BatchNorm_beta : tensor<16xf32>) outs(%67 : tensor<1x112x112x16xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x16xf32>
  %69 = tensor.empty() : tensor<1x112x112x16xf32>
  %70 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_1_project_BatchNorm_moving_mean : tensor<16xf32>) outs(%69 : tensor<1x112x112x16xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x16xf32>
  %71 = tensor.empty() : tensor<1x112x112x16xf32>
  %72 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%64 : tensor<16xf32>) outs(%71 : tensor<1x112x112x16xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x16xf32>
  %73 = tensor.empty() : tensor<1x112x112x16xf32>
  %74 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%60, %70 : tensor<1x112x112x16xf32>, tensor<1x112x112x16xf32>) outs(%73 : tensor<1x112x112x16xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x16xf32>
  %75 = tensor.empty() : tensor<1x112x112x16xf32>
  %76 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%74, %66 : tensor<1x112x112x16xf32>, tensor<1x112x112x16xf32>) outs(%75 : tensor<1x112x112x16xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x16xf32>
  %77 = tensor.empty() : tensor<1x112x112x16xf32>
  %78 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%76, %72 : tensor<1x112x112x16xf32>, tensor<1x112x112x16xf32>) outs(%77 : tensor<1x112x112x16xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x16xf32>
  %79 = tensor.empty() : tensor<1x112x112x16xf32>
  %80 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%78, %68 : tensor<1x112x112x16xf32>, tensor<1x112x112x16xf32>) outs(%79 : tensor<1x112x112x16xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x16xf32>

  // Layer 4 - Bottleneck block 2, first Conv2D, 1x1 filter, stride 1
  %81 = tensor.empty() : tensor<1x112x112x96xf32>
  %82 = linalg.fill ins(%cst : f32) outs(%81 : tensor<1x112x112x96xf32>) -> tensor<1x112x112x96xf32>
  %83 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%80, %bottleneck_block_2_expand_weights : tensor<1x112x112x16xf32>, tensor<1x1x16x96xf32>) outs(%82 : tensor<1x112x112x96xf32>) -> tensor<1x112x112x96xf32>
  %84 = tensor.empty() : tensor<96xf32>
  %85 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_2_expand_BatchNorm_moving_variance, %cst_2 : tensor<96xf32>, tensor<96xf32>) outs(%84 : tensor<96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<96xf32>
  %86 = tensor.empty() : tensor<96xf32>
  %87 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%85 : tensor<96xf32>) outs(%86 : tensor<96xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<96xf32>
  %88 = tensor.empty() : tensor<1x112x112x96xf32>
  %89 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_2_expand_BatchNorm_gamma : tensor<96xf32>) outs(%88 : tensor<1x112x112x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x96xf32>
  %90 = tensor.empty() : tensor<1x112x112x96xf32>
  %91 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_2_expand_BatchNorm_beta : tensor<96xf32>) outs(%90 : tensor<1x112x112x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x96xf32>
  %92 = tensor.empty() : tensor<1x112x112x96xf32>
  %93 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_2_expand_BatchNorm_moving_mean : tensor<96xf32>) outs(%92 : tensor<1x112x112x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x96xf32>
  %94 = tensor.empty() : tensor<1x112x112x96xf32>
  %95 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%87 : tensor<96xf32>) outs(%94 : tensor<1x112x112x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x112x112x96xf32>
  %96 = tensor.empty() : tensor<1x112x112x96xf32>
  %97 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%83, %93 : tensor<1x112x112x96xf32>, tensor<1x112x112x96xf32>) outs(%96 : tensor<1x112x112x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x96xf32>
  %98 = tensor.empty() : tensor<1x112x112x96xf32>
  %99 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%97, %89 : tensor<1x112x112x96xf32>, tensor<1x112x112x96xf32>) outs(%98 : tensor<1x112x112x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x96xf32>
  %100 = tensor.empty() : tensor<1x112x112x96xf32>
  %101 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%99, %95 : tensor<1x112x112x96xf32>, tensor<1x112x112x96xf32>) outs(%100 : tensor<1x112x112x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x96xf32>
  %102 = tensor.empty() : tensor<1x112x112x96xf32>
  %103 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%101, %91 : tensor<1x112x112x96xf32>, tensor<1x112x112x96xf32>) outs(%102 : tensor<1x112x112x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x112x112x96xf32>

  // ReLU6
  %104 = tensor.empty() : tensor<1x112x112x96xf32>
  %105 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %103, %cst_14 : tensor<f32>, tensor<1x112x112x96xf32>, tensor<f32>) outs(%104 : tensor<1x112x112x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x112x112x96xf32>
  %padded_19 = tensor.pad %105 low[0, 0, 0, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x112x112x96xf32> to tensor<1x113x113x96xf32>

  // Layer 5 - Bottleneck block 2, depthwise Conv2D, 3x3, stride 2
  %106 = tensor.empty() : tensor<1x56x56x96xf32>
  %107 = linalg.fill ins(%cst : f32) outs(%106 : tensor<1x56x56x96xf32>) -> tensor<1x56x56x96xf32>
  %collapsed_20 = tensor.collapse_shape %bottleneck_block_2_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x96x1xf32> into tensor<3x3x96xf32>
  %108 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%padded_19, %collapsed_20 : tensor<1x113x113x96xf32>, tensor<3x3x96xf32>) outs(%107 : tensor<1x56x56x96xf32>) -> tensor<1x56x56x96xf32>
  %109 = tensor.empty() : tensor<96xf32>
  %110 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_2_depthwise_BatchNorm_moving_variance, %cst_2 : tensor<96xf32>, tensor<96xf32>) outs(%109 : tensor<96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<96xf32>
  %111 = tensor.empty() : tensor<96xf32>
  %112 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%110 : tensor<96xf32>) outs(%111 : tensor<96xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<96xf32>
  %113 = tensor.empty() : tensor<1x56x56x96xf32>
  %114 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_2_depthwise_BatchNorm_gamma : tensor<96xf32>) outs(%113 : tensor<1x56x56x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x96xf32>
  %115 = tensor.empty() : tensor<1x56x56x96xf32>
  %116 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_2_depthwise_BatchNorm_beta : tensor<96xf32>) outs(%115 : tensor<1x56x56x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x96xf32>
  %117 = tensor.empty() : tensor<1x56x56x96xf32>
  %118 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_2_depthwise_BatchNorm_moving_mean : tensor<96xf32>) outs(%117 : tensor<1x56x56x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x96xf32>
  %119 = tensor.empty() : tensor<1x56x56x96xf32>
  %120 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%112 : tensor<96xf32>) outs(%119 : tensor<1x56x56x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x96xf32>
  %121 = tensor.empty() : tensor<1x56x56x96xf32>
  %122 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%108, %118 : tensor<1x56x56x96xf32>, tensor<1x56x56x96xf32>) outs(%121 : tensor<1x56x56x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x96xf32>
  %123 = tensor.empty() : tensor<1x56x56x96xf32>
  %124 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%122, %114 : tensor<1x56x56x96xf32>, tensor<1x56x56x96xf32>) outs(%123 : tensor<1x56x56x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x96xf32>
  %125 = tensor.empty() : tensor<1x56x56x96xf32>
  %126 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%124, %120 : tensor<1x56x56x96xf32>, tensor<1x56x56x96xf32>) outs(%125 : tensor<1x56x56x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x96xf32>
  %127 = tensor.empty() : tensor<1x56x56x96xf32>
  %128 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%126, %116 : tensor<1x56x56x96xf32>, tensor<1x56x56x96xf32>) outs(%127 : tensor<1x56x56x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x96xf32>

  // ReLU6
  %129 = tensor.empty() : tensor<1x56x56x96xf32>
  %130 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %128, %cst_14 : tensor<f32>, tensor<1x56x56x96xf32>, tensor<f32>) outs(%129 : tensor<1x56x56x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x56x56x96xf32>

  // Layer 6 - Bottleneck block 2, second Conv2D, 1x1 filter, stride 1
  %131 = tensor.empty() : tensor<1x56x56x24xf32>
  %132 = linalg.fill ins(%cst : f32) outs(%131 : tensor<1x56x56x24xf32>) -> tensor<1x56x56x24xf32>
  %133 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%130, %bottleneck_block_2_project_weights : tensor<1x56x56x96xf32>, tensor<1x1x96x24xf32>) outs(%132 : tensor<1x56x56x24xf32>) -> tensor<1x56x56x24xf32>
  %134 = tensor.empty() : tensor<24xf32>
  %135 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_2_project_BatchNorm_moving_variance, %cst_3 : tensor<24xf32>, tensor<24xf32>) outs(%134 : tensor<24xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<24xf32>
  %136 = tensor.empty() : tensor<24xf32>
  %137 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%135 : tensor<24xf32>) outs(%136 : tensor<24xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<24xf32>
  %138 = tensor.empty() : tensor<1x56x56x24xf32>
  %139 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_2_project_BatchNorm_gamma : tensor<24xf32>) outs(%138 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x24xf32>
  %140 = tensor.empty() : tensor<1x56x56x24xf32>
  %141 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_2_project_BatchNorm_beta : tensor<24xf32>) outs(%140 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x24xf32>
  %142 = tensor.empty() : tensor<1x56x56x24xf32>
  %143 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_2_project_BatchNorm_moving_mean : tensor<24xf32>) outs(%142 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x24xf32>
  %144 = tensor.empty() : tensor<1x56x56x24xf32>
  %145 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%137 : tensor<24xf32>) outs(%144 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x24xf32>
  %146 = tensor.empty() : tensor<1x56x56x24xf32>
  %147 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%133, %143 : tensor<1x56x56x24xf32>, tensor<1x56x56x24xf32>) outs(%146 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x24xf32>
  %148 = tensor.empty() : tensor<1x56x56x24xf32>
  %149 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%147, %139 : tensor<1x56x56x24xf32>, tensor<1x56x56x24xf32>) outs(%148 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x24xf32>
  %150 = tensor.empty() : tensor<1x56x56x24xf32>
  %151 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%149, %145 : tensor<1x56x56x24xf32>, tensor<1x56x56x24xf32>) outs(%150 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x24xf32>
  %152 = tensor.empty() : tensor<1x56x56x24xf32>
  %153 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%151, %141 : tensor<1x56x56x24xf32>, tensor<1x56x56x24xf32>) outs(%152 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x24xf32>

  // Layer 7 - Bottleneck block 3, first Conv2D, 1x1 filter, stride 1
  %154 = tensor.empty() : tensor<1x56x56x144xf32>
  %155 = linalg.fill ins(%cst : f32) outs(%154 : tensor<1x56x56x144xf32>) -> tensor<1x56x56x144xf32>
  %156 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%153, %bottleneck_block_3_expand_weights : tensor<1x56x56x24xf32>, tensor<1x1x24x144xf32>) outs(%155 : tensor<1x56x56x144xf32>) -> tensor<1x56x56x144xf32>
  %157 = tensor.empty() : tensor<144xf32>
  %158 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_3_expand_BatchNorm_moving_variance, %cst_4 : tensor<144xf32>, tensor<144xf32>) outs(%157 : tensor<144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<144xf32>
  %159 = tensor.empty() : tensor<144xf32>
  %160 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%158 : tensor<144xf32>) outs(%159 : tensor<144xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<144xf32>
  %161 = tensor.empty() : tensor<1x56x56x144xf32>
  %162 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_3_expand_BatchNorm_gamma : tensor<144xf32>) outs(%161 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %163 = tensor.empty() : tensor<1x56x56x144xf32>
  %164 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_3_expand_BatchNorm_beta : tensor<144xf32>) outs(%163 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %165 = tensor.empty() : tensor<1x56x56x144xf32>
  %166 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_3_expand_BatchNorm_moving_mean : tensor<144xf32>) outs(%165 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %167 = tensor.empty() : tensor<1x56x56x144xf32>
  %168 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%160 : tensor<144xf32>) outs(%167 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %169 = tensor.empty() : tensor<1x56x56x144xf32>
  %170 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%156, %166 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%169 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>
  %171 = tensor.empty() : tensor<1x56x56x144xf32>
  %172 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%170, %162 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%171 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>
  %173 = tensor.empty() : tensor<1x56x56x144xf32>
  %174 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%172, %168 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%173 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>
  %175 = tensor.empty() : tensor<1x56x56x144xf32>
  %176 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%174, %164 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%175 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>

  // ReLU6
  %177 = tensor.empty() : tensor<1x56x56x144xf32>
  %178 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %176, %cst_14 : tensor<f32>, tensor<1x56x56x144xf32>, tensor<f32>) outs(%177 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x56x56x144xf32>
  %padded_21 = tensor.pad %178 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x56x56x144xf32> to tensor<1x58x58x144xf32>

  // Layer 8 - Bottleneck block 3, depthwise Conv2D, 3x3, stride 1
  %179 = tensor.empty() : tensor<1x56x56x144xf32>
  %180 = linalg.fill ins(%cst : f32) outs(%179 : tensor<1x56x56x144xf32>) -> tensor<1x56x56x144xf32>
  %collapsed_22 = tensor.collapse_shape %bottleneck_block_3_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x144x1xf32> into tensor<3x3x144xf32>
  %181 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_21, %collapsed_22 : tensor<1x58x58x144xf32>, tensor<3x3x144xf32>) outs(%180 : tensor<1x56x56x144xf32>) -> tensor<1x56x56x144xf32>
  %182 = tensor.empty() : tensor<144xf32>
  %183 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_3_depthwise_BatchNorm_moving_variance, %cst_4 : tensor<144xf32>, tensor<144xf32>) outs(%182 : tensor<144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<144xf32>
  %184 = tensor.empty() : tensor<144xf32>
  %185 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%183 : tensor<144xf32>) outs(%184 : tensor<144xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<144xf32>
  %186 = tensor.empty() : tensor<1x56x56x144xf32>
  %187 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_3_depthwise_BatchNorm_gamma : tensor<144xf32>) outs(%186 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %188 = tensor.empty() : tensor<1x56x56x144xf32>
  %189 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_3_depthwise_BatchNorm_beta : tensor<144xf32>) outs(%188 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %190 = tensor.empty() : tensor<1x56x56x144xf32>
  %191 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_3_depthwise_BatchNorm_moving_mean : tensor<144xf32>) outs(%190 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %192 = tensor.empty() : tensor<1x56x56x144xf32>
  %193 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%185 : tensor<144xf32>) outs(%192 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %194 = tensor.empty() : tensor<1x56x56x144xf32>
  %195 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%181, %191 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%194 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>
  %196 = tensor.empty() : tensor<1x56x56x144xf32>
  %197 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%195, %187 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%196 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>
  %198 = tensor.empty() : tensor<1x56x56x144xf32>
  %199 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%197, %193 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%198 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>
  %200 = tensor.empty() : tensor<1x56x56x144xf32>
  %201 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%199, %189 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%200 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>

  // ReLU6
  %202 = tensor.empty() : tensor<1x56x56x144xf32>
  %203 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %201, %cst_14 : tensor<f32>, tensor<1x56x56x144xf32>, tensor<f32>) outs(%202 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x56x56x144xf32>

  // Layer 9 - Bottleneck block 3, second Conv2D, 1x1 filter, stride 1
  %204 = tensor.empty() : tensor<1x56x56x24xf32>
  %205 = linalg.fill ins(%cst : f32) outs(%204 : tensor<1x56x56x24xf32>) -> tensor<1x56x56x24xf32>
  %206 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%203, %bottleneck_block_3_project_weights : tensor<1x56x56x144xf32>, tensor<1x1x144x24xf32>) outs(%205 : tensor<1x56x56x24xf32>) -> tensor<1x56x56x24xf32>
  %207 = tensor.empty() : tensor<24xf32>
  %208 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_3_project_BatchNorm_moving_variance, %cst_3 : tensor<24xf32>, tensor<24xf32>) outs(%207 : tensor<24xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<24xf32>
  %209 = tensor.empty() : tensor<24xf32>
  %210 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%208 : tensor<24xf32>) outs(%209 : tensor<24xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<24xf32>
  %211 = tensor.empty() : tensor<1x56x56x24xf32>
  %212 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_3_project_BatchNorm_gamma : tensor<24xf32>) outs(%211 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x24xf32>
  %213 = tensor.empty() : tensor<1x56x56x24xf32>
  %214 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_3_project_BatchNorm_beta : tensor<24xf32>) outs(%213 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x24xf32>
  %215 = tensor.empty() : tensor<1x56x56x24xf32>
  %216 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_3_project_BatchNorm_moving_mean : tensor<24xf32>) outs(%215 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x24xf32>
  %217 = tensor.empty() : tensor<1x56x56x24xf32>
  %218 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%210 : tensor<24xf32>) outs(%217 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x24xf32>
  %219 = tensor.empty() : tensor<1x56x56x24xf32>
  %220 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%206, %216 : tensor<1x56x56x24xf32>, tensor<1x56x56x24xf32>) outs(%219 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x24xf32>
  %221 = tensor.empty() : tensor<1x56x56x24xf32>
  %222 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%220, %212 : tensor<1x56x56x24xf32>, tensor<1x56x56x24xf32>) outs(%221 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x24xf32>
  %223 = tensor.empty() : tensor<1x56x56x24xf32>
  %224 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%222, %218 : tensor<1x56x56x24xf32>, tensor<1x56x56x24xf32>) outs(%223 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x24xf32>
  %225 = tensor.empty() : tensor<1x56x56x24xf32>
  %226 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%224, %214 : tensor<1x56x56x24xf32>, tensor<1x56x56x24xf32>) outs(%225 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x24xf32>
  %227 = tensor.empty() : tensor<1x56x56x24xf32>
  %228 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%226, %153 : tensor<1x56x56x24xf32>, tensor<1x56x56x24xf32>) outs(%227 : tensor<1x56x56x24xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x24xf32>

  // Layer 10 - Bottleneck block 4, first Conv2D, 1x1 filter, stride 1
  %229 = tensor.empty() : tensor<1x56x56x144xf32>
  %230 = linalg.fill ins(%cst : f32) outs(%229 : tensor<1x56x56x144xf32>) -> tensor<1x56x56x144xf32>
  %231 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%228, %bottleneck_block_4_expand_weights : tensor<1x56x56x24xf32>, tensor<1x1x24x144xf32>) outs(%230 : tensor<1x56x56x144xf32>) -> tensor<1x56x56x144xf32>
  %232 = tensor.empty() : tensor<144xf32>
  %233 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_4_expand_BatchNorm_moving_variance, %cst_4 : tensor<144xf32>, tensor<144xf32>) outs(%232 : tensor<144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<144xf32>
  %234 = tensor.empty() : tensor<144xf32>
  %235 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%233 : tensor<144xf32>) outs(%234 : tensor<144xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<144xf32>
  %236 = tensor.empty() : tensor<1x56x56x144xf32>
  %237 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_4_expand_BatchNorm_gamma : tensor<144xf32>) outs(%236 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %238 = tensor.empty() : tensor<1x56x56x144xf32>
  %239 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_4_expand_BatchNorm_beta : tensor<144xf32>) outs(%238 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %240 = tensor.empty() : tensor<1x56x56x144xf32>
  %241 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_4_expand_BatchNorm_moving_mean : tensor<144xf32>) outs(%240 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %242 = tensor.empty() : tensor<1x56x56x144xf32>
  %243 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%235 : tensor<144xf32>) outs(%242 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x56x56x144xf32>
  %244 = tensor.empty() : tensor<1x56x56x144xf32>
  %245 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%231, %241 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%244 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>
  %246 = tensor.empty() : tensor<1x56x56x144xf32>
  %247 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%245, %237 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%246 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>
  %248 = tensor.empty() : tensor<1x56x56x144xf32>
  %249 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%247, %243 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%248 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>
  %250 = tensor.empty() : tensor<1x56x56x144xf32>
  %251 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%249, %239 : tensor<1x56x56x144xf32>, tensor<1x56x56x144xf32>) outs(%250 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x56x56x144xf32>

  // ReLU6
  %252 = tensor.empty() : tensor<1x56x56x144xf32>
  %253 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %251, %cst_14 : tensor<f32>, tensor<1x56x56x144xf32>, tensor<f32>) outs(%252 : tensor<1x56x56x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x56x56x144xf32>
  %padded_23 = tensor.pad %253 low[0, 0, 0, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x56x56x144xf32> to tensor<1x57x57x144xf32>

  // Layer 11 - Bottleneck block 4, depthwise Conv2D, 3x3, stride 2
  %254 = tensor.empty() : tensor<1x28x28x144xf32>
  %255 = linalg.fill ins(%cst : f32) outs(%254 : tensor<1x28x28x144xf32>) -> tensor<1x28x28x144xf32>
  %collapsed_24 = tensor.collapse_shape %bottleneck_block_4_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x144x1xf32> into tensor<3x3x144xf32>
  %256 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%padded_23, %collapsed_24 : tensor<1x57x57x144xf32>, tensor<3x3x144xf32>) outs(%255 : tensor<1x28x28x144xf32>) -> tensor<1x28x28x144xf32>
  %257 = tensor.empty() : tensor<144xf32>
  %258 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_4_depthwise_BatchNorm_moving_variance, %cst_4 : tensor<144xf32>, tensor<144xf32>) outs(%257 : tensor<144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<144xf32>
  %259 = tensor.empty() : tensor<144xf32>
  %260 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%258 : tensor<144xf32>) outs(%259 : tensor<144xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<144xf32>
  %261 = tensor.empty() : tensor<1x28x28x144xf32>
  %262 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_4_depthwise_BatchNorm_gamma : tensor<144xf32>) outs(%261 : tensor<1x28x28x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x144xf32>
  %263 = tensor.empty() : tensor<1x28x28x144xf32>
  %264 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_4_depthwise_BatchNorm_beta : tensor<144xf32>) outs(%263 : tensor<1x28x28x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x144xf32>
  %265 = tensor.empty() : tensor<1x28x28x144xf32>
  %266 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_4_depthwise_BatchNorm_moving_mean : tensor<144xf32>) outs(%265 : tensor<1x28x28x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x144xf32>
  %267 = tensor.empty() : tensor<1x28x28x144xf32>
  %268 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%260 : tensor<144xf32>) outs(%267 : tensor<1x28x28x144xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x144xf32>
  %269 = tensor.empty() : tensor<1x28x28x144xf32>
  %270 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%256, %266 : tensor<1x28x28x144xf32>, tensor<1x28x28x144xf32>) outs(%269 : tensor<1x28x28x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x144xf32>
  %271 = tensor.empty() : tensor<1x28x28x144xf32>
  %272 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%270, %262 : tensor<1x28x28x144xf32>, tensor<1x28x28x144xf32>) outs(%271 : tensor<1x28x28x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x144xf32>
  %273 = tensor.empty() : tensor<1x28x28x144xf32>
  %274 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%272, %268 : tensor<1x28x28x144xf32>, tensor<1x28x28x144xf32>) outs(%273 : tensor<1x28x28x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x144xf32>
  %275 = tensor.empty() : tensor<1x28x28x144xf32>
  %276 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%274, %264 : tensor<1x28x28x144xf32>, tensor<1x28x28x144xf32>) outs(%275 : tensor<1x28x28x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x144xf32>

  // ReLU6
  %277 = tensor.empty() : tensor<1x28x28x144xf32>
  %278 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %276, %cst_14 : tensor<f32>, tensor<1x28x28x144xf32>, tensor<f32>) outs(%277 : tensor<1x28x28x144xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x28x28x144xf32>

  // Layer 12 - Bottleneck block 4, second Conv2D, 1x1 filter, stride 1
  %279 = tensor.empty() : tensor<1x28x28x32xf32>
  %280 = linalg.fill ins(%cst : f32) outs(%279 : tensor<1x28x28x32xf32>) -> tensor<1x28x28x32xf32>
  %281 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%278, %bottleneck_block_4_project_weights : tensor<1x28x28x144xf32>, tensor<1x1x144x32xf32>) outs(%280 : tensor<1x28x28x32xf32>) -> tensor<1x28x28x32xf32>
  %282 = tensor.empty() : tensor<32xf32>
  %283 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_4_project_BatchNorm_moving_variance, %cst_0 : tensor<32xf32>, tensor<32xf32>) outs(%282 : tensor<32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<32xf32>
  %284 = tensor.empty() : tensor<32xf32>
  %285 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%283 : tensor<32xf32>) outs(%284 : tensor<32xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<32xf32>
  %286 = tensor.empty() : tensor<1x28x28x32xf32>
  %287 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_4_project_BatchNorm_gamma : tensor<32xf32>) outs(%286 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %288 = tensor.empty() : tensor<1x28x28x32xf32>
  %289 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_4_project_BatchNorm_beta : tensor<32xf32>) outs(%288 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %290 = tensor.empty() : tensor<1x28x28x32xf32>
  %291 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_4_project_BatchNorm_moving_mean : tensor<32xf32>) outs(%290 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %292 = tensor.empty() : tensor<1x28x28x32xf32>
  %293 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%285 : tensor<32xf32>) outs(%292 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %294 = tensor.empty() : tensor<1x28x28x32xf32>
  %295 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%281, %291 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%294 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>
  %296 = tensor.empty() : tensor<1x28x28x32xf32>
  %297 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%295, %287 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%296 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>
  %298 = tensor.empty() : tensor<1x28x28x32xf32>
  %299 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%297, %293 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%298 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>
  %300 = tensor.empty() : tensor<1x28x28x32xf32>
  %301 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%299, %289 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%300 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>

  // Layer 13 - Bottleneck block 5, first Conv2D, 1x1 filter, stride 1
  %302 = tensor.empty() : tensor<1x28x28x192xf32>
  %303 = linalg.fill ins(%cst : f32) outs(%302 : tensor<1x28x28x192xf32>) -> tensor<1x28x28x192xf32>
  %304 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%301, %bottleneck_block_5_expand_weights : tensor<1x28x28x32xf32>, tensor<1x1x32x192xf32>) outs(%303 : tensor<1x28x28x192xf32>) -> tensor<1x28x28x192xf32>
  %305 = tensor.empty() : tensor<192xf32>
  %306 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_5_expand_BatchNorm_moving_variance, %cst_5 : tensor<192xf32>, tensor<192xf32>) outs(%305 : tensor<192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %307 = tensor.empty() : tensor<192xf32>
  %308 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%306 : tensor<192xf32>) outs(%307 : tensor<192xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %309 = tensor.empty() : tensor<1x28x28x192xf32>
  %310 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_5_expand_BatchNorm_gamma : tensor<192xf32>) outs(%309 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %311 = tensor.empty() : tensor<1x28x28x192xf32>
  %312 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_5_expand_BatchNorm_beta : tensor<192xf32>) outs(%311 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %313 = tensor.empty() : tensor<1x28x28x192xf32>
  %314 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_5_expand_BatchNorm_moving_mean : tensor<192xf32>) outs(%313 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %315 = tensor.empty() : tensor<1x28x28x192xf32>
  %316 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%308 : tensor<192xf32>) outs(%315 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %317 = tensor.empty() : tensor<1x28x28x192xf32>
  %318 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%304, %314 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%317 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %319 = tensor.empty() : tensor<1x28x28x192xf32>
  %320 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%318, %310 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%319 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %321 = tensor.empty() : tensor<1x28x28x192xf32>
  %322 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%320, %316 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%321 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %323 = tensor.empty() : tensor<1x28x28x192xf32>
  %324 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%322, %312 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%323 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>

  // ReLU6
  %325 = tensor.empty() : tensor<1x28x28x192xf32>
  %326 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %324, %cst_14 : tensor<f32>, tensor<1x28x28x192xf32>, tensor<f32>) outs(%325 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x28x28x192xf32>
  %padded_25 = tensor.pad %326 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x28x28x192xf32> to tensor<1x30x30x192xf32>

  // Layer 14 - Bottleneck block 5, depthwise Conv2D, 3x3, stride 1
  %327 = tensor.empty() : tensor<1x28x28x192xf32>
  %328 = linalg.fill ins(%cst : f32) outs(%327 : tensor<1x28x28x192xf32>) -> tensor<1x28x28x192xf32>
  %collapsed_26 = tensor.collapse_shape %bottleneck_block_5_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x192x1xf32> into tensor<3x3x192xf32>
  %329 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_25, %collapsed_26 : tensor<1x30x30x192xf32>, tensor<3x3x192xf32>) outs(%328 : tensor<1x28x28x192xf32>) -> tensor<1x28x28x192xf32>
  %330 = tensor.empty() : tensor<192xf32>
  %331 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_5_depthwise_BatchNorm_moving_variance, %cst_5 : tensor<192xf32>, tensor<192xf32>) outs(%330 : tensor<192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %332 = tensor.empty() : tensor<192xf32>
  %333 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%331 : tensor<192xf32>) outs(%332 : tensor<192xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %334 = tensor.empty() : tensor<1x28x28x192xf32>
  %335 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_5_depthwise_BatchNorm_gamma : tensor<192xf32>) outs(%334 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %336 = tensor.empty() : tensor<1x28x28x192xf32>
  %337 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_5_depthwise_BatchNorm_beta : tensor<192xf32>) outs(%336 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %338 = tensor.empty() : tensor<1x28x28x192xf32>
  %339 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_5_depthwise_BatchNorm_moving_mean : tensor<192xf32>) outs(%338 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %340 = tensor.empty() : tensor<1x28x28x192xf32>
  %341 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%333 : tensor<192xf32>) outs(%340 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %342 = tensor.empty() : tensor<1x28x28x192xf32>
  %343 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%329, %339 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%342 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %344 = tensor.empty() : tensor<1x28x28x192xf32>
  %345 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%343, %335 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%344 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %346 = tensor.empty() : tensor<1x28x28x192xf32>
  %347 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%345, %341 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%346 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %348 = tensor.empty() : tensor<1x28x28x192xf32>
  %349 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%347, %337 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%348 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>

  // ReLU6
  %350 = tensor.empty() : tensor<1x28x28x192xf32>
  %351 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %349, %cst_14 : tensor<f32>, tensor<1x28x28x192xf32>, tensor<f32>) outs(%350 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x28x28x192xf32>

  // Layer 15 - Bottleneck block 5, second Conv2D, 1x1 filter, stride 1
  %352 = tensor.empty() : tensor<1x28x28x32xf32>
  %353 = linalg.fill ins(%cst : f32) outs(%352 : tensor<1x28x28x32xf32>) -> tensor<1x28x28x32xf32>
  %354 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%351, %bottleneck_block_5_project_weights : tensor<1x28x28x192xf32>, tensor<1x1x192x32xf32>) outs(%353 : tensor<1x28x28x32xf32>) -> tensor<1x28x28x32xf32>
  %355 = tensor.empty() : tensor<32xf32>
  %356 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_5_project_BatchNorm_moving_variance, %cst_0 : tensor<32xf32>, tensor<32xf32>) outs(%355 : tensor<32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<32xf32>
  %357 = tensor.empty() : tensor<32xf32>
  %358 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%356 : tensor<32xf32>) outs(%357 : tensor<32xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<32xf32>
  %359 = tensor.empty() : tensor<1x28x28x32xf32>
  %360 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_5_project_BatchNorm_gamma : tensor<32xf32>) outs(%359 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %361 = tensor.empty() : tensor<1x28x28x32xf32>
  %362 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_5_project_BatchNorm_beta : tensor<32xf32>) outs(%361 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %363 = tensor.empty() : tensor<1x28x28x32xf32>
  %364 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_5_project_BatchNorm_moving_mean : tensor<32xf32>) outs(%363 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %365 = tensor.empty() : tensor<1x28x28x32xf32>
  %366 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%358 : tensor<32xf32>) outs(%365 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %367 = tensor.empty() : tensor<1x28x28x32xf32>
  %368 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%354, %364 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%367 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>
  %369 = tensor.empty() : tensor<1x28x28x32xf32>
  %370 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%368, %360 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%369 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>
  %371 = tensor.empty() : tensor<1x28x28x32xf32>
  %372 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%370, %366 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%371 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>
  %373 = tensor.empty() : tensor<1x28x28x32xf32>
  %374 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%372, %362 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%373 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>
  %375 = tensor.empty() : tensor<1x28x28x32xf32>
  %376 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%374, %301 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%375 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>

  // Layer 16 - Bottleneck block 6, first Conv2D, 1x1 filter, stride 1
  %377 = tensor.empty() : tensor<1x28x28x192xf32>
  %378 = linalg.fill ins(%cst : f32) outs(%377 : tensor<1x28x28x192xf32>) -> tensor<1x28x28x192xf32>
  %379 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%376, %bottleneck_block_6_expand_weights : tensor<1x28x28x32xf32>, tensor<1x1x32x192xf32>) outs(%378 : tensor<1x28x28x192xf32>) -> tensor<1x28x28x192xf32>
  %380 = tensor.empty() : tensor<192xf32>
  %381 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_6_expand_BatchNorm_moving_variance, %cst_5 : tensor<192xf32>, tensor<192xf32>) outs(%380 : tensor<192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %382 = tensor.empty() : tensor<192xf32>
  %383 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%381 : tensor<192xf32>) outs(%382 : tensor<192xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %384 = tensor.empty() : tensor<1x28x28x192xf32>
  %385 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_6_expand_BatchNorm_gamma : tensor<192xf32>) outs(%384 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %386 = tensor.empty() : tensor<1x28x28x192xf32>
  %387 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_6_expand_BatchNorm_beta : tensor<192xf32>) outs(%386 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %388 = tensor.empty() : tensor<1x28x28x192xf32>
  %389 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_6_expand_BatchNorm_moving_mean : tensor<192xf32>) outs(%388 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %390 = tensor.empty() : tensor<1x28x28x192xf32>
  %391 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%383 : tensor<192xf32>) outs(%390 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %392 = tensor.empty() : tensor<1x28x28x192xf32>
  %393 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%379, %389 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%392 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %394 = tensor.empty() : tensor<1x28x28x192xf32>
  %395 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%393, %385 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%394 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %396 = tensor.empty() : tensor<1x28x28x192xf32>
  %397 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%395, %391 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%396 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %398 = tensor.empty() : tensor<1x28x28x192xf32>
  %399 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%397, %387 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%398 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>

  // ReLU6
  %400 = tensor.empty() : tensor<1x28x28x192xf32>
  %401 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %399, %cst_14 : tensor<f32>, tensor<1x28x28x192xf32>, tensor<f32>) outs(%400 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x28x28x192xf32>
  %padded_27 = tensor.pad %401 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x28x28x192xf32> to tensor<1x30x30x192xf32>

  // Layer 17 - Bottleneck block 6, depthwise Conv2D, 3x3, stride 1
  %402 = tensor.empty() : tensor<1x28x28x192xf32>
  %403 = linalg.fill ins(%cst : f32) outs(%402 : tensor<1x28x28x192xf32>) -> tensor<1x28x28x192xf32>
  %collapsed_28 = tensor.collapse_shape %bottleneck_block_6_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x192x1xf32> into tensor<3x3x192xf32>
  %404 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_27, %collapsed_28 : tensor<1x30x30x192xf32>, tensor<3x3x192xf32>) outs(%403 : tensor<1x28x28x192xf32>) -> tensor<1x28x28x192xf32>
  %405 = tensor.empty() : tensor<192xf32>
  %406 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_6_depthwise_BatchNorm_moving_variance, %cst_5 : tensor<192xf32>, tensor<192xf32>) outs(%405 : tensor<192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %407 = tensor.empty() : tensor<192xf32>
  %408 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%406 : tensor<192xf32>) outs(%407 : tensor<192xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %409 = tensor.empty() : tensor<1x28x28x192xf32>
  %410 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_6_depthwise_BatchNorm_gamma : tensor<192xf32>) outs(%409 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %411 = tensor.empty() : tensor<1x28x28x192xf32>
  %412 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_6_depthwise_BatchNorm_beta : tensor<192xf32>) outs(%411 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %413 = tensor.empty() : tensor<1x28x28x192xf32>
  %414 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_6_depthwise_BatchNorm_moving_mean : tensor<192xf32>) outs(%413 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %415 = tensor.empty() : tensor<1x28x28x192xf32>
  %416 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%408 : tensor<192xf32>) outs(%415 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %417 = tensor.empty() : tensor<1x28x28x192xf32>
  %418 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%404, %414 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%417 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %419 = tensor.empty() : tensor<1x28x28x192xf32>
  %420 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%418, %410 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%419 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %421 = tensor.empty() : tensor<1x28x28x192xf32>
  %422 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%420, %416 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%421 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %423 = tensor.empty() : tensor<1x28x28x192xf32>
  %424 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%422, %412 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%423 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>

  // ReLU6
  %425 = tensor.empty() : tensor<1x28x28x192xf32>
  %426 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %424, %cst_14 : tensor<f32>, tensor<1x28x28x192xf32>, tensor<f32>) outs(%425 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x28x28x192xf32>

  // Layer 18 - Bottleneck block 6, second Conv2D, 1x1 filter, stride 1
  %427 = tensor.empty() : tensor<1x28x28x32xf32>
  %428 = linalg.fill ins(%cst : f32) outs(%427 : tensor<1x28x28x32xf32>) -> tensor<1x28x28x32xf32>
  %429 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%426, %bottleneck_block_6_project_weights : tensor<1x28x28x192xf32>, tensor<1x1x192x32xf32>) outs(%428 : tensor<1x28x28x32xf32>) -> tensor<1x28x28x32xf32>
  %430 = tensor.empty() : tensor<32xf32>
  %431 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_6_project_BatchNorm_moving_variance, %cst_0 : tensor<32xf32>, tensor<32xf32>) outs(%430 : tensor<32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<32xf32>
  %432 = tensor.empty() : tensor<32xf32>
  %433 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%431 : tensor<32xf32>) outs(%432 : tensor<32xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<32xf32>
  %434 = tensor.empty() : tensor<1x28x28x32xf32>
  %435 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_6_project_BatchNorm_gamma : tensor<32xf32>) outs(%434 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %436 = tensor.empty() : tensor<1x28x28x32xf32>
  %437 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_6_project_BatchNorm_beta : tensor<32xf32>) outs(%436 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %438 = tensor.empty() : tensor<1x28x28x32xf32>
  %439 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_6_project_BatchNorm_moving_mean : tensor<32xf32>) outs(%438 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %440 = tensor.empty() : tensor<1x28x28x32xf32>
  %441 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%433 : tensor<32xf32>) outs(%440 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x32xf32>
  %442 = tensor.empty() : tensor<1x28x28x32xf32>
  %443 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%429, %439 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%442 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>
  %444 = tensor.empty() : tensor<1x28x28x32xf32>
  %445 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%443, %435 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%444 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>
  %446 = tensor.empty() : tensor<1x28x28x32xf32>
  %447 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%445, %441 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%446 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>
  %448 = tensor.empty() : tensor<1x28x28x32xf32>
  %449 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%447, %437 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%448 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>
  %450 = tensor.empty() : tensor<1x28x28x32xf32>
  %451 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%449, %376 : tensor<1x28x28x32xf32>, tensor<1x28x28x32xf32>) outs(%450 : tensor<1x28x28x32xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x32xf32>

  // Layer 19 - Bottleneck block 7, first Conv2D, 1x1 filter, stride 1
  %452 = tensor.empty() : tensor<1x28x28x192xf32>
  %453 = linalg.fill ins(%cst : f32) outs(%452 : tensor<1x28x28x192xf32>) -> tensor<1x28x28x192xf32>
  %454 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%451, %bottleneck_block_7_expand_weights : tensor<1x28x28x32xf32>, tensor<1x1x32x192xf32>) outs(%453 : tensor<1x28x28x192xf32>) -> tensor<1x28x28x192xf32>
  %455 = tensor.empty() : tensor<192xf32>
  %456 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_7_expand_BatchNorm_moving_variance, %cst_5 : tensor<192xf32>, tensor<192xf32>) outs(%455 : tensor<192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %457 = tensor.empty() : tensor<192xf32>
  %458 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%456 : tensor<192xf32>) outs(%457 : tensor<192xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %459 = tensor.empty() : tensor<1x28x28x192xf32>
  %460 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_7_expand_BatchNorm_gamma : tensor<192xf32>) outs(%459 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %461 = tensor.empty() : tensor<1x28x28x192xf32>
  %462 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_7_expand_BatchNorm_beta : tensor<192xf32>) outs(%461 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %463 = tensor.empty() : tensor<1x28x28x192xf32>
  %464 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_7_expand_BatchNorm_moving_mean : tensor<192xf32>) outs(%463 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %465 = tensor.empty() : tensor<1x28x28x192xf32>
  %466 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%458 : tensor<192xf32>) outs(%465 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x28x28x192xf32>
  %467 = tensor.empty() : tensor<1x28x28x192xf32>
  %468 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%454, %464 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%467 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %469 = tensor.empty() : tensor<1x28x28x192xf32>
  %470 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%468, %460 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%469 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %471 = tensor.empty() : tensor<1x28x28x192xf32>
  %472 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%470, %466 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%471 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>
  %473 = tensor.empty() : tensor<1x28x28x192xf32>
  %474 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%472, %462 : tensor<1x28x28x192xf32>, tensor<1x28x28x192xf32>) outs(%473 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x28x28x192xf32>

  // ReLU6
  %475 = tensor.empty() : tensor<1x28x28x192xf32>
  %476 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %474, %cst_14 : tensor<f32>, tensor<1x28x28x192xf32>, tensor<f32>) outs(%475 : tensor<1x28x28x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x28x28x192xf32>
  %padded_29 = tensor.pad %476 low[0, 0, 0, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x28x28x192xf32> to tensor<1x29x29x192xf32>

  // Layer 20 - Bottleneck block 7, depthwise Conv2D, 3x3, stride 2
  %477 = tensor.empty() : tensor<1x14x14x192xf32>
  %478 = linalg.fill ins(%cst : f32) outs(%477 : tensor<1x14x14x192xf32>) -> tensor<1x14x14x192xf32>
  %collapsed_30 = tensor.collapse_shape %bottleneck_block_7_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x192x1xf32> into tensor<3x3x192xf32>
  %479 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%padded_29, %collapsed_30 : tensor<1x29x29x192xf32>, tensor<3x3x192xf32>) outs(%478 : tensor<1x14x14x192xf32>) -> tensor<1x14x14x192xf32>
  %480 = tensor.empty() : tensor<192xf32>
  %481 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_7_depthwise_BatchNorm_moving_variance, %cst_5 : tensor<192xf32>, tensor<192xf32>) outs(%480 : tensor<192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %482 = tensor.empty() : tensor<192xf32>
  %483 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%481 : tensor<192xf32>) outs(%482 : tensor<192xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<192xf32>
  %484 = tensor.empty() : tensor<1x14x14x192xf32>
  %485 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_7_depthwise_BatchNorm_gamma : tensor<192xf32>) outs(%484 : tensor<1x14x14x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x192xf32>
  %486 = tensor.empty() : tensor<1x14x14x192xf32>
  %487 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_7_depthwise_BatchNorm_beta : tensor<192xf32>) outs(%486 : tensor<1x14x14x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x192xf32>
  %488 = tensor.empty() : tensor<1x14x14x192xf32>
  %489 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_7_depthwise_BatchNorm_moving_mean : tensor<192xf32>) outs(%488 : tensor<1x14x14x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x192xf32>
  %490 = tensor.empty() : tensor<1x14x14x192xf32>
  %491 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%483 : tensor<192xf32>) outs(%490 : tensor<1x14x14x192xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x192xf32>
  %492 = tensor.empty() : tensor<1x14x14x192xf32>
  %493 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%479, %489 : tensor<1x14x14x192xf32>, tensor<1x14x14x192xf32>) outs(%492 : tensor<1x14x14x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x192xf32>
  %494 = tensor.empty() : tensor<1x14x14x192xf32>
  %495 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%493, %485 : tensor<1x14x14x192xf32>, tensor<1x14x14x192xf32>) outs(%494 : tensor<1x14x14x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x192xf32>
  %496 = tensor.empty() : tensor<1x14x14x192xf32>
  %497 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%495, %491 : tensor<1x14x14x192xf32>, tensor<1x14x14x192xf32>) outs(%496 : tensor<1x14x14x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x192xf32>
  %498 = tensor.empty() : tensor<1x14x14x192xf32>
  %499 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%497, %487 : tensor<1x14x14x192xf32>, tensor<1x14x14x192xf32>) outs(%498 : tensor<1x14x14x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x192xf32>

  // ReLU6
  %500 = tensor.empty() : tensor<1x14x14x192xf32>
  %501 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %499, %cst_14 : tensor<f32>, tensor<1x14x14x192xf32>, tensor<f32>) outs(%500 : tensor<1x14x14x192xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x192xf32>

  // Layer 21 - Bottleneck block 7, second Conv2D, 1x1 filter, stride 1
  %502 = tensor.empty() : tensor<1x14x14x64xf32>
  %503 = linalg.fill ins(%cst : f32) outs(%502 : tensor<1x14x14x64xf32>) -> tensor<1x14x14x64xf32>
  %504 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%501, %bottleneck_block_7_project_weights : tensor<1x14x14x192xf32>, tensor<1x1x192x64xf32>) outs(%503 : tensor<1x14x14x64xf32>) -> tensor<1x14x14x64xf32>
  %505 = tensor.empty() : tensor<64xf32>
  %506 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_7_project_BatchNorm_moving_variance, %cst_6 : tensor<64xf32>, tensor<64xf32>) outs(%505 : tensor<64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<64xf32>
  %507 = tensor.empty() : tensor<64xf32>
  %508 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%506 : tensor<64xf32>) outs(%507 : tensor<64xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<64xf32>
  %509 = tensor.empty() : tensor<1x14x14x64xf32>
  %510 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_7_project_BatchNorm_gamma : tensor<64xf32>) outs(%509 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %511 = tensor.empty() : tensor<1x14x14x64xf32>
  %512 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_7_project_BatchNorm_beta : tensor<64xf32>) outs(%511 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %513 = tensor.empty() : tensor<1x14x14x64xf32>
  %514 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_7_project_BatchNorm_moving_mean : tensor<64xf32>) outs(%513 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %515 = tensor.empty() : tensor<1x14x14x64xf32>
  %516 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%508 : tensor<64xf32>) outs(%515 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %517 = tensor.empty() : tensor<1x14x14x64xf32>
  %518 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%504, %514 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%517 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %519 = tensor.empty() : tensor<1x14x14x64xf32>
  %520 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%518, %510 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%519 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %521 = tensor.empty() : tensor<1x14x14x64xf32>
  %522 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%520, %516 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%521 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %523 = tensor.empty() : tensor<1x14x14x64xf32>
  %524 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%522, %512 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%523 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>

  // Layer 22 - Bottleneck block 8, first Conv2D, 1x1 filter, stride 1
  %525 = tensor.empty() : tensor<1x14x14x384xf32>
  %526 = linalg.fill ins(%cst : f32) outs(%525 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %527 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%524, %bottleneck_block_8_expand_weights : tensor<1x14x14x64xf32>, tensor<1x1x64x384xf32>) outs(%526 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %528 = tensor.empty() : tensor<384xf32>
  %529 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_8_expand_BatchNorm_moving_variance, %cst_7 : tensor<384xf32>, tensor<384xf32>) outs(%528 : tensor<384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %530 = tensor.empty() : tensor<384xf32>
  %531 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%529 : tensor<384xf32>) outs(%530 : tensor<384xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %532 = tensor.empty() : tensor<1x14x14x384xf32>
  %533 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_8_expand_BatchNorm_gamma : tensor<384xf32>) outs(%532 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %534 = tensor.empty() : tensor<1x14x14x384xf32>
  %535 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_8_expand_BatchNorm_beta : tensor<384xf32>) outs(%534 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %536 = tensor.empty() : tensor<1x14x14x384xf32>
  %537 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_8_expand_BatchNorm_moving_mean : tensor<384xf32>) outs(%536 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %538 = tensor.empty() : tensor<1x14x14x384xf32>
  %539 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%531 : tensor<384xf32>) outs(%538 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %540 = tensor.empty() : tensor<1x14x14x384xf32>
  %541 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%527, %537 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%540 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %542 = tensor.empty() : tensor<1x14x14x384xf32>
  %543 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%541, %533 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%542 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %544 = tensor.empty() : tensor<1x14x14x384xf32>
  %545 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%543, %539 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%544 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %546 = tensor.empty() : tensor<1x14x14x384xf32>
  %547 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%545, %535 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%546 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>

  // ReLU6
  %548 = tensor.empty() : tensor<1x14x14x384xf32>
  %549 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %547, %cst_14 : tensor<f32>, tensor<1x14x14x384xf32>, tensor<f32>) outs(%548 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x384xf32>
  %padded_31 = tensor.pad %549 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x14x14x384xf32> to tensor<1x16x16x384xf32>

  // Layer 23 - Bottleneck block 8, depthwise Conv2D, 3x3, stride 1
  %550 = tensor.empty() : tensor<1x14x14x384xf32>
  %551 = linalg.fill ins(%cst : f32) outs(%550 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %collapsed_32 = tensor.collapse_shape %bottleneck_block_8_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x384x1xf32> into tensor<3x3x384xf32>
  %552 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_31, %collapsed_32 : tensor<1x16x16x384xf32>, tensor<3x3x384xf32>) outs(%551 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %553 = tensor.empty() : tensor<384xf32>
  %554 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_8_depthwise_BatchNorm_moving_variance, %cst_7 : tensor<384xf32>, tensor<384xf32>) outs(%553 : tensor<384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %555 = tensor.empty() : tensor<384xf32>
  %556 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%554 : tensor<384xf32>) outs(%555 : tensor<384xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %557 = tensor.empty() : tensor<1x14x14x384xf32>
  %558 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_8_depthwise_BatchNorm_gamma : tensor<384xf32>) outs(%557 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %559 = tensor.empty() : tensor<1x14x14x384xf32>
  %560 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_8_depthwise_BatchNorm_beta : tensor<384xf32>) outs(%559 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %561 = tensor.empty() : tensor<1x14x14x384xf32>
  %562 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_8_depthwise_BatchNorm_moving_mean : tensor<384xf32>) outs(%561 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %563 = tensor.empty() : tensor<1x14x14x384xf32>
  %564 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%556 : tensor<384xf32>) outs(%563 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %565 = tensor.empty() : tensor<1x14x14x384xf32>
  %566 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%552, %562 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%565 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %567 = tensor.empty() : tensor<1x14x14x384xf32>
  %568 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%566, %558 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%567 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %569 = tensor.empty() : tensor<1x14x14x384xf32>
  %570 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%568, %564 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%569 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %571 = tensor.empty() : tensor<1x14x14x384xf32>
  %572 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%570, %560 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%571 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>

  // ReLU6
  %573 = tensor.empty() : tensor<1x14x14x384xf32>
  %574 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %572, %cst_14 : tensor<f32>, tensor<1x14x14x384xf32>, tensor<f32>) outs(%573 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x384xf32>

  // Layer 24 - Bottleneck block 8, second Conv2D, 1x1 filter, stride 1
  %575 = tensor.empty() : tensor<1x14x14x64xf32>
  %576 = linalg.fill ins(%cst : f32) outs(%575 : tensor<1x14x14x64xf32>) -> tensor<1x14x14x64xf32>
  %577 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%574, %bottleneck_block_8_project_weights : tensor<1x14x14x384xf32>, tensor<1x1x384x64xf32>) outs(%576 : tensor<1x14x14x64xf32>) -> tensor<1x14x14x64xf32>
  %578 = tensor.empty() : tensor<64xf32>
  %579 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_8_project_BatchNorm_moving_variance, %cst_6 : tensor<64xf32>, tensor<64xf32>) outs(%578 : tensor<64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<64xf32>
  %580 = tensor.empty() : tensor<64xf32>
  %581 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%579 : tensor<64xf32>) outs(%580 : tensor<64xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<64xf32>
  %582 = tensor.empty() : tensor<1x14x14x64xf32>
  %583 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_8_project_BatchNorm_gamma : tensor<64xf32>) outs(%582 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %584 = tensor.empty() : tensor<1x14x14x64xf32>
  %585 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_8_project_BatchNorm_beta : tensor<64xf32>) outs(%584 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %586 = tensor.empty() : tensor<1x14x14x64xf32>
  %587 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_8_project_BatchNorm_moving_mean : tensor<64xf32>) outs(%586 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %588 = tensor.empty() : tensor<1x14x14x64xf32>
  %589 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%581 : tensor<64xf32>) outs(%588 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %590 = tensor.empty() : tensor<1x14x14x64xf32>
  %591 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%577, %587 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%590 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %592 = tensor.empty() : tensor<1x14x14x64xf32>
  %593 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%591, %583 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%592 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %594 = tensor.empty() : tensor<1x14x14x64xf32>
  %595 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%593, %589 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%594 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %596 = tensor.empty() : tensor<1x14x14x64xf32>
  %597 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%595, %585 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%596 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %598 = tensor.empty() : tensor<1x14x14x64xf32>
  %599 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%597, %524 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%598 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>

  // Layer 25 - Bottleneck block 9, first Conv2D, 1x1 filter, stride 1
  %600 = tensor.empty() : tensor<1x14x14x384xf32>
  %601 = linalg.fill ins(%cst : f32) outs(%600 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %602 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%599, %bottleneck_block_9_expand_weights : tensor<1x14x14x64xf32>, tensor<1x1x64x384xf32>) outs(%601 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %603 = tensor.empty() : tensor<384xf32>
  %604 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_9_expand_BatchNorm_moving_variance, %cst_7 : tensor<384xf32>, tensor<384xf32>) outs(%603 : tensor<384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %605 = tensor.empty() : tensor<384xf32>
  %606 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%604 : tensor<384xf32>) outs(%605 : tensor<384xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %607 = tensor.empty() : tensor<1x14x14x384xf32>
  %608 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_9_expand_BatchNorm_gamma : tensor<384xf32>) outs(%607 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %609 = tensor.empty() : tensor<1x14x14x384xf32>
  %610 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_9_expand_BatchNorm_beta : tensor<384xf32>) outs(%609 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %611 = tensor.empty() : tensor<1x14x14x384xf32>
  %612 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_9_expand_BatchNorm_moving_mean : tensor<384xf32>) outs(%611 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %613 = tensor.empty() : tensor<1x14x14x384xf32>
  %614 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%606 : tensor<384xf32>) outs(%613 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %615 = tensor.empty() : tensor<1x14x14x384xf32>
  %616 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%602, %612 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%615 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %617 = tensor.empty() : tensor<1x14x14x384xf32>
  %618 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%616, %608 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%617 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %619 = tensor.empty() : tensor<1x14x14x384xf32>
  %620 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%618, %614 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%619 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %621 = tensor.empty() : tensor<1x14x14x384xf32>
  %622 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%620, %610 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%621 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>

  // ReLU6
  %623 = tensor.empty() : tensor<1x14x14x384xf32>
  %624 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %622, %cst_14 : tensor<f32>, tensor<1x14x14x384xf32>, tensor<f32>) outs(%623 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x384xf32>
  %padded_33 = tensor.pad %624 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x14x14x384xf32> to tensor<1x16x16x384xf32>

  // Layer 26 - Bottleneck block 9, depthwise Conv2D, 3x3, stride 1
  %625 = tensor.empty() : tensor<1x14x14x384xf32>
  %626 = linalg.fill ins(%cst : f32) outs(%625 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %collapsed_34 = tensor.collapse_shape %bottleneck_block_9_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x384x1xf32> into tensor<3x3x384xf32>
  %627 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_33, %collapsed_34 : tensor<1x16x16x384xf32>, tensor<3x3x384xf32>) outs(%626 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %628 = tensor.empty() : tensor<384xf32>
  %629 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_9_depthwise_BatchNorm_moving_variance, %cst_7 : tensor<384xf32>, tensor<384xf32>) outs(%628 : tensor<384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %630 = tensor.empty() : tensor<384xf32>
  %631 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%629 : tensor<384xf32>) outs(%630 : tensor<384xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %632 = tensor.empty() : tensor<1x14x14x384xf32>
  %633 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_9_depthwise_BatchNorm_gamma : tensor<384xf32>) outs(%632 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %634 = tensor.empty() : tensor<1x14x14x384xf32>
  %635 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_9_depthwise_BatchNorm_beta : tensor<384xf32>) outs(%634 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %636 = tensor.empty() : tensor<1x14x14x384xf32>
  %637 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_9_depthwise_BatchNorm_moving_mean : tensor<384xf32>) outs(%636 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %638 = tensor.empty() : tensor<1x14x14x384xf32>
  %639 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%631 : tensor<384xf32>) outs(%638 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %640 = tensor.empty() : tensor<1x14x14x384xf32>
  %641 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%627, %637 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%640 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %642 = tensor.empty() : tensor<1x14x14x384xf32>
  %643 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%641, %633 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%642 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %644 = tensor.empty() : tensor<1x14x14x384xf32>
  %645 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%643, %639 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%644 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %646 = tensor.empty() : tensor<1x14x14x384xf32>
  %647 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%645, %635 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%646 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>

  // ReLU6
  %648 = tensor.empty() : tensor<1x14x14x384xf32>
  %649 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %647, %cst_14 : tensor<f32>, tensor<1x14x14x384xf32>, tensor<f32>) outs(%648 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x384xf32>

  // Layer 27 - Bottleneck block 9, second Conv2D, 1x1 filter, stride 1
  %650 = tensor.empty() : tensor<1x14x14x64xf32>
  %651 = linalg.fill ins(%cst : f32) outs(%650 : tensor<1x14x14x64xf32>) -> tensor<1x14x14x64xf32>
  %652 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%649, %bottleneck_block_9_project_weights : tensor<1x14x14x384xf32>, tensor<1x1x384x64xf32>) outs(%651 : tensor<1x14x14x64xf32>) -> tensor<1x14x14x64xf32>
  %653 = tensor.empty() : tensor<64xf32>
  %654 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_9_project_BatchNorm_moving_variance, %cst_6 : tensor<64xf32>, tensor<64xf32>) outs(%653 : tensor<64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<64xf32>
  %655 = tensor.empty() : tensor<64xf32>
  %656 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%654 : tensor<64xf32>) outs(%655 : tensor<64xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<64xf32>
  %657 = tensor.empty() : tensor<1x14x14x64xf32>
  %658 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_9_project_BatchNorm_gamma : tensor<64xf32>) outs(%657 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %659 = tensor.empty() : tensor<1x14x14x64xf32>
  %660 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_9_project_BatchNorm_beta : tensor<64xf32>) outs(%659 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %661 = tensor.empty() : tensor<1x14x14x64xf32>
  %662 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_9_project_BatchNorm_moving_mean : tensor<64xf32>) outs(%661 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %663 = tensor.empty() : tensor<1x14x14x64xf32>
  %664 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%656 : tensor<64xf32>) outs(%663 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %665 = tensor.empty() : tensor<1x14x14x64xf32>
  %666 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%652, %662 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%665 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %667 = tensor.empty() : tensor<1x14x14x64xf32>
  %668 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%666, %658 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%667 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %669 = tensor.empty() : tensor<1x14x14x64xf32>
  %670 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%668, %664 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%669 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %671 = tensor.empty() : tensor<1x14x14x64xf32>
  %672 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%670, %660 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%671 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %673 = tensor.empty() : tensor<1x14x14x64xf32>
  %674 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%672, %599 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%673 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>

  // Layer 28 - Bottleneck block 10, first Conv2D, 1x1 filter, stride 1
  %675 = tensor.empty() : tensor<1x14x14x384xf32>
  %676 = linalg.fill ins(%cst : f32) outs(%675 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %677 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%674, %bottleneck_block_10_expand_weights : tensor<1x14x14x64xf32>, tensor<1x1x64x384xf32>) outs(%676 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %678 = tensor.empty() : tensor<384xf32>
  %679 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_10_expand_BatchNorm_moving_variance, %cst_7 : tensor<384xf32>, tensor<384xf32>) outs(%678 : tensor<384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %680 = tensor.empty() : tensor<384xf32>
  %681 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%679 : tensor<384xf32>) outs(%680 : tensor<384xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %682 = tensor.empty() : tensor<1x14x14x384xf32>
  %683 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_10_expand_BatchNorm_gamma : tensor<384xf32>) outs(%682 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %684 = tensor.empty() : tensor<1x14x14x384xf32>
  %685 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_10_expand_BatchNorm_beta : tensor<384xf32>) outs(%684 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %686 = tensor.empty() : tensor<1x14x14x384xf32>
  %687 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_10_expand_BatchNorm_moving_mean : tensor<384xf32>) outs(%686 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %688 = tensor.empty() : tensor<1x14x14x384xf32>
  %689 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%681 : tensor<384xf32>) outs(%688 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %690 = tensor.empty() : tensor<1x14x14x384xf32>
  %691 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%677, %687 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%690 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %692 = tensor.empty() : tensor<1x14x14x384xf32>
  %693 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%691, %683 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%692 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %694 = tensor.empty() : tensor<1x14x14x384xf32>
  %695 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%693, %689 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%694 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %696 = tensor.empty() : tensor<1x14x14x384xf32>
  %697 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%695, %685 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%696 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>

  // ReLU6
  %698 = tensor.empty() : tensor<1x14x14x384xf32>
  %699 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %697, %cst_14 : tensor<f32>, tensor<1x14x14x384xf32>, tensor<f32>) outs(%698 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x384xf32>
  %padded_35 = tensor.pad %699 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x14x14x384xf32> to tensor<1x16x16x384xf32>

  // Layer 29 - Bottleneck block 10, depthwise Conv2D, 3x3, stride 1
  %700 = tensor.empty() : tensor<1x14x14x384xf32>
  %701 = linalg.fill ins(%cst : f32) outs(%700 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %collapsed_36 = tensor.collapse_shape %bottleneck_block_10_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x384x1xf32> into tensor<3x3x384xf32>
  %702 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_35, %collapsed_36 : tensor<1x16x16x384xf32>, tensor<3x3x384xf32>) outs(%701 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %703 = tensor.empty() : tensor<384xf32>
  %704 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_10_depthwise_BatchNorm_moving_variance, %cst_7 : tensor<384xf32>, tensor<384xf32>) outs(%703 : tensor<384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %705 = tensor.empty() : tensor<384xf32>
  %706 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%704 : tensor<384xf32>) outs(%705 : tensor<384xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %707 = tensor.empty() : tensor<1x14x14x384xf32>
  %708 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_10_depthwise_BatchNorm_gamma : tensor<384xf32>) outs(%707 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %709 = tensor.empty() : tensor<1x14x14x384xf32>
  %710 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_10_depthwise_BatchNorm_beta : tensor<384xf32>) outs(%709 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %711 = tensor.empty() : tensor<1x14x14x384xf32>
  %712 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_10_depthwise_BatchNorm_moving_mean : tensor<384xf32>) outs(%711 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %713 = tensor.empty() : tensor<1x14x14x384xf32>
  %714 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%706 : tensor<384xf32>) outs(%713 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %715 = tensor.empty() : tensor<1x14x14x384xf32>
  %716 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%702, %712 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%715 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %717 = tensor.empty() : tensor<1x14x14x384xf32>
  %718 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%716, %708 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%717 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %719 = tensor.empty() : tensor<1x14x14x384xf32>
  %720 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%718, %714 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%719 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %721 = tensor.empty() : tensor<1x14x14x384xf32>
  %722 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%720, %710 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%721 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>

  // ReLU6
  %723 = tensor.empty() : tensor<1x14x14x384xf32>
  %724 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %722, %cst_14 : tensor<f32>, tensor<1x14x14x384xf32>, tensor<f32>) outs(%723 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x384xf32>

  // Layer 30 - Bottleneck block 10, second Conv2D, 1x1 filter, stride 1
  %725 = tensor.empty() : tensor<1x14x14x64xf32>
  %726 = linalg.fill ins(%cst : f32) outs(%725 : tensor<1x14x14x64xf32>) -> tensor<1x14x14x64xf32>
  %727 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%724, %bottleneck_block_10_project_weights : tensor<1x14x14x384xf32>, tensor<1x1x384x64xf32>) outs(%726 : tensor<1x14x14x64xf32>) -> tensor<1x14x14x64xf32>
  %728 = tensor.empty() : tensor<64xf32>
  %729 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_10_project_BatchNorm_moving_variance, %cst_6 : tensor<64xf32>, tensor<64xf32>) outs(%728 : tensor<64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<64xf32>
  %730 = tensor.empty() : tensor<64xf32>
  %731 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%729 : tensor<64xf32>) outs(%730 : tensor<64xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<64xf32>
  %732 = tensor.empty() : tensor<1x14x14x64xf32>
  %733 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_10_project_BatchNorm_gamma : tensor<64xf32>) outs(%732 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %734 = tensor.empty() : tensor<1x14x14x64xf32>
  %735 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_10_project_BatchNorm_beta : tensor<64xf32>) outs(%734 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %736 = tensor.empty() : tensor<1x14x14x64xf32>
  %737 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_10_project_BatchNorm_moving_mean : tensor<64xf32>) outs(%736 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %738 = tensor.empty() : tensor<1x14x14x64xf32>
  %739 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%731 : tensor<64xf32>) outs(%738 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x64xf32>
  %740 = tensor.empty() : tensor<1x14x14x64xf32>
  %741 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%727, %737 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%740 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %742 = tensor.empty() : tensor<1x14x14x64xf32>
  %743 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%741, %733 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%742 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %744 = tensor.empty() : tensor<1x14x14x64xf32>
  %745 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%743, %739 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%744 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %746 = tensor.empty() : tensor<1x14x14x64xf32>
  %747 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%745, %735 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%746 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>
  %748 = tensor.empty() : tensor<1x14x14x64xf32>
  %749 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%747, %674 : tensor<1x14x14x64xf32>, tensor<1x14x14x64xf32>) outs(%748 : tensor<1x14x14x64xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x64xf32>

  // Layer 31 - Bottleneck block 11, first Conv2D, 1x1 filter, stride 1
  %750 = tensor.empty() : tensor<1x14x14x384xf32>
  %751 = linalg.fill ins(%cst : f32) outs(%750 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %752 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%749, %bottleneck_block_11_expand_weights : tensor<1x14x14x64xf32>, tensor<1x1x64x384xf32>) outs(%751 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %753 = tensor.empty() : tensor<384xf32>
  %754 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_11_expand_BatchNorm_moving_variance, %cst_7 : tensor<384xf32>, tensor<384xf32>) outs(%753 : tensor<384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %755 = tensor.empty() : tensor<384xf32>
  %756 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%754 : tensor<384xf32>) outs(%755 : tensor<384xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %757 = tensor.empty() : tensor<1x14x14x384xf32>
  %758 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_11_expand_BatchNorm_gamma : tensor<384xf32>) outs(%757 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %759 = tensor.empty() : tensor<1x14x14x384xf32>
  %760 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_11_expand_BatchNorm_beta : tensor<384xf32>) outs(%759 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %761 = tensor.empty() : tensor<1x14x14x384xf32>
  %762 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_11_expand_BatchNorm_moving_mean : tensor<384xf32>) outs(%761 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %763 = tensor.empty() : tensor<1x14x14x384xf32>
  %764 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%756 : tensor<384xf32>) outs(%763 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %765 = tensor.empty() : tensor<1x14x14x384xf32>
  %766 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%752, %762 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%765 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %767 = tensor.empty() : tensor<1x14x14x384xf32>
  %768 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%766, %758 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%767 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %769 = tensor.empty() : tensor<1x14x14x384xf32>
  %770 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%768, %764 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%769 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %771 = tensor.empty() : tensor<1x14x14x384xf32>
  %772 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%770, %760 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%771 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>

  // ReLU6
  %773 = tensor.empty() : tensor<1x14x14x384xf32>
  %774 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %772, %cst_14 : tensor<f32>, tensor<1x14x14x384xf32>, tensor<f32>) outs(%773 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x384xf32>
  %padded_37 = tensor.pad %774 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x14x14x384xf32> to tensor<1x16x16x384xf32>

  // Layer 32 - Bottleneck block 11, depthwise Conv2D, 3x3, stride 1
  %775 = tensor.empty() : tensor<1x14x14x384xf32>
  %776 = linalg.fill ins(%cst : f32) outs(%775 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %collapsed_38 = tensor.collapse_shape %bottleneck_block_11_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x384x1xf32> into tensor<3x3x384xf32>
  %777 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_37, %collapsed_38 : tensor<1x16x16x384xf32>, tensor<3x3x384xf32>) outs(%776 : tensor<1x14x14x384xf32>) -> tensor<1x14x14x384xf32>
  %778 = tensor.empty() : tensor<384xf32>
  %779 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_11_depthwise_BatchNorm_moving_variance, %cst_7 : tensor<384xf32>, tensor<384xf32>) outs(%778 : tensor<384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %780 = tensor.empty() : tensor<384xf32>
  %781 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%779 : tensor<384xf32>) outs(%780 : tensor<384xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<384xf32>
  %782 = tensor.empty() : tensor<1x14x14x384xf32>
  %783 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_11_depthwise_BatchNorm_gamma : tensor<384xf32>) outs(%782 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %784 = tensor.empty() : tensor<1x14x14x384xf32>
  %785 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_11_depthwise_BatchNorm_beta : tensor<384xf32>) outs(%784 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %786 = tensor.empty() : tensor<1x14x14x384xf32>
  %787 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_11_depthwise_BatchNorm_moving_mean : tensor<384xf32>) outs(%786 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %788 = tensor.empty() : tensor<1x14x14x384xf32>
  %789 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%781 : tensor<384xf32>) outs(%788 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x384xf32>
  %790 = tensor.empty() : tensor<1x14x14x384xf32>
  %791 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%777, %787 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%790 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %792 = tensor.empty() : tensor<1x14x14x384xf32>
  %793 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%791, %783 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%792 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %794 = tensor.empty() : tensor<1x14x14x384xf32>
  %795 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%793, %789 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%794 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>
  %796 = tensor.empty() : tensor<1x14x14x384xf32>
  %797 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%795, %785 : tensor<1x14x14x384xf32>, tensor<1x14x14x384xf32>) outs(%796 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x384xf32>

  // ReLU6
  %798 = tensor.empty() : tensor<1x14x14x384xf32>
  %799 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %797, %cst_14 : tensor<f32>, tensor<1x14x14x384xf32>, tensor<f32>) outs(%798 : tensor<1x14x14x384xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x384xf32>

  // Layer 33 - Bottleneck block 11, second Conv2D, 1x1 filter, stride 1
  %800 = tensor.empty() : tensor<1x14x14x96xf32>
  %801 = linalg.fill ins(%cst : f32) outs(%800 : tensor<1x14x14x96xf32>) -> tensor<1x14x14x96xf32>
  %802 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%799, %bottleneck_block_11_project_weights : tensor<1x14x14x384xf32>, tensor<1x1x384x96xf32>) outs(%801 : tensor<1x14x14x96xf32>) -> tensor<1x14x14x96xf32>
  %803 = tensor.empty() : tensor<96xf32>
  %804 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_11_project_BatchNorm_moving_variance, %cst_2 : tensor<96xf32>, tensor<96xf32>) outs(%803 : tensor<96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<96xf32>
  %805 = tensor.empty() : tensor<96xf32>
  %806 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%804 : tensor<96xf32>) outs(%805 : tensor<96xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<96xf32>
  %807 = tensor.empty() : tensor<1x14x14x96xf32>
  %808 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_11_project_BatchNorm_gamma : tensor<96xf32>) outs(%807 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %809 = tensor.empty() : tensor<1x14x14x96xf32>
  %810 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_11_project_BatchNorm_beta : tensor<96xf32>) outs(%809 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %811 = tensor.empty() : tensor<1x14x14x96xf32>
  %812 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_11_project_BatchNorm_moving_mean : tensor<96xf32>) outs(%811 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %813 = tensor.empty() : tensor<1x14x14x96xf32>
  %814 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%806 : tensor<96xf32>) outs(%813 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %815 = tensor.empty() : tensor<1x14x14x96xf32>
  %816 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%802, %812 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%815 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>
  %817 = tensor.empty() : tensor<1x14x14x96xf32>
  %818 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%816, %808 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%817 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>
  %819 = tensor.empty() : tensor<1x14x14x96xf32>
  %820 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%818, %814 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%819 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>
  %821 = tensor.empty() : tensor<1x14x14x96xf32>
  %822 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%820, %810 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%821 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>

  // Layer 34 - Bottleneck block 12, first Conv2D, 1x1 filter, stride 1
  %823 = tensor.empty() : tensor<1x14x14x576xf32>
  %824 = linalg.fill ins(%cst : f32) outs(%823 : tensor<1x14x14x576xf32>) -> tensor<1x14x14x576xf32>
  %825 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%822, %bottleneck_block_12_expand_weights : tensor<1x14x14x96xf32>, tensor<1x1x96x576xf32>) outs(%824 : tensor<1x14x14x576xf32>) -> tensor<1x14x14x576xf32>
  %826 = tensor.empty() : tensor<576xf32>
  %827 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_12_expand_BatchNorm_moving_variance, %cst_8 : tensor<576xf32>, tensor<576xf32>) outs(%826 : tensor<576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %828 = tensor.empty() : tensor<576xf32>
  %829 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%827 : tensor<576xf32>) outs(%828 : tensor<576xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %830 = tensor.empty() : tensor<1x14x14x576xf32>
  %831 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_12_expand_BatchNorm_gamma : tensor<576xf32>) outs(%830 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %832 = tensor.empty() : tensor<1x14x14x576xf32>
  %833 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_12_expand_BatchNorm_beta : tensor<576xf32>) outs(%832 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %834 = tensor.empty() : tensor<1x14x14x576xf32>
  %835 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_12_expand_BatchNorm_moving_mean : tensor<576xf32>) outs(%834 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %836 = tensor.empty() : tensor<1x14x14x576xf32>
  %837 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%829 : tensor<576xf32>) outs(%836 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %838 = tensor.empty() : tensor<1x14x14x576xf32>
  %839 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%825, %835 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%838 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %840 = tensor.empty() : tensor<1x14x14x576xf32>
  %841 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%839, %831 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%840 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %842 = tensor.empty() : tensor<1x14x14x576xf32>
  %843 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%841, %837 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%842 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %844 = tensor.empty() : tensor<1x14x14x576xf32>
  %845 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%843, %833 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%844 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>

  // ReLU6
  %846 = tensor.empty() : tensor<1x14x14x576xf32>
  %847 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %845, %cst_14 : tensor<f32>, tensor<1x14x14x576xf32>, tensor<f32>) outs(%846 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x576xf32>
  %padded_39 = tensor.pad %847 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x14x14x576xf32> to tensor<1x16x16x576xf32>

  // Layer 35 - Bottleneck block 12, depthwise Conv2D, 3x3, stride 1
  %848 = tensor.empty() : tensor<1x14x14x576xf32>
  %849 = linalg.fill ins(%cst : f32) outs(%848 : tensor<1x14x14x576xf32>) -> tensor<1x14x14x576xf32>
  %collapsed_40 = tensor.collapse_shape %bottleneck_block_12_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x576x1xf32> into tensor<3x3x576xf32>
  %850 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_39, %collapsed_40 : tensor<1x16x16x576xf32>, tensor<3x3x576xf32>) outs(%849 : tensor<1x14x14x576xf32>) -> tensor<1x14x14x576xf32>
  %851 = tensor.empty() : tensor<576xf32>
  %852 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_12_depthwise_BatchNorm_moving_variance, %cst_8 : tensor<576xf32>, tensor<576xf32>) outs(%851 : tensor<576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %853 = tensor.empty() : tensor<576xf32>
  %854 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%852 : tensor<576xf32>) outs(%853 : tensor<576xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %855 = tensor.empty() : tensor<1x14x14x576xf32>
  %856 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_12_depthwise_BatchNorm_gamma : tensor<576xf32>) outs(%855 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %857 = tensor.empty() : tensor<1x14x14x576xf32>
  %858 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_12_depthwise_BatchNorm_beta : tensor<576xf32>) outs(%857 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %859 = tensor.empty() : tensor<1x14x14x576xf32>
  %860 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_12_depthwise_BatchNorm_moving_mean : tensor<576xf32>) outs(%859 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %861 = tensor.empty() : tensor<1x14x14x576xf32>
  %862 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%854 : tensor<576xf32>) outs(%861 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %863 = tensor.empty() : tensor<1x14x14x576xf32>
  %864 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%850, %860 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%863 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %865 = tensor.empty() : tensor<1x14x14x576xf32>
  %866 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%864, %856 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%865 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %867 = tensor.empty() : tensor<1x14x14x576xf32>
  %868 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%866, %862 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%867 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %869 = tensor.empty() : tensor<1x14x14x576xf32>
  %870 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%868, %858 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%869 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>

  // ReLU6
  %871 = tensor.empty() : tensor<1x14x14x576xf32>
  %872 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %870, %cst_14 : tensor<f32>, tensor<1x14x14x576xf32>, tensor<f32>) outs(%871 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x576xf32>

  // Layer 36 - Bottleneck block 12, second Conv2D, 1x1 filter, stride 1
  %873 = tensor.empty() : tensor<1x14x14x96xf32>
  %874 = linalg.fill ins(%cst : f32) outs(%873 : tensor<1x14x14x96xf32>) -> tensor<1x14x14x96xf32>
  %875 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%872, %bottleneck_block_12_project_weights : tensor<1x14x14x576xf32>, tensor<1x1x576x96xf32>) outs(%874 : tensor<1x14x14x96xf32>) -> tensor<1x14x14x96xf32>
  %876 = tensor.empty() : tensor<96xf32>
  %877 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_12_project_BatchNorm_moving_variance, %cst_2 : tensor<96xf32>, tensor<96xf32>) outs(%876 : tensor<96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<96xf32>
  %878 = tensor.empty() : tensor<96xf32>
  %879 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%877 : tensor<96xf32>) outs(%878 : tensor<96xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<96xf32>
  %880 = tensor.empty() : tensor<1x14x14x96xf32>
  %881 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_12_project_BatchNorm_gamma : tensor<96xf32>) outs(%880 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %882 = tensor.empty() : tensor<1x14x14x96xf32>
  %883 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_12_project_BatchNorm_beta : tensor<96xf32>) outs(%882 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %884 = tensor.empty() : tensor<1x14x14x96xf32>
  %885 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_12_project_BatchNorm_moving_mean : tensor<96xf32>) outs(%884 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %886 = tensor.empty() : tensor<1x14x14x96xf32>
  %887 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%879 : tensor<96xf32>) outs(%886 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %888 = tensor.empty() : tensor<1x14x14x96xf32>
  %889 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%875, %885 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%888 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>
  %890 = tensor.empty() : tensor<1x14x14x96xf32>
  %891 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%889, %881 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%890 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>
  %892 = tensor.empty() : tensor<1x14x14x96xf32>
  %893 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%891, %887 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%892 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>
  %894 = tensor.empty() : tensor<1x14x14x96xf32>
  %895 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%893, %883 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%894 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>
  %896 = tensor.empty() : tensor<1x14x14x96xf32>
  %897 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%895, %822 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%896 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>

  // Layer 37 - Bottleneck block 13, first Conv2D, 1x1 filter, stride 1
  %898 = tensor.empty() : tensor<1x14x14x576xf32>
  %899 = linalg.fill ins(%cst : f32) outs(%898 : tensor<1x14x14x576xf32>) -> tensor<1x14x14x576xf32>
  %900 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%897, %bottleneck_block_13_expand_weights : tensor<1x14x14x96xf32>, tensor<1x1x96x576xf32>) outs(%899 : tensor<1x14x14x576xf32>) -> tensor<1x14x14x576xf32>
  %901 = tensor.empty() : tensor<576xf32>
  %902 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_13_expand_BatchNorm_moving_variance, %cst_8 : tensor<576xf32>, tensor<576xf32>) outs(%901 : tensor<576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %903 = tensor.empty() : tensor<576xf32>
  %904 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%902 : tensor<576xf32>) outs(%903 : tensor<576xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %905 = tensor.empty() : tensor<1x14x14x576xf32>
  %906 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_13_expand_BatchNorm_gamma : tensor<576xf32>) outs(%905 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %907 = tensor.empty() : tensor<1x14x14x576xf32>
  %908 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_13_expand_BatchNorm_beta : tensor<576xf32>) outs(%907 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %909 = tensor.empty() : tensor<1x14x14x576xf32>
  %910 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_13_expand_BatchNorm_moving_mean : tensor<576xf32>) outs(%909 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %911 = tensor.empty() : tensor<1x14x14x576xf32>
  %912 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%904 : tensor<576xf32>) outs(%911 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %913 = tensor.empty() : tensor<1x14x14x576xf32>
  %914 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%900, %910 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%913 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %915 = tensor.empty() : tensor<1x14x14x576xf32>
  %916 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%914, %906 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%915 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %917 = tensor.empty() : tensor<1x14x14x576xf32>
  %918 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%916, %912 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%917 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %919 = tensor.empty() : tensor<1x14x14x576xf32>
  %920 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%918, %908 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%919 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>

  // ReLU6
  %921 = tensor.empty() : tensor<1x14x14x576xf32>
  %922 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %920, %cst_14 : tensor<f32>, tensor<1x14x14x576xf32>, tensor<f32>) outs(%921 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x576xf32>
  %padded_41 = tensor.pad %922 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x14x14x576xf32> to tensor<1x16x16x576xf32>

  // Layer 38 - Bottleneck block 13, depthwise Conv2D, 3x3, stride 1
  %923 = tensor.empty() : tensor<1x14x14x576xf32>
  %924 = linalg.fill ins(%cst : f32) outs(%923 : tensor<1x14x14x576xf32>) -> tensor<1x14x14x576xf32>
  %collapsed_42 = tensor.collapse_shape %bottleneck_block_13_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x576x1xf32> into tensor<3x3x576xf32>
  %925 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_41, %collapsed_42 : tensor<1x16x16x576xf32>, tensor<3x3x576xf32>) outs(%924 : tensor<1x14x14x576xf32>) -> tensor<1x14x14x576xf32>
  %926 = tensor.empty() : tensor<576xf32>
  %927 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_13_depthwise_BatchNorm_moving_variance, %cst_8 : tensor<576xf32>, tensor<576xf32>) outs(%926 : tensor<576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %928 = tensor.empty() : tensor<576xf32>
  %929 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%927 : tensor<576xf32>) outs(%928 : tensor<576xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %930 = tensor.empty() : tensor<1x14x14x576xf32>
  %931 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_13_depthwise_BatchNorm_gamma : tensor<576xf32>) outs(%930 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %932 = tensor.empty() : tensor<1x14x14x576xf32>
  %933 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_13_depthwise_BatchNorm_beta : tensor<576xf32>) outs(%932 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %934 = tensor.empty() : tensor<1x14x14x576xf32>
  %935 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_13_depthwise_BatchNorm_moving_mean : tensor<576xf32>) outs(%934 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %936 = tensor.empty() : tensor<1x14x14x576xf32>
  %937 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%929 : tensor<576xf32>) outs(%936 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %938 = tensor.empty() : tensor<1x14x14x576xf32>
  %939 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%925, %935 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%938 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %940 = tensor.empty() : tensor<1x14x14x576xf32>
  %941 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%939, %931 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%940 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %942 = tensor.empty() : tensor<1x14x14x576xf32>
  %943 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%941, %937 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%942 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %944 = tensor.empty() : tensor<1x14x14x576xf32>
  %945 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%943, %933 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%944 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>

  // ReLU6
  %946 = tensor.empty() : tensor<1x14x14x576xf32>
  %947 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %945, %cst_14 : tensor<f32>, tensor<1x14x14x576xf32>, tensor<f32>) outs(%946 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x576xf32>

  // Layer 39 - Bottleneck block 13, second Conv2D, 1x1 filter, stride 1
  %948 = tensor.empty() : tensor<1x14x14x96xf32>
  %949 = linalg.fill ins(%cst : f32) outs(%948 : tensor<1x14x14x96xf32>) -> tensor<1x14x14x96xf32>
  %950 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%947, %bottleneck_block_13_project_weights : tensor<1x14x14x576xf32>, tensor<1x1x576x96xf32>) outs(%949 : tensor<1x14x14x96xf32>) -> tensor<1x14x14x96xf32>
  %951 = tensor.empty() : tensor<96xf32>
  %952 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_13_project_BatchNorm_moving_variance, %cst_2 : tensor<96xf32>, tensor<96xf32>) outs(%951 : tensor<96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<96xf32>
  %953 = tensor.empty() : tensor<96xf32>
  %954 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%952 : tensor<96xf32>) outs(%953 : tensor<96xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<96xf32>
  %955 = tensor.empty() : tensor<1x14x14x96xf32>
  %956 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_13_project_BatchNorm_gamma : tensor<96xf32>) outs(%955 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %957 = tensor.empty() : tensor<1x14x14x96xf32>
  %958 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_13_project_BatchNorm_beta : tensor<96xf32>) outs(%957 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %959 = tensor.empty() : tensor<1x14x14x96xf32>
  %960 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_13_project_BatchNorm_moving_mean : tensor<96xf32>) outs(%959 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %961 = tensor.empty() : tensor<1x14x14x96xf32>
  %962 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%954 : tensor<96xf32>) outs(%961 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x96xf32>
  %963 = tensor.empty() : tensor<1x14x14x96xf32>
  %964 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%950, %960 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%963 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>
  %965 = tensor.empty() : tensor<1x14x14x96xf32>
  %966 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%964, %956 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%965 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>
  %967 = tensor.empty() : tensor<1x14x14x96xf32>
  %968 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%966, %962 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%967 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>
  %969 = tensor.empty() : tensor<1x14x14x96xf32>
  %970 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%968, %958 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%969 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>
  %971 = tensor.empty() : tensor<1x14x14x96xf32>
  %972 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%970, %897 : tensor<1x14x14x96xf32>, tensor<1x14x14x96xf32>) outs(%971 : tensor<1x14x14x96xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x96xf32>

  // Layer 40 - Bottleneck block 14, first Conv2D, 1x1 filter, stride 1
  %973 = tensor.empty() : tensor<1x14x14x576xf32>
  %974 = linalg.fill ins(%cst : f32) outs(%973 : tensor<1x14x14x576xf32>) -> tensor<1x14x14x576xf32>
  %975 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%972, %bottleneck_block_14_expand_weights : tensor<1x14x14x96xf32>, tensor<1x1x96x576xf32>) outs(%974 : tensor<1x14x14x576xf32>) -> tensor<1x14x14x576xf32>
  %976 = tensor.empty() : tensor<576xf32>
  %977 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_14_expand_BatchNorm_moving_variance, %cst_8 : tensor<576xf32>, tensor<576xf32>) outs(%976 : tensor<576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %978 = tensor.empty() : tensor<576xf32>
  %979 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%977 : tensor<576xf32>) outs(%978 : tensor<576xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %980 = tensor.empty() : tensor<1x14x14x576xf32>
  %981 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_14_expand_BatchNorm_gamma : tensor<576xf32>) outs(%980 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %982 = tensor.empty() : tensor<1x14x14x576xf32>
  %983 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_14_expand_BatchNorm_beta : tensor<576xf32>) outs(%982 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %984 = tensor.empty() : tensor<1x14x14x576xf32>
  %985 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_14_expand_BatchNorm_moving_mean : tensor<576xf32>) outs(%984 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %986 = tensor.empty() : tensor<1x14x14x576xf32>
  %987 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%979 : tensor<576xf32>) outs(%986 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x14x14x576xf32>
  %988 = tensor.empty() : tensor<1x14x14x576xf32>
  %989 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%975, %985 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%988 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %990 = tensor.empty() : tensor<1x14x14x576xf32>
  %991 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%989, %981 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%990 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %992 = tensor.empty() : tensor<1x14x14x576xf32>
  %993 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%991, %987 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%992 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>
  %994 = tensor.empty() : tensor<1x14x14x576xf32>
  %995 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%993, %983 : tensor<1x14x14x576xf32>, tensor<1x14x14x576xf32>) outs(%994 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x14x14x576xf32>

  // ReLU6
  %996 = tensor.empty() : tensor<1x14x14x576xf32>
  %997 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %995, %cst_14 : tensor<f32>, tensor<1x14x14x576xf32>, tensor<f32>) outs(%996 : tensor<1x14x14x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x14x14x576xf32>
  %padded_43 = tensor.pad %997 low[0, 0, 0, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x14x14x576xf32> to tensor<1x15x15x576xf32>

  // Layer 41 - Bottleneck block 14, depthwise Conv2D, 3x3, stride 2
  %998 = tensor.empty() : tensor<1x7x7x576xf32>
  %999 = linalg.fill ins(%cst : f32) outs(%998 : tensor<1x7x7x576xf32>) -> tensor<1x7x7x576xf32>
  %collapsed_44 = tensor.collapse_shape %bottleneck_block_14_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x576x1xf32> into tensor<3x3x576xf32>
  %1000 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%padded_43, %collapsed_44 : tensor<1x15x15x576xf32>, tensor<3x3x576xf32>) outs(%999 : tensor<1x7x7x576xf32>) -> tensor<1x7x7x576xf32>
  %1001 = tensor.empty() : tensor<576xf32>
  %1002 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_14_depthwise_BatchNorm_moving_variance, %cst_8 : tensor<576xf32>, tensor<576xf32>) outs(%1001 : tensor<576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %1003 = tensor.empty() : tensor<576xf32>
  %1004 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1002 : tensor<576xf32>) outs(%1003 : tensor<576xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<576xf32>
  %1005 = tensor.empty() : tensor<1x7x7x576xf32>
  %1006 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_14_depthwise_BatchNorm_gamma : tensor<576xf32>) outs(%1005 : tensor<1x7x7x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x576xf32>
  %1007 = tensor.empty() : tensor<1x7x7x576xf32>
  %1008 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_14_depthwise_BatchNorm_beta : tensor<576xf32>) outs(%1007 : tensor<1x7x7x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x576xf32>
  %1009 = tensor.empty() : tensor<1x7x7x576xf32>
  %1010 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_14_depthwise_BatchNorm_moving_mean : tensor<576xf32>) outs(%1009 : tensor<1x7x7x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x576xf32>
  %1011 = tensor.empty() : tensor<1x7x7x576xf32>
  %1012 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1004 : tensor<576xf32>) outs(%1011 : tensor<1x7x7x576xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x576xf32>
  %1013 = tensor.empty() : tensor<1x7x7x576xf32>
  %1014 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1000, %1010 : tensor<1x7x7x576xf32>, tensor<1x7x7x576xf32>) outs(%1013 : tensor<1x7x7x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x576xf32>
  %1015 = tensor.empty() : tensor<1x7x7x576xf32>
  %1016 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1014, %1006 : tensor<1x7x7x576xf32>, tensor<1x7x7x576xf32>) outs(%1015 : tensor<1x7x7x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x576xf32>
  %1017 = tensor.empty() : tensor<1x7x7x576xf32>
  %1018 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1016, %1012 : tensor<1x7x7x576xf32>, tensor<1x7x7x576xf32>) outs(%1017 : tensor<1x7x7x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x576xf32>
  %1019 = tensor.empty() : tensor<1x7x7x576xf32>
  %1020 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1018, %1008 : tensor<1x7x7x576xf32>, tensor<1x7x7x576xf32>) outs(%1019 : tensor<1x7x7x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x576xf32>

  // ReLU6
  %1021 = tensor.empty() : tensor<1x7x7x576xf32>
  %1022 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %1020, %cst_14 : tensor<f32>, tensor<1x7x7x576xf32>, tensor<f32>) outs(%1021 : tensor<1x7x7x576xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x7x7x576xf32>

  // Layer 42 - Bottleneck block 14, second Conv2D, 1x1 filter, stride 1
  %1023 = tensor.empty() : tensor<1x7x7x160xf32>
  %1024 = linalg.fill ins(%cst : f32) outs(%1023 : tensor<1x7x7x160xf32>) -> tensor<1x7x7x160xf32>
  %1025 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1022, %bottleneck_block_14_project_weights : tensor<1x7x7x576xf32>, tensor<1x1x576x160xf32>) outs(%1024 : tensor<1x7x7x160xf32>) -> tensor<1x7x7x160xf32>
  %1026 = tensor.empty() : tensor<160xf32>
  %1027 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_14_project_BatchNorm_moving_variance, %cst_9 : tensor<160xf32>, tensor<160xf32>) outs(%1026 : tensor<160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<160xf32>
  %1028 = tensor.empty() : tensor<160xf32>
  %1029 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1027 : tensor<160xf32>) outs(%1028 : tensor<160xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<160xf32>
  %1030 = tensor.empty() : tensor<1x7x7x160xf32>
  %1031 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_14_project_BatchNorm_gamma : tensor<160xf32>) outs(%1030 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1032 = tensor.empty() : tensor<1x7x7x160xf32>
  %1033 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_14_project_BatchNorm_beta : tensor<160xf32>) outs(%1032 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1034 = tensor.empty() : tensor<1x7x7x160xf32>
  %1035 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_14_project_BatchNorm_moving_mean : tensor<160xf32>) outs(%1034 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1036 = tensor.empty() : tensor<1x7x7x160xf32>
  %1037 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1029 : tensor<160xf32>) outs(%1036 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1038 = tensor.empty() : tensor<1x7x7x160xf32>
  %1039 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1025, %1035 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1038 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>
  %1040 = tensor.empty() : tensor<1x7x7x160xf32>
  %1041 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1039, %1031 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1040 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>
  %1042 = tensor.empty() : tensor<1x7x7x160xf32>
  %1043 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1041, %1037 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1042 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>
  %1044 = tensor.empty() : tensor<1x7x7x160xf32>
  %1045 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1043, %1033 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1044 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>

  // Layer 43 - Bottleneck block 15, first Conv2D, 1x1 filter, stride 1
  %1046 = tensor.empty() : tensor<1x7x7x960xf32>
  %1047 = linalg.fill ins(%cst : f32) outs(%1046 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %1048 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1045, %bottleneck_block_15_expand_weights : tensor<1x7x7x160xf32>, tensor<1x1x160x960xf32>) outs(%1047 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %1049 = tensor.empty() : tensor<960xf32>
  %1050 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_15_expand_BatchNorm_moving_variance, %cst_10 : tensor<960xf32>, tensor<960xf32>) outs(%1049 : tensor<960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1051 = tensor.empty() : tensor<960xf32>
  %1052 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1050 : tensor<960xf32>) outs(%1051 : tensor<960xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1053 = tensor.empty() : tensor<1x7x7x960xf32>
  %1054 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_15_expand_BatchNorm_gamma : tensor<960xf32>) outs(%1053 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1055 = tensor.empty() : tensor<1x7x7x960xf32>
  %1056 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_15_expand_BatchNorm_beta : tensor<960xf32>) outs(%1055 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1057 = tensor.empty() : tensor<1x7x7x960xf32>
  %1058 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_15_expand_BatchNorm_moving_mean : tensor<960xf32>) outs(%1057 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1059 = tensor.empty() : tensor<1x7x7x960xf32>
  %1060 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1052 : tensor<960xf32>) outs(%1059 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1061 = tensor.empty() : tensor<1x7x7x960xf32>
  %1062 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1048, %1058 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1061 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1063 = tensor.empty() : tensor<1x7x7x960xf32>
  %1064 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1062, %1054 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1063 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1065 = tensor.empty() : tensor<1x7x7x960xf32>
  %1066 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1064, %1060 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1065 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1067 = tensor.empty() : tensor<1x7x7x960xf32>
  %1068 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1066, %1056 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1067 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>

  // ReLU6
  %1069 = tensor.empty() : tensor<1x7x7x960xf32>
  %1070 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %1068, %cst_14 : tensor<f32>, tensor<1x7x7x960xf32>, tensor<f32>) outs(%1069 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x7x7x960xf32>
  %padded_45 = tensor.pad %1070 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x7x7x960xf32> to tensor<1x9x9x960xf32>

  // Layer 44 - Bottleneck block 15, depthwise Conv2D, 3x3, stride 1
  %1071 = tensor.empty() : tensor<1x7x7x960xf32>
  %1072 = linalg.fill ins(%cst : f32) outs(%1071 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %collapsed_46 = tensor.collapse_shape %bottleneck_block_15_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x960x1xf32> into tensor<3x3x960xf32>
  %1073 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_45, %collapsed_46 : tensor<1x9x9x960xf32>, tensor<3x3x960xf32>) outs(%1072 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %1074 = tensor.empty() : tensor<960xf32>
  %1075 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_15_depthwise_BatchNorm_moving_variance, %cst_10 : tensor<960xf32>, tensor<960xf32>) outs(%1074 : tensor<960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1076 = tensor.empty() : tensor<960xf32>
  %1077 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1075 : tensor<960xf32>) outs(%1076 : tensor<960xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1078 = tensor.empty() : tensor<1x7x7x960xf32>
  %1079 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_15_depthwise_BatchNorm_gamma : tensor<960xf32>) outs(%1078 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1080 = tensor.empty() : tensor<1x7x7x960xf32>
  %1081 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_15_depthwise_BatchNorm_beta : tensor<960xf32>) outs(%1080 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1082 = tensor.empty() : tensor<1x7x7x960xf32>
  %1083 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_15_depthwise_BatchNorm_moving_mean : tensor<960xf32>) outs(%1082 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1084 = tensor.empty() : tensor<1x7x7x960xf32>
  %1085 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1077 : tensor<960xf32>) outs(%1084 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1086 = tensor.empty() : tensor<1x7x7x960xf32>
  %1087 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1073, %1083 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1086 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1088 = tensor.empty() : tensor<1x7x7x960xf32>
  %1089 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1087, %1079 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1088 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1090 = tensor.empty() : tensor<1x7x7x960xf32>
  %1091 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1089, %1085 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1090 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1092 = tensor.empty() : tensor<1x7x7x960xf32>
  %1093 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1091, %1081 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1092 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>

  // ReLU6
  %1094 = tensor.empty() : tensor<1x7x7x960xf32>
  %1095 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %1093, %cst_14 : tensor<f32>, tensor<1x7x7x960xf32>, tensor<f32>) outs(%1094 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x7x7x960xf32>

  // Layer 45 - Bottleneck block 15, second Conv2D, 1x1 filter, stride 1
  %1096 = tensor.empty() : tensor<1x7x7x160xf32>
  %1097 = linalg.fill ins(%cst : f32) outs(%1096 : tensor<1x7x7x160xf32>) -> tensor<1x7x7x160xf32>
  %1098 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1095, %bottleneck_block_15_project_weights : tensor<1x7x7x960xf32>, tensor<1x1x960x160xf32>) outs(%1097 : tensor<1x7x7x160xf32>) -> tensor<1x7x7x160xf32>
  %1099 = tensor.empty() : tensor<160xf32>
  %1100 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_15_project_BatchNorm_moving_variance, %cst_9 : tensor<160xf32>, tensor<160xf32>) outs(%1099 : tensor<160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<160xf32>
  %1101 = tensor.empty() : tensor<160xf32>
  %1102 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1100 : tensor<160xf32>) outs(%1101 : tensor<160xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<160xf32>
  %1103 = tensor.empty() : tensor<1x7x7x160xf32>
  %1104 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_15_project_BatchNorm_gamma : tensor<160xf32>) outs(%1103 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1105 = tensor.empty() : tensor<1x7x7x160xf32>
  %1106 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_15_project_BatchNorm_beta : tensor<160xf32>) outs(%1105 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1107 = tensor.empty() : tensor<1x7x7x160xf32>
  %1108 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_15_project_BatchNorm_moving_mean : tensor<160xf32>) outs(%1107 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1109 = tensor.empty() : tensor<1x7x7x160xf32>
  %1110 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1102 : tensor<160xf32>) outs(%1109 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1111 = tensor.empty() : tensor<1x7x7x160xf32>
  %1112 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1098, %1108 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1111 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>
  %1113 = tensor.empty() : tensor<1x7x7x160xf32>
  %1114 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1112, %1104 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1113 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>
  %1115 = tensor.empty() : tensor<1x7x7x160xf32>
  %1116 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1114, %1110 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1115 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>
  %1117 = tensor.empty() : tensor<1x7x7x160xf32>
  %1118 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1116, %1106 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1117 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>
  %1119 = tensor.empty() : tensor<1x7x7x160xf32>
  %1120 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1118, %1045 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1119 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>

  // Layer 46 - Bottleneck block 16, first Conv2D, 1x1 filter, stride 1
  %1121 = tensor.empty() : tensor<1x7x7x960xf32>
  %1122 = linalg.fill ins(%cst : f32) outs(%1121 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %1123 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1120, %bottleneck_block_16_expand_weights : tensor<1x7x7x160xf32>, tensor<1x1x160x960xf32>) outs(%1122 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %1124 = tensor.empty() : tensor<960xf32>
  %1125 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_16_expand_BatchNorm_moving_variance, %cst_10 : tensor<960xf32>, tensor<960xf32>) outs(%1124 : tensor<960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1126 = tensor.empty() : tensor<960xf32>
  %1127 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1125 : tensor<960xf32>) outs(%1126 : tensor<960xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1128 = tensor.empty() : tensor<1x7x7x960xf32>
  %1129 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_16_expand_BatchNorm_gamma : tensor<960xf32>) outs(%1128 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1130 = tensor.empty() : tensor<1x7x7x960xf32>
  %1131 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_16_expand_BatchNorm_beta : tensor<960xf32>) outs(%1130 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1132 = tensor.empty() : tensor<1x7x7x960xf32>
  %1133 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_16_expand_BatchNorm_moving_mean : tensor<960xf32>) outs(%1132 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1134 = tensor.empty() : tensor<1x7x7x960xf32>
  %1135 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1127 : tensor<960xf32>) outs(%1134 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1136 = tensor.empty() : tensor<1x7x7x960xf32>
  %1137 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1123, %1133 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1136 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1138 = tensor.empty() : tensor<1x7x7x960xf32>
  %1139 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1137, %1129 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1138 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1140 = tensor.empty() : tensor<1x7x7x960xf32>
  %1141 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1139, %1135 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1140 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1142 = tensor.empty() : tensor<1x7x7x960xf32>
  %1143 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1141, %1131 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1142 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>

  // ReLU6
  %1144 = tensor.empty() : tensor<1x7x7x960xf32>
  %1145 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %1143, %cst_14 : tensor<f32>, tensor<1x7x7x960xf32>, tensor<f32>) outs(%1144 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x7x7x960xf32>
  %padded_47 = tensor.pad %1145 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x7x7x960xf32> to tensor<1x9x9x960xf32>

  // Layer 47 - Bottleneck block 16, depthwise Conv2D, 3x3, stride 1
  %1146 = tensor.empty() : tensor<1x7x7x960xf32>
  %1147 = linalg.fill ins(%cst : f32) outs(%1146 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %collapsed_48 = tensor.collapse_shape %bottleneck_block_16_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x960x1xf32> into tensor<3x3x960xf32>
  %1148 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_47, %collapsed_48 : tensor<1x9x9x960xf32>, tensor<3x3x960xf32>) outs(%1147 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %1149 = tensor.empty() : tensor<960xf32>
  %1150 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_16_depthwise_BatchNorm_moving_variance, %cst_10 : tensor<960xf32>, tensor<960xf32>) outs(%1149 : tensor<960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1151 = tensor.empty() : tensor<960xf32>
  %1152 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1150 : tensor<960xf32>) outs(%1151 : tensor<960xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1153 = tensor.empty() : tensor<1x7x7x960xf32>
  %1154 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_16_depthwise_BatchNorm_gamma : tensor<960xf32>) outs(%1153 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1155 = tensor.empty() : tensor<1x7x7x960xf32>
  %1156 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_16_depthwise_BatchNorm_beta : tensor<960xf32>) outs(%1155 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1157 = tensor.empty() : tensor<1x7x7x960xf32>
  %1158 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_16_depthwise_BatchNorm_moving_mean : tensor<960xf32>) outs(%1157 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1159 = tensor.empty() : tensor<1x7x7x960xf32>
  %1160 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1152 : tensor<960xf32>) outs(%1159 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1161 = tensor.empty() : tensor<1x7x7x960xf32>
  %1162 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1148, %1158 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1161 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1163 = tensor.empty() : tensor<1x7x7x960xf32>
  %1164 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1162, %1154 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1163 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1165 = tensor.empty() : tensor<1x7x7x960xf32>
  %1166 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1164, %1160 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1165 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1167 = tensor.empty() : tensor<1x7x7x960xf32>
  %1168 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1166, %1156 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1167 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>

  // ReLU6
  %1169 = tensor.empty() : tensor<1x7x7x960xf32>
  %1170 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %1168, %cst_14 : tensor<f32>, tensor<1x7x7x960xf32>, tensor<f32>) outs(%1169 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x7x7x960xf32>

  // Layer 48 - Bottleneck block 16, second Conv2D, 1x1 filter, stride 1
  %1171 = tensor.empty() : tensor<1x7x7x160xf32>
  %1172 = linalg.fill ins(%cst : f32) outs(%1171 : tensor<1x7x7x160xf32>) -> tensor<1x7x7x160xf32>
  %1173 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1170, %bottleneck_block_16_project_weights : tensor<1x7x7x960xf32>, tensor<1x1x960x160xf32>) outs(%1172 : tensor<1x7x7x160xf32>) -> tensor<1x7x7x160xf32>
  %1174 = tensor.empty() : tensor<160xf32>
  %1175 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_16_project_BatchNorm_moving_variance, %cst_9 : tensor<160xf32>, tensor<160xf32>) outs(%1174 : tensor<160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<160xf32>
  %1176 = tensor.empty() : tensor<160xf32>
  %1177 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1175 : tensor<160xf32>) outs(%1176 : tensor<160xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<160xf32>
  %1178 = tensor.empty() : tensor<1x7x7x160xf32>
  %1179 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_16_project_BatchNorm_gamma : tensor<160xf32>) outs(%1178 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1180 = tensor.empty() : tensor<1x7x7x160xf32>
  %1181 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_16_project_BatchNorm_beta : tensor<160xf32>) outs(%1180 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1182 = tensor.empty() : tensor<1x7x7x160xf32>
  %1183 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_16_project_BatchNorm_moving_mean : tensor<160xf32>) outs(%1182 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1184 = tensor.empty() : tensor<1x7x7x160xf32>
  %1185 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1177 : tensor<160xf32>) outs(%1184 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x160xf32>
  %1186 = tensor.empty() : tensor<1x7x7x160xf32>
  %1187 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1173, %1183 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1186 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>
  %1188 = tensor.empty() : tensor<1x7x7x160xf32>
  %1189 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1187, %1179 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1188 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>
  %1190 = tensor.empty() : tensor<1x7x7x160xf32>
  %1191 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1189, %1185 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1190 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>
  %1192 = tensor.empty() : tensor<1x7x7x160xf32>
  %1193 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1191, %1181 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1192 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>
  %1194 = tensor.empty() : tensor<1x7x7x160xf32>
  %1195 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1193, %1120 : tensor<1x7x7x160xf32>, tensor<1x7x7x160xf32>) outs(%1194 : tensor<1x7x7x160xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x160xf32>

  // Layer 49 - Bottleneck block 17, first Conv2D, 1x1 filter, stride 1
  %1196 = tensor.empty() : tensor<1x7x7x960xf32>
  %1197 = linalg.fill ins(%cst : f32) outs(%1196 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %1198 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1195, %bottleneck_block_17_expand_weights : tensor<1x7x7x160xf32>, tensor<1x1x160x960xf32>) outs(%1197 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %1199 = tensor.empty() : tensor<960xf32>
  %1200 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_17_expand_BatchNorm_moving_variance, %cst_10 : tensor<960xf32>, tensor<960xf32>) outs(%1199 : tensor<960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1201 = tensor.empty() : tensor<960xf32>
  %1202 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1200 : tensor<960xf32>) outs(%1201 : tensor<960xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1203 = tensor.empty() : tensor<1x7x7x960xf32>
  %1204 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_17_expand_BatchNorm_gamma : tensor<960xf32>) outs(%1203 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1205 = tensor.empty() : tensor<1x7x7x960xf32>
  %1206 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_17_expand_BatchNorm_beta : tensor<960xf32>) outs(%1205 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1207 = tensor.empty() : tensor<1x7x7x960xf32>
  %1208 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_17_expand_BatchNorm_moving_mean : tensor<960xf32>) outs(%1207 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1209 = tensor.empty() : tensor<1x7x7x960xf32>
  %1210 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1202 : tensor<960xf32>) outs(%1209 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1211 = tensor.empty() : tensor<1x7x7x960xf32>
  %1212 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1198, %1208 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1211 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1213 = tensor.empty() : tensor<1x7x7x960xf32>
  %1214 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1212, %1204 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1213 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1215 = tensor.empty() : tensor<1x7x7x960xf32>
  %1216 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1214, %1210 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1215 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1217 = tensor.empty() : tensor<1x7x7x960xf32>
  %1218 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1216, %1206 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1217 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>

  // ReLU6
  %1219 = tensor.empty() : tensor<1x7x7x960xf32>
  %1220 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %1218, %cst_14 : tensor<f32>, tensor<1x7x7x960xf32>, tensor<f32>) outs(%1219 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x7x7x960xf32>
  %padded_49 = tensor.pad %1220 low[0, 1, 1, 0] high[0, 1, 1, 0] {
  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):
    tensor.yield %cst : f32
  } : tensor<1x7x7x960xf32> to tensor<1x9x9x960xf32>

  // Layer 50 - Bottleneck block 17, depthwise Conv2D, 3x3, stride 1
  %1221 = tensor.empty() : tensor<1x7x7x960xf32>
  %1222 = linalg.fill ins(%cst : f32) outs(%1221 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %collapsed_50 = tensor.collapse_shape %bottleneck_block_17_depthwise_depthwise_weights [[0], [1], [2, 3]] : tensor<3x3x960x1xf32> into tensor<3x3x960xf32>
  %1223 = linalg.depthwise_conv_2d_nhwc_hwc {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded_49, %collapsed_50 : tensor<1x9x9x960xf32>, tensor<3x3x960xf32>) outs(%1222 : tensor<1x7x7x960xf32>) -> tensor<1x7x7x960xf32>
  %1224 = tensor.empty() : tensor<960xf32>
  %1225 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_17_depthwise_BatchNorm_moving_variance, %cst_10 : tensor<960xf32>, tensor<960xf32>) outs(%1224 : tensor<960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1226 = tensor.empty() : tensor<960xf32>
  %1227 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1225 : tensor<960xf32>) outs(%1226 : tensor<960xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<960xf32>
  %1228 = tensor.empty() : tensor<1x7x7x960xf32>
  %1229 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_17_depthwise_BatchNorm_gamma : tensor<960xf32>) outs(%1228 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1230 = tensor.empty() : tensor<1x7x7x960xf32>
  %1231 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_17_depthwise_BatchNorm_beta : tensor<960xf32>) outs(%1230 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1232 = tensor.empty() : tensor<1x7x7x960xf32>
  %1233 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_17_depthwise_BatchNorm_moving_mean : tensor<960xf32>) outs(%1232 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1234 = tensor.empty() : tensor<1x7x7x960xf32>
  %1235 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1227 : tensor<960xf32>) outs(%1234 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x960xf32>
  %1236 = tensor.empty() : tensor<1x7x7x960xf32>
  %1237 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1223, %1233 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1236 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1238 = tensor.empty() : tensor<1x7x7x960xf32>
  %1239 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1237, %1229 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1238 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1240 = tensor.empty() : tensor<1x7x7x960xf32>
  %1241 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1239, %1235 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1240 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>
  %1242 = tensor.empty() : tensor<1x7x7x960xf32>
  %1243 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1241, %1231 : tensor<1x7x7x960xf32>, tensor<1x7x7x960xf32>) outs(%1242 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x960xf32>

  // ReLU6
  %1244 = tensor.empty() : tensor<1x7x7x960xf32>
  %1245 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %1243, %cst_14 : tensor<f32>, tensor<1x7x7x960xf32>, tensor<f32>) outs(%1244 : tensor<1x7x7x960xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x7x7x960xf32>

  // Layer 51 - Bottleneck block 17, second Conv2D, 1x1 filter, stride 1
  %1246 = tensor.empty() : tensor<1x7x7x320xf32>
  %1247 = linalg.fill ins(%cst : f32) outs(%1246 : tensor<1x7x7x320xf32>) -> tensor<1x7x7x320xf32>
  %1248 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1245, %bottleneck_block_17_project_weights : tensor<1x7x7x960xf32>, tensor<1x1x960x320xf32>) outs(%1247 : tensor<1x7x7x320xf32>) -> tensor<1x7x7x320xf32>
  %1249 = tensor.empty() : tensor<320xf32>
  %1250 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%bottleneck_block_17_project_BatchNorm_moving_variance, %cst_11 : tensor<320xf32>, tensor<320xf32>) outs(%1249 : tensor<320xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<320xf32>
  %1251 = tensor.empty() : tensor<320xf32>
  %1252 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1250 : tensor<320xf32>) outs(%1251 : tensor<320xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<320xf32>
  %1253 = tensor.empty() : tensor<1x7x7x320xf32>
  %1254 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_17_project_BatchNorm_gamma : tensor<320xf32>) outs(%1253 : tensor<1x7x7x320xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x320xf32>
  %1255 = tensor.empty() : tensor<1x7x7x320xf32>
  %1256 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_17_project_BatchNorm_beta : tensor<320xf32>) outs(%1255 : tensor<1x7x7x320xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x320xf32>
  %1257 = tensor.empty() : tensor<1x7x7x320xf32>
  %1258 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%bottleneck_block_17_project_BatchNorm_moving_mean : tensor<320xf32>) outs(%1257 : tensor<1x7x7x320xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x320xf32>
  %1259 = tensor.empty() : tensor<1x7x7x320xf32>
  %1260 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1252 : tensor<320xf32>) outs(%1259 : tensor<1x7x7x320xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x320xf32>
  %1261 = tensor.empty() : tensor<1x7x7x320xf32>
  %1262 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1248, %1258 : tensor<1x7x7x320xf32>, tensor<1x7x7x320xf32>) outs(%1261 : tensor<1x7x7x320xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x320xf32>
  %1263 = tensor.empty() : tensor<1x7x7x320xf32>
  %1264 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1262, %1254 : tensor<1x7x7x320xf32>, tensor<1x7x7x320xf32>) outs(%1263 : tensor<1x7x7x320xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x320xf32>
  %1265 = tensor.empty() : tensor<1x7x7x320xf32>
  %1266 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1264, %1260 : tensor<1x7x7x320xf32>, tensor<1x7x7x320xf32>) outs(%1265 : tensor<1x7x7x320xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x320xf32>
  %1267 = tensor.empty() : tensor<1x7x7x320xf32>
  %1268 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1266, %1256 : tensor<1x7x7x320xf32>, tensor<1x7x7x320xf32>) outs(%1267 : tensor<1x7x7x320xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x320xf32>

  // Layer 52 - Conv2D, 1x1 filter, stride 1
  %1269 = tensor.empty() : tensor<1x7x7x1280xf32>
  %1270 = linalg.fill ins(%cst : f32) outs(%1269 : tensor<1x7x7x1280xf32>) -> tensor<1x7x7x1280xf32>
  %1271 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1268, %layer_52_conv_weights : tensor<1x7x7x320xf32>, tensor<1x1x320x1280xf32>) outs(%1270 : tensor<1x7x7x1280xf32>) -> tensor<1x7x7x1280xf32>
  %1272 = tensor.empty() : tensor<1280xf32>
  %1273 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel"]} ins(%layer_52_conv_BatchNorm_moving_variance, %cst_12 : tensor<1280xf32>, tensor<1280xf32>) outs(%1272 : tensor<1280xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1280xf32>
  %1274 = tensor.empty() : tensor<1280xf32>
  %1275 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel"]} ins(%1273 : tensor<1280xf32>) outs(%1274 : tensor<1280xf32>) {
  ^bb0(%in: f32, %out: f32):
    %1307 = math.sqrt %in : f32
    linalg.yield %1307 : f32
  } -> tensor<1280xf32>
  %1276 = tensor.empty() : tensor<1x7x7x1280xf32>
  %1277 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%layer_52_conv_BatchNorm_gamma : tensor<1280xf32>) outs(%1276 : tensor<1x7x7x1280xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x1280xf32>
  %1278 = tensor.empty() : tensor<1x7x7x1280xf32>
  %1279 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%layer_52_conv_BatchNorm_beta : tensor<1280xf32>) outs(%1278 : tensor<1x7x7x1280xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x1280xf32>
  %1280 = tensor.empty() : tensor<1x7x7x1280xf32>
  %1281 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%layer_52_conv_BatchNorm_moving_mean : tensor<1280xf32>) outs(%1280 : tensor<1x7x7x1280xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x1280xf32>
  %1282 = tensor.empty() : tensor<1x7x7x1280xf32>
  %1283 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1275 : tensor<1280xf32>) outs(%1282 : tensor<1x7x7x1280xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x7x7x1280xf32>
  %1284 = tensor.empty() : tensor<1x7x7x1280xf32>
  %1285 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1271, %1281 : tensor<1x7x7x1280xf32>, tensor<1x7x7x1280xf32>) outs(%1284 : tensor<1x7x7x1280xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.subf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x1280xf32>
  %1286 = tensor.empty() : tensor<1x7x7x1280xf32>
  %1287 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1285, %1277 : tensor<1x7x7x1280xf32>, tensor<1x7x7x1280xf32>) outs(%1286 : tensor<1x7x7x1280xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.mulf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x1280xf32>
  %1288 = tensor.empty() : tensor<1x7x7x1280xf32>
  %1289 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1287, %1283 : tensor<1x7x7x1280xf32>, tensor<1x7x7x1280xf32>) outs(%1288 : tensor<1x7x7x1280xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x1280xf32>
  %1290 = tensor.empty() : tensor<1x7x7x1280xf32>
  %1291 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1289, %1279 : tensor<1x7x7x1280xf32>, tensor<1x7x7x1280xf32>) outs(%1290 : tensor<1x7x7x1280xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x7x7x1280xf32>

  // ReLU6
  %1292 = tensor.empty() : tensor<1x7x7x1280xf32>
  %1293 = linalg.generic {indexing_maps = [#map1, #map0, #map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_15, %1291, %cst_14 : tensor<f32>, tensor<1x7x7x1280xf32>, tensor<f32>) outs(%1292 : tensor<1x7x7x1280xf32>) {
  ^bb0(%in: f32, %in_52: f32, %in_53: f32, %out: f32):
    %1307 = arith.maxf %in, %in_52 : f32
    %1308 = arith.minf %1307, %in_53 : f32
    linalg.yield %1308 : f32
  } -> tensor<1x7x7x1280xf32>

  // Layer 53 - Average pooling
  %1294 = tensor.empty() : tensor<7x7xf32>
  %1295 = tensor.empty() : tensor<1x1x1x1280xf32>
  %1296 = linalg.fill ins(%cst : f32) outs(%1295 : tensor<1x1x1x1280xf32>) -> tensor<1x1x1x1280xf32>
  %1297 = linalg.pooling_nhwc_sum {dilations  = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%1293, %1294 : tensor<1x7x7x1280xf32>, tensor<7x7xf32>) outs(%1296 : tensor<1x1x1x1280xf32>) -> tensor<1x1x1x1280xf32>
  %1298 = tensor.empty() : tensor<1x1x1x1280xf32>
  %1299 = linalg.generic {indexing_maps = [#map1, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst_13 : tensor<f32>) outs(%1298 : tensor<1x1x1x1280xf32>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -> tensor<1x1x1x1280xf32>
  %1300 = tensor.empty() : tensor<1x1x1x1280xf32>
  %1301 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1297, %1299 : tensor<1x1x1x1280xf32>, tensor<1x1x1x1280xf32>) outs(%1300 : tensor<1x1x1x1280xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.divf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x1x1x1280xf32>
  
  // Layer 54 - Conv2D, 1x1 filter, stride 1
  %1302 = tensor.empty() : tensor<1x1x1x1001xf32>
  %1303 = linalg.fill ins(%cst : f32) outs(%1302 : tensor<1x1x1x1001xf32>) -> tensor<1x1x1x1001xf32>
  %1304 = linalg.conv_2d_nhwc_hwcf {dilations  = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1301, %layer_54_logits_conv_weights : tensor<1x1x1x1280xf32>, tensor<1x1x1280x1001xf32>) outs(%1303 : tensor<1x1x1x1001xf32>) -> tensor<1x1x1x1001xf32>
  %expanded = tensor.expand_shape %layer_54_logits_conv_biases [[0, 1, 2, 3]] : tensor<1001xf32> into tensor<1x1x1x1001xf32>
  %1305 = tensor.empty() : tensor<1x1x1x1001xf32>
  %1306 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1304, %expanded : tensor<1x1x1x1001xf32>, tensor<1x1x1x1001xf32>) outs(%1305 : tensor<1x1x1x1001xf32>) {
  ^bb0(%in: f32, %in_52: f32, %out: f32):
    %1307 = arith.addf %in, %in_52 : f32
    linalg.yield %1307 : f32
  } -> tensor<1x1x1x1001xf32>
  %collapsed_51 = tensor.collapse_shape %1306 [[0], [1, 2, 3]] : tensor<1x1x1x1001xf32> into tensor<1x1001xf32>
  return %collapsed_51 : tensor<1x1001xf32>
}
